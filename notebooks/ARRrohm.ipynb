{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c359bb1d",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854e74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa4268",
   "metadata": {},
   "source": [
    "### Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff5fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]</th>\n",
       "      <th>H POS25 T 75°C [mΩ]</th>\n",
       "      <th>H POS26 T 75°C [mΩ]</th>\n",
       "      <th>H POS27 T 75°C [mΩ]</th>\n",
       "      <th>X POS1 R 75°C [mΩ]</th>\n",
       "      <th>X POS1 S 75°C [mΩ]</th>\n",
       "      <th>X POS1 T 75°C [mΩ]</th>\n",
       "      <th>Y POS1 R 75°C [mΩ]</th>\n",
       "      <th>Y POS1 S 75°C [mΩ]</th>\n",
       "      <th>Y POS1 T 75°C [mΩ]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393.230000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.142000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>420.991013</td>\n",
       "      <td>406.693652</td>\n",
       "      <td>378.146272</td>\n",
       "      <td>406.622639</td>\n",
       "      <td>421.073862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.068145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424.407154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.451000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0         NaN  59571 2016-10-23                 NaN          393.230000   \n",
       "1         NaN  59571 2006-01-29                 NaN                 NaN   \n",
       "2         NaN  59571 1996-04-16          420.991013          406.693652   \n",
       "3         NaN  59572 2016-09-18                 NaN          424.407154   \n",
       "4         NaN  59572 2006-01-29                 NaN                 NaN   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ] H POS5 R 75°C [mΩ]  \\\n",
       "0                 NaN                 NaN                NaN   \n",
       "1                 NaN                 NaN                NaN   \n",
       "2          378.146272          406.622639         421.073862   \n",
       "3                 NaN                 NaN                NaN   \n",
       "4                 NaN                 NaN                NaN   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
       "0                 NaN                 NaN  ...                  NaN   \n",
       "1                 NaN                 NaN  ...                  NaN   \n",
       "2                 NaN                 NaN  ...                  NaN   \n",
       "3                 NaN                 NaN  ...                  NaN   \n",
       "4                 NaN                 NaN  ...                  NaN   \n",
       "\n",
       "   H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  X POS1 T 75°C [mΩ]  \\\n",
       "0           28.142000                 NaN                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2           29.068145                 NaN                 NaN   \n",
       "3           26.451000                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  Y POS1 T 75°C [mΩ]  \n",
       "0              15.909                 NaN                 NaN  \n",
       "1                 NaN                 NaN                 NaN  \n",
       "2                 NaN                 NaN                 0.0  \n",
       "3              15.038                 NaN                 NaN  \n",
       "4                 NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# LECTURA DE DATOS\n",
    "# ---------------------------\n",
    "\n",
    "# Lista de posibles rutas\n",
    "addresses = [\n",
    "    'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx',\n",
    "    'C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx',\n",
    "    'C:/Users/mticllacu/OneDrive - LUZ DEL SUR S.A.A/Archivos de Ronald Quispe Ocaña - ProyectoRyD_V2/Basededatos/RDEV.xlsx'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in addresses:\n",
    "    if os.path.exists(path):   # verifica si existe\n",
    "        df = pd.read_excel(path, header=1)\n",
    "        print(f\"✅ Archivo cargado desde: {path}\")\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    raise FileNotFoundError(\"❌ No se encontró el archivo en ninguna de las rutas especificadas.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0e2851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]</th>\n",
       "      <th>H POS25 T 75°C [mΩ]</th>\n",
       "      <th>H POS26 T 75°C [mΩ]</th>\n",
       "      <th>H POS27 T 75°C [mΩ]</th>\n",
       "      <th>X POS1 R 75°C [mΩ]</th>\n",
       "      <th>X POS1 S 75°C [mΩ]</th>\n",
       "      <th>X POS1 T 75°C [mΩ]</th>\n",
       "      <th>Y POS1 R 75°C [mΩ]</th>\n",
       "      <th>Y POS1 S 75°C [mΩ]</th>\n",
       "      <th>Y POS1 T 75°C [mΩ]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393.230000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.142000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>420.991013</td>\n",
       "      <td>406.693652</td>\n",
       "      <td>378.146272</td>\n",
       "      <td>406.622639</td>\n",
       "      <td>421.073862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.068145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424.407154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.451000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  59571 2016-10-23                 NaN          393.230000   \n",
       "1  59571 2006-01-29                 NaN                 NaN   \n",
       "2  59571 1996-04-16          420.991013          406.693652   \n",
       "3  59572 2016-09-18                 NaN          424.407154   \n",
       "4  59572 2006-01-29                 NaN                 NaN   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ] H POS5 R 75°C [mΩ]  \\\n",
       "0                 NaN                 NaN                NaN   \n",
       "1                 NaN                 NaN                NaN   \n",
       "2          378.146272          406.622639         421.073862   \n",
       "3                 NaN                 NaN                NaN   \n",
       "4                 NaN                 NaN                NaN   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0                 NaN                 NaN                 NaN  ...   \n",
       "1                 NaN                 NaN                 NaN  ...   \n",
       "2                 NaN                 NaN                 NaN  ...   \n",
       "3                 NaN                 NaN                 NaN  ...   \n",
       "4                 NaN                 NaN                 NaN  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]  H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   H POS27 T 75°C [mΩ]  X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  \\\n",
       "0                  NaN           28.142000                 NaN   \n",
       "1                  NaN                 NaN                 NaN   \n",
       "2                  NaN           29.068145                 NaN   \n",
       "3                  NaN           26.451000                 NaN   \n",
       "4                  NaN                 NaN                 NaN   \n",
       "\n",
       "   X POS1 T 75°C [mΩ]  Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  \\\n",
       "0                 NaN              15.909                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 NaN                 NaN                 NaN   \n",
       "3                 NaN              15.038                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   Y POS1 T 75°C [mΩ]  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 0.0  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# LIMPIEZA DE DATOS\n",
    "# ---------------------------\n",
    "df = df.iloc[:, 1:]   # quitar primera columna vacía\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors=\"coerce\")\n",
    "df = df.dropna(subset=['FECHA'])\n",
    "df[\"SERIE\"] = df[\"SERIE\"].astype(str)\n",
    "df_full = df.copy()   # copia de detalles originales\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cba584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_8852\\1278047033.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Delta</th>\n",
       "      <th>X POS1 R 75°C [mΩ]_Delta</th>\n",
       "      <th>X POS1 S 75°C [mΩ]_Delta</th>\n",
       "      <th>X POS1 T 75°C [mΩ]_Delta</th>\n",
       "      <th>Y POS1 R 75°C [mΩ]_Delta</th>\n",
       "      <th>Y POS1 S 75°C [mΩ]_Delta</th>\n",
       "      <th>Y POS1 T 75°C [mΩ]_Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393.230000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.186118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>420.991013</td>\n",
       "      <td>406.693652</td>\n",
       "      <td>378.146272</td>\n",
       "      <td>406.622639</td>\n",
       "      <td>421.073862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424.407154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.244089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.59857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  59571 2016-10-23                 NaN          393.230000   \n",
       "1  59571 2006-01-29                 NaN                 NaN   \n",
       "2  59571 1996-04-16          420.991013          406.693652   \n",
       "3  59572 2016-09-18                 NaN          424.407154   \n",
       "4  59572 2006-01-29                 NaN                 NaN   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0                 NaN                 NaN                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2          378.146272          406.622639          421.073862   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0                 NaN                 NaN                 NaN  ...   \n",
       "1                 NaN                 NaN                 NaN  ...   \n",
       "2                 NaN                 NaN                 NaN  ...   \n",
       "3                 NaN                 NaN                 NaN  ...   \n",
       "4                 NaN                 NaN                 NaN  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]_Delta  H POS25 T 75°C [mΩ]_Delta  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   H POS26 T 75°C [mΩ]_Delta  H POS27 T 75°C [mΩ]_Delta  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   X POS1 R 75°C [mΩ]_Delta  X POS1 S 75°C [mΩ]_Delta  \\\n",
       "0                  3.186118                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                  0.000000                       NaN   \n",
       "3                 12.244089                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   X POS1 T 75°C [mΩ]_Delta  Y POS1 R 75°C [mΩ]_Delta  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                  11.59857   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   Y POS1 S 75°C [mΩ]_Delta  Y POS1 T 75°C [mΩ]_Delta  \n",
       "0                       NaN                       NaN  \n",
       "1                       NaN                       NaN  \n",
       "2                       NaN                       NaN  \n",
       "3                       NaN                       NaN  \n",
       "4                       NaN                       NaN  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# CÁLCULO DE DELTAS\n",
    "# ---------------------------\n",
    "res_cols = [c for c in df.columns if c.endswith(\"[mΩ]\")]\n",
    "\n",
    "for col in res_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # valor inicial por SERIE en la fecha mínima\n",
    "    ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
    "    ref_mapped = df[\"SERIE\"].map(ref)\n",
    "\n",
    "    # variación porcentual\n",
    "    \n",
    "    delta = abs((df[col] - ref_mapped) / ref_mapped) * 100\n",
    "    delta = delta.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # marcar casos inválidos\n",
    "    mask = df[col].isna() | ref_mapped.isna() | (ref_mapped == 0) | (df[col] == 0)\n",
    "    delta[mask] = np.nan\n",
    "\n",
    "    # agregar columna nueva\n",
    "    df[f\"{col}_Delta\"] = delta\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f474e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    }
   ],
   "source": [
    "# Columnas de resistencia (terminan en mΩ)\n",
    "res_cols = [c for c in df.columns if c.endswith(\"[mΩ]\")]\n",
    "\n",
    "for col in res_cols:\n",
    "    # valor inicial por SERIE en la fecha mínima\n",
    "    ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
    "    ref_mapped = df[\"SERIE\"].map(ref)\n",
    "\n",
    "    # variación porcentual\n",
    "    delta = abs((df[col] - ref_mapped) / ref_mapped) * 100\n",
    "\n",
    "    # reemplazar inf por NaN (división por cero)\n",
    "    delta = delta.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # si alguno es NaN o ref/valor es 0 -> NaN\n",
    "    mask = df[col].isna() | ref_mapped.isna() | (ref_mapped == 0) | (df[col] == 0)\n",
    "    delta[mask] = np.nan\n",
    "\n",
    "    # agregar columna nueva\n",
    "    df[f\"{col}_Delta\"] = delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a57ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Delta</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Delta</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Delta</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.668552</td>\n",
       "      <td>3.693408</td>\n",
       "      <td>3.654666</td>\n",
       "      <td>3.683929</td>\n",
       "      <td>3.432531</td>\n",
       "      <td>3.073641</td>\n",
       "      <td>2.758893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.753419</td>\n",
       "      <td>4.192451</td>\n",
       "      <td>4.091914</td>\n",
       "      <td>4.047196</td>\n",
       "      <td>118.927854</td>\n",
       "      <td>115.680402</td>\n",
       "      <td>128.940916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611445</td>\n",
       "      <td>2.591122</td>\n",
       "      <td>2.599196</td>\n",
       "      <td>2.591715</td>\n",
       "      <td>17.088098</td>\n",
       "      <td>16.900843</td>\n",
       "      <td>88.271359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]_Delta  H POS25 T 75°C [mΩ]_Delta  \\\n",
       "0                   3.668552                   3.693408   \n",
       "1                   3.753419                   4.192451   \n",
       "2                   0.000000                   0.000000   \n",
       "3                   2.611445                   2.591122   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   H POS26 T 75°C [mΩ]_Delta  H POS27 T 75°C [mΩ]_Delta  \\\n",
       "0                   3.654666                   3.683929   \n",
       "1                   4.091914                   4.047196   \n",
       "2                   0.000000                   0.000000   \n",
       "3                   2.599196                   2.591715   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   X POS1 R 75°C[mΩ]_Delta  X POS1 S 75°C[mΩ]_Delta  X POS1 T 75°C[mΩ]_Delta  \\\n",
       "0                 3.432531                 3.073641                 2.758893   \n",
       "1               118.927854               115.680402               128.940916   \n",
       "2                 0.000000                 0.000000                 0.000000   \n",
       "3                17.088098                16.900843                88.271359   \n",
       "4                 0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   Y POS1 R 75°C[mΩ]_Delta  Y POS1 S 75°C[mΩ]_Delta  Y POS1 T 75°C[mΩ]_Delta  \n",
       "0                      NaN                      NaN                      NaN  \n",
       "1                      NaN                      NaN                      NaN  \n",
       "2                      NaN                      NaN                      NaN  \n",
       "3                      NaN                      NaN                      NaN  \n",
       "4                      NaN                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n"
     ]
    }
   ],
   "source": [
    "# Identificar las columnas que terminan en \"_Delta\"\n",
    "delta_cols = [c for c in df.columns if c.endswith(\"_Delta\")]\n",
    "\n",
    "# Crear nuevas columnas de puntaje según la regla\n",
    "for col in delta_cols:\n",
    "    puntaje_col = col.replace(\"_Delta\", \"_Score\")  # ejemplo: H POS21..._Delta → H POS21..._Score\n",
    "    df[puntaje_col] = df[col].apply(\n",
    "        lambda x: np.nan if pd.isna(x) else (1 if x < 5 else 5) \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Score</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]_Score  H POS25 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   H POS26 T 75°C [mΩ]_Score  H POS27 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   X POS1 R 75°C[mΩ]_Score  X POS1 S 75°C[mΩ]_Score  X POS1 T 75°C[mΩ]_Score  \\\n",
       "0                        1                        1                        1   \n",
       "1                        5                        5                        5   \n",
       "2                        1                        1                        1   \n",
       "3                        5                        5                        5   \n",
       "4                        1                        1                        1   \n",
       "\n",
       "   Y POS1 R 75°C[mΩ]_Score  Y POS1 S 75°C[mΩ]_Score  Y POS1 T 75°C[mΩ]_Score  \n",
       "0                      NaN                      NaN                      NaN  \n",
       "1                      NaN                      NaN                      NaN  \n",
       "2                      NaN                      NaN                      NaN  \n",
       "3                      NaN                      NaN                      NaN  \n",
       "4                      NaN                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 263 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\4100089174.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ROHM\"] = df[delta_cols].max(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Identificar las columnas que terminan en \"_Delta\"\n",
    "delta_cols = [c for c in df.columns if c.endswith(\"_Score\")]\n",
    "\n",
    "# Crear una nueva columna con el máximo por fila\n",
    "df[\"ROHM\"] = df[delta_cols].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fdecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Score</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>ROHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS25 T 75°C [mΩ]_Score  H POS26 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   H POS27 T 75°C [mΩ]_Score  X POS1 R 75°C[mΩ]_Score  \\\n",
       "0                          1                        1   \n",
       "1                          1                        5   \n",
       "2                          1                        1   \n",
       "3                          1                        5   \n",
       "4                          1                        1   \n",
       "\n",
       "   X POS1 S 75°C[mΩ]_Score  X POS1 T 75°C[mΩ]_Score  Y POS1 R 75°C[mΩ]_Score  \\\n",
       "0                        1                        1                      NaN   \n",
       "1                        5                        5                      NaN   \n",
       "2                        1                        1                      NaN   \n",
       "3                        5                        5                      NaN   \n",
       "4                        1                        1                      NaN   \n",
       "\n",
       "   Y POS1 S 75°C[mΩ]_Score  Y POS1 T 75°C[mΩ]_Score  ROHM  \n",
       "0                      NaN                      NaN   1.0  \n",
       "1                      NaN                      NaN   5.0  \n",
       "2                      NaN                      NaN   1.0  \n",
       "3                      NaN                      NaN   5.0  \n",
       "4                      NaN                      NaN   1.0  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e02c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>ROHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  ROHM\n",
       "0  146916 2019-06-30   1.0\n",
       "1  146916 2015-01-06   5.0\n",
       "2  146916 2014-11-12   1.0\n",
       "3  146917 2022-05-12   5.0\n",
       "4  146917 2014-12-05   1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROHM = df[['SERIE','FECHA','ROHM']]\n",
    "df_ROHM.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
