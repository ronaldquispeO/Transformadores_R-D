{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea64d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "from sqlalchemy.types import Date\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f6a20",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab7e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS']\n",
      "SERIE            object\n",
      "FECHA    datetime64[ns]\n",
      "HI              float64\n",
      "DGA             float64\n",
      "ACE             float64\n",
      "ARR             float64\n",
      "AIS             float64\n",
      "NUC             float64\n",
      "OLTC            float64\n",
      "BUS             float64\n",
      "dtype: object\n",
      "       SERIE      FECHA        HI   DGA       ACE  ARR       AIS  NUC  OLTC  \\\n",
      "0  230531-01 2025-10-15  3.910714  2.80  4.000000  5.0  4.142857  3.5   3.5   \n",
      "1   146660T3 2025-10-15  3.862347  2.65  4.090909  5.0  3.857143  3.5   5.0   \n",
      "2     338118 2025-10-15  3.584578  2.35  2.363636  5.0  4.142857  3.5   2.5   \n",
      "\n",
      "        BUS  \n",
      "0  5.000000  \n",
      "1  4.529412  \n",
      "2  5.000000  \n",
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'HI', 'DGA', 'ACE', 'ARR', 'AIS', 'NUC', 'OLTC', 'BUS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from main import obtener_HI\n",
    "\n",
    "df_HI = obtener_HI()\n",
    "df_HI = df_HI.sort_values(by=[\"FECHA\", \"HI\"], ascending=[False, False]).reset_index(drop=True)\n",
    "print(df_HI.dtypes)\n",
    "print(df_HI.head(3))\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_HI.to_sql('hi_general', engine, if_exists='replace', index=False, schema='processed_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_HI)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_HI.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d324e8",
   "metadata": {},
   "source": [
    "# IMPORTAR hidga detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64602e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from DGA import get_df_detalles_DGA\n",
    "\n",
    "df_dga = get_df_detalles_DGA()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_dga.to_sql('hi_dga', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_dga)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_dga.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1044df",
   "metadata": {},
   "source": [
    "# IMPORTAR hidga detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7caf6f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from DGA import get_df_detalles_ext_DGA\n",
    "\n",
    "df_dga_ext = get_df_detalles_ext_DGA()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_dga_ext.to_sql('hi_dga_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_dga_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_dga_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb70212",
   "metadata": {},
   "source": [
    "# IMPORTAR hiace detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef55482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ACE import get_df_detalles_ACE\n",
    "\n",
    "df_ace = get_df_detalles_ACE()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ace.to_sql('hi_ace', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ace)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ace.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29e890",
   "metadata": {},
   "source": [
    "# IMPORTAR hiace detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b8c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ACE import get_df_detalles_ext_ACE\n",
    "\n",
    "df_ace_ext = get_df_detalles_ext_ACE()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ace_ext.to_sql('hi_ace_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ace_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ace_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b92eb",
   "metadata": {},
   "source": [
    "# IMPORTAR hiarr detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fcb3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 39 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARR import get_df_detalles_ARR\n",
    "\n",
    "df_arr = get_df_detalles_ARR()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr.to_sql('hi_arr', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b30da",
   "metadata": {},
   "source": [
    "# IMPORTAR hiarr detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85db5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARR import get_df_detalles_ext_ARR\n",
    "\n",
    "df_arr_ext = get_df_detalles_ext_ARR()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_ext.to_sql('hi_arr_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6716ffe",
   "metadata": {},
   "source": [
    "# IMPORTAR rohm detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6773795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C[mΩ]', 'X POS1 S 75°C[mΩ]', 'X POS1 T 75°C[mΩ]', 'Y POS1 R 75°C[mΩ]', 'Y POS1 S 75°C[mΩ]', 'Y POS1 T 75°C[mΩ]']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARRrohm import get_df_detalles_ROHM\n",
    "\n",
    "df_arr_rohm = get_df_detalles_ROHM()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rohm.to_sql('hi_arr_rohm', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rohm)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rohm.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f7d8f",
   "metadata": {},
   "source": [
    "# IMPORTAR rohm detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc92231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C[mΩ]', 'X POS1 S 75°C[mΩ]', 'X POS1 T 75°C[mΩ]', 'Y POS1 R 75°C[mΩ]', 'Y POS1 S 75°C[mΩ]', 'Y POS1 T 75°C[mΩ]']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARRrohm import get_df_detalles_ext_ROHM\n",
    "\n",
    "df_arr_rohm_ext = get_df_detalles_ext_ROHM()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rohm_ext.to_sql('hi_arr_rohm_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rohm_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rohm_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c70682",
   "metadata": {},
   "source": [
    "# IMPORTAR rtra detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171ad9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from ARRrtra import get_df_detalles_RTRA\n",
    "\n",
    "df_arr_rtra = get_df_detalles_RTRA()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rtra.to_sql('hi_arr_rtra', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rtra)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rtra.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa4aaa",
   "metadata": {},
   "source": [
    "# IMPORTAR rtra detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f795c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARRrtra import get_df_detalles_ext_RTRA\n",
    "\n",
    "df_arr_rtra_ext = get_df_detalles_ext_RTRA()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rtra_ext.to_sql('hi_arr_rtra_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rtra_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rtra_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570bcd9",
   "metadata": {},
   "source": [
    "# IMPORTAR rdis detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d95a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X 1 [%] ONAF 2', 'H-X 14 [%] ONAF 2', 'H-X 27 [%] ONAF 2', 'H-Y 1 [%]', 'H-Y 14 [%]', 'H-Y 27 [%]', 'X-Y 1 [%]', 'X-Y 2 [%]', 'X-Y 3 [%]']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from ARRdis import get_df_detalles_DIS\n",
    "\n",
    "df_arr_rdis = get_df_detalles_DIS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rdis.to_sql('hi_arr_rdis', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rdis)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rdis.columns))   \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f989e0",
   "metadata": {},
   "source": [
    "# IMPORTAR rdis detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82466f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X 1 [%] ONAF 2', 'H-X 14 [%] ONAF 2', 'H-X 27 [%] ONAF 2', 'H-Y 1 [%]', 'H-Y 14 [%]', 'H-Y 27 [%]', 'X-Y 1 [%]', 'X-Y 2 [%]', 'X-Y 3 [%]']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from ARRdis import get_df_detalles_ext_DIS\n",
    "\n",
    "df_arr_rdis_ext = get_df_detalles_ext_DIS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_arr_rdis_ext.to_sql('hi_arr_rdis_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_arr_rdis_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_arr_rdis_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0fbc7e",
   "metadata": {},
   "source": [
    "# IMPORTAR hiais detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe01d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 28 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from AIS import get_df_detalles_AIS\n",
    "\n",
    "df_ais = get_df_detalles_AIS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais.to_sql('hi_ais', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294050bc",
   "metadata": {},
   "source": [
    "# IMPORTAR hiais detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b55ba925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from AIS import get_df_detalles_ext_AIS\n",
    "\n",
    "df_ais_ext = get_df_detalles_ext_AIS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_ext.to_sql('hi_ais_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98233cad",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_nuc detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00eba8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 28 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUC :\n",
    "from NUC import get_df_detalles_NUC\n",
    "\n",
    "df_nuc = get_df_detalles_NUC()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_nuc.to_sql('hi_nuc', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_nuc)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d981efc",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_nuc detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a723d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUC EXTENDIDO :\n",
    "from NUC import get_df_detalles_ext_NUC\n",
    "\n",
    "df_nuc_ext = get_df_detalles_ext_NUC()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_nuc_ext.to_sql('hi_nuc_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_nuc_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab6102",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_oltc detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6787d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME OLTC :\n",
    "from OLTC import df_detalles as df_oltc\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_oltc.to_sql('hi_oltc', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_oltc)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_oltc.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed466794",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_oltc detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87f57369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME OLTC EXTENDIDO :\n",
    "from OLTC import df_detalles_ext as df_oltc_ext\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_oltc_ext.to_sql('hi_oltc_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_oltc_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_oltc_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118c661",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387fc57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME BUS :\n",
    "from BUS import get_df_detalles_BUS\n",
    "from sqlalchemy.types import Date\n",
    "\n",
    "df_bus = get_df_detalles_BUS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_bus.to_sql('hi_bus', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_bus)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2bf06",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eda60e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME BUS EXTENDIDO :\n",
    "from BUS import get_df_detalles_ext_BUS\n",
    "\n",
    "df_bus_ext = get_df_detalles_ext_BUS()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_bus_ext.to_sql('hi_bus_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_bus_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b327b6",
   "metadata": {},
   "source": [
    "# IMPORTAR FURANOS detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bcc2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from FURANOS import get_df_detalles_FUR\n",
    "\n",
    "df_ais_furanos = get_df_detalles_FUR()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_furanos.to_sql('hi_ais_furanos', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_furanos)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_furanos.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac57fde",
   "metadata": {},
   "source": [
    "# IMPORTAR FURANOS detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ec24df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from FURANOS import get_df_detalles_ext_FUR\n",
    "\n",
    "df_ais_furanos_ext = get_df_detalles_ext_FUR()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_furanos_ext.to_sql('hi_ais_furanos_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_furanos_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_furanos_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfecc5d",
   "metadata": {},
   "source": [
    "# IMPORTAR FP detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027f6a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT+ICLH %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH+ICTL %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from FP import get_df_detalles_FP\n",
    "\n",
    "df_ais_fp = get_df_detalles_FP()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_fp.to_sql('hi_ais_fp', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_fp)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_fp.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25948a",
   "metadata": {},
   "source": [
    "# IMPORTAR FP detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ef33d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT+ICLH %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH+ICTL %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from FP import get_df_detalles_ext_FP\n",
    "\n",
    "df_ais_fp_ext = get_df_detalles_ext_FP()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_fp_ext.to_sql('hi_ais_fp_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_fp_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_fp_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d72c8b",
   "metadata": {},
   "source": [
    "# IMPORTAR CD Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea6a66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ARR :\n",
    "from CD import get_df_detalles_CD\n",
    "\n",
    "df_ais_cd = get_df_detalles_CD()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la_rohm tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_cd.to_sql('hi_ais_cd', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_cd)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_cd.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbd196",
   "metadata": {},
   "source": [
    "# IMPORTAR CD Detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25e4c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME ACE :\n",
    "from CD import get_df_detalles_ext_CD\n",
    "\n",
    "df_ais_cd_ext = get_df_detalles_ext_CD()\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_ais_cd_ext.to_sql('hi_ais_cd_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_ais_cd_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_ais_cd_ext.columns))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b69a3a",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_fpbc1 detallado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55d64871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPBC1 :\n",
    "from FPBC1 import get_df_detalles_FP_C1\n",
    "df_bus_fpbc1 = get_df_detalles_FP_C1()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpbc1.to_sql('hi_bus_fpbc1', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpbc1)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpbc1.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510cb3b",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_fpbc1 detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a648466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPBC1 EXTENDIDO :\n",
    "from FPBC1 import get_df_detalles_ext_FP_C1\n",
    "df_bus_fpbc1_ext = get_df_detalles_ext_FP_C1()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpbc1_ext.to_sql('hi_bus_fpbc1_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpbc1_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpbc1_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5449e",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_fpbc2 detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af84d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPBC2 :\n",
    "from FPBC2 import get_df_detalles_FP_C2\n",
    "df_bus_fpbc2 = get_df_detalles_FP_C2()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpbc2.to_sql('hi_bus_fpbc2', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpbc2)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpbc2.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29902f",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_fpbc2 detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dd2b01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPBC2 EXTENDIDO :\n",
    "from FPBC2 import get_df_detalles_ext_FP_C2\n",
    "df_bus_fpbc2_ext = get_df_detalles_ext_FP_C2()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpbc2_ext.to_sql('hi_bus_fpbc2_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpbc2_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpbc2_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59bb5d",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cbc1 detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "883b90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME CBC1 :\n",
    "from CBC1 import get_df_detalles_C_C1\n",
    "df_bus_cbc1 = get_df_detalles_C_C1()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_cbc1.to_sql('hi_bus_cbc1', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_cbc1)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_cbc1.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ffebf",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cbc1 detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "760b7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME CBC1 EXTENDIDO :\n",
    "from CBC1 import get_df_detalles_ext_C_C1\n",
    "df_bus_cbc1_ext = get_df_detalles_ext_C_C1()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_cbc1_ext.to_sql('hi_bus_cbc1_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_cbc1_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_cbc1_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3b2cb",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cbc2 detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "129b3daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 NH0 pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME CBC2 :\n",
    "from CBC2 import get_df_detalles_C_C2\n",
    "df_bus_cbc2 = get_df_detalles_C_C2()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_cbc2.to_sql('hi_bus_cbc2', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_cbc2)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_cbc2.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c06ad7",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cbc2 detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93d497ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 NH0 pF']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME CBC2 EXTENDIDO :\n",
    "from CBC2 import get_df_detalles_ext_C_C2\n",
    "df_bus_cbc2_ext = get_df_detalles_ext_C_C2()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_cbc2_ext.to_sql('hi_bus_cbc2_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_cbc2_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_cbc2_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52f0ff",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cc extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e33ae922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPCOCA :\n",
    "from FPCOCA import get_df_detalles_CC\n",
    "df_bus_fpcoca = get_df_detalles_CC()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpcoca.to_sql('hi_bus_cc', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpcoca)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpcoca.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfafc1",
   "metadata": {},
   "source": [
    "# IMPORTAR hi_bus_cc detallado y extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10848e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME FPCOCA EXTENDIDO :\n",
    "from FPCOCA import get_df_detalles_ext_CC\n",
    "df_bus_fpcoca_ext = get_df_detalles_ext_CC()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_bus_fpcoca_ext.to_sql('hi_bus_cc_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_bus_fpcoca_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_bus_fpcoca_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19677351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12  mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12  mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12  mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUCiex :\n",
    "from NUCiex import get_df_detalles_IEX\n",
    "df_nuc_iex = get_df_detalles_IEX()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_nuc_iex.to_sql('hi_nuc_iex', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_nuc_iex)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc_iex.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3624a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12  mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12  mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12  mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUCiex EXTENDIDO :\n",
    "from NUCiex import get_df_detalles_ext_IEX\n",
    "df_nuc_iex_ext = get_df_detalles_ext_IEX()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_nuc_iex_ext.to_sql('hi_nuc_iex_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_nuc_iex_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc_iex_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89d42159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 16 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUCrnuc :\n",
    "from NUCrnuc import get_df_detalles_RNUC\n",
    "df_nuc_rnuc = get_df_detalles_RNUC()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_nuc_rnuc.to_sql('hi_nuc_rnuc', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_nuc_rnuc)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc_rnuc.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8878c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Éxito! 15764 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME NUCrnuc EXTENDIDO :\n",
    "from NUCrnuc import get_df_detalles_ext_RNUC\n",
    "df_nuc_rnuc_ext = get_df_detalles_ext_RNUC()\n",
    "try:\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "    df_nuc_rnuc_ext.to_sql('hi_nuc_rnuc_extendido', engine, if_exists='replace', index=False, schema='raw_v2',dtype={'FECHA': Date()})\n",
    "    print(f\"¡Éxito! {len(df_nuc_rnuc_ext)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_nuc_rnuc_ext.columns))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
