{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcda64d",
   "metadata": {},
   "source": [
    "### Importación de librerías y dirección del path donde están los scripts de .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c867c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "from sqlalchemy.types import Date\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\")\n",
    "sys.path.append(r\"C:\\Users\\RONALD Q\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca74e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx\n",
      "¡Éxito! 170 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'SUBESTACION', 'CIRCUITO', 'FASE', 'TENSION', 'POT. INSTALADA', 'POT. PLACA', 'RELACION TRANSFORMACION', 'MARCA', 'Año Fab.', 'POTENCIA', 'POS. TAP', 'TENSION TAP']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "# ---------------------------\n",
    "# CARGA DEL ARCHIVO\n",
    "# ---------------------------\n",
    "addresses = [\n",
    "    'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx',\n",
    "    'C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx',\n",
    "    'C:/Users/mticllacu/OneDrive - LUZ DEL SUR S.A.A/Archivos de Ronald Quispe Ocaña - ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in addresses:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_excel(path)\n",
    "        print(f\"✅ Archivo cargado desde: {path}\")\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    raise FileNotFoundError(\"❌ No se encontró el archivo en ninguna de las rutas especificadas.\")\n",
    "df[\"SERIE\"] = df[\"SERIE\"].astype(str)\n",
    "df['SERIE'] = df['SERIE'].astype(str).str.replace(\" \", \"\")\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df.to_sql('bd_detalles', engine, if_exists='replace', index=False, schema='master_v2')\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e7586",
   "metadata": {},
   "source": [
    "### Carga automática de tablas de subíndices (DGA,ACE,AIS,ARR,NUC,OLTC,BUS) a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886751c",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombres de tabla 'hi_<subíndice>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb90b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/DGA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:117: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:125: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  DGA\n",
      "0     D518293 2025-02-07  1.3\n",
      "1     D518293 2023-08-29  1.3\n",
      "2     D518293 2022-06-14  1.3\n",
      "3     D518293 2022-04-28  1.3\n",
      "4     D518293 2021-08-15  1.0\n",
      "...       ...        ...  ...\n",
      "2674   338118 2013-02-11  1.3\n",
      "2675   338118 2011-12-19  1.3\n",
      "2676   338118 2011-11-28  1.0\n",
      "2677   338118 2011-11-21  1.0\n",
      "2678   338118 2011-09-17  1.0\n",
      "\n",
      "[2676 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  DGA\n",
      "634718  V180403 2025-11-06  1.0\n",
      "634719  V180403 2025-11-07  1.0\n",
      "634720  V180403 2025-11-08  1.0\n",
      "634721  V180403 2025-11-09  1.0\n",
      "634722  V180403 2025-11-10  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  DGA   H2   CH4  C2H2  C2H4  C2H6      CO     CO2  \\\n",
      "0  D518293 2025-02-07  1.3  4.0  11.8   1.0   1.0   2.6  1064.6  3681.0   \n",
      "1  D518293 2023-08-29  1.3  3.0   9.0   1.0   1.0   2.0   788.0  3213.0   \n",
      "2  D518293 2022-06-14  1.3  5.0   9.0   1.0   1.0   2.0   758.0  3021.0   \n",
      "3  D518293 2022-04-28  1.3  1.0   8.0   1.0   1.0   2.0   745.0  2942.0   \n",
      "4  D518293 2021-08-15  1.0  7.0   7.0   1.0   1.0   1.0   547.0  2375.0   \n",
      "\n",
      "        O2  \n",
      "0   3372.2  \n",
      "1  10157.0  \n",
      "2   3106.0  \n",
      "3   3837.0  \n",
      "4  11922.0   \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "         SERIE      FECHA  DGA   H2  CH4  C2H2  C2H4  C2H6     CO    CO2  \\\n",
      "19559  123160T 2025-02-08  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19560  123160T 2025-02-09  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19561  123160T 2025-02-10  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19562  123160T 2025-02-11  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "19563  123160T 2025-02-12  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "19564  123160T 2025-02-13  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "\n",
      "            O2  \n",
      "19559      NaN  \n",
      "19560      NaN  \n",
      "19561      NaN  \n",
      "19562  28466.0  \n",
      "19563  28466.0  \n",
      "19564  28466.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/ACE.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:150: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "          SERIE      FECHA       ACE\n",
      "0       D518293 2025-02-07  1.000000\n",
      "1       D518293 2023-08-29  1.000000\n",
      "2       D518293 2022-04-28  1.000000\n",
      "3       D518293 2021-08-15  1.952381\n",
      "4       D518293 2019-04-25  1.000000\n",
      "...         ...        ...       ...\n",
      "2932  230531-01 2005-06-08  5.000000\n",
      "2933  230531-01 2005-05-07  5.000000\n",
      "2934  230531-01 2004-06-08  1.000000\n",
      "2935  230531-01 2004-06-03  1.000000\n",
      "2936  230531-01 2004-06-01  1.000000\n",
      "\n",
      "[2937 rows x 3 columns]\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  ACE\n",
      "0  100138 2015-01-01  NaN\n",
      "1  100138 2015-01-02  NaN\n",
      "2  100138 2015-01-03  NaN\n",
      "3  100138 2015-01-04  NaN\n",
      "4  100138 2015-01-05  NaN\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA       ACE   FP25  FP100    HU    AC   TIF   CO    RD  IO\n",
      "0  D518293 2025-02-07  1.000000  0.002  0.096   6.0  0.00  39.9  0.5  74.0 NaN\n",
      "1  D518293 2023-08-29  1.000000  0.001  0.034   7.0  0.01  39.6  0.5  74.0 NaN\n",
      "2  D518293 2022-04-28  1.000000  0.004  0.080   7.0  0.02  41.3  1.0  71.2 NaN\n",
      "3  D518293 2021-08-15  1.952381  0.007  0.225  14.0  0.02  40.0  0.5  42.0 NaN\n",
      "4  D518293 2019-04-25  1.000000  0.005  0.060   NaN  0.01  45.9  0.5  64.0 NaN\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ACE   FP25  FP100   HU     AC   TIF   CO    RD  IO\n",
      "642679  V180403 2025-11-06  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642680  V180403 2025-11-07  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642681  V180403 2025-11-08  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642682  V180403 2025-11-09  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642683  V180403 2025-11-10  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ROHM\"] = df[score_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:101: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:101: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "            SERIE      FECHA  ROHM\n",
      "0           59571 2016-10-23   1.0\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   1.0\n",
      "3           59572 2016-09-18   5.0\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "341  5337PA196-03 2025-10-20   1.0\n",
      "342  5337PA196-04 2025-10-20   5.0\n",
      "343       P186255 2025-11-02   1.0\n",
      "344       P186256 2025-11-02   5.0\n",
      "345       P186257 2025-11-02   1.0\n",
      "\n",
      "[346 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  ROHM\n",
      "0  123157T 2015-01-01   NaN\n",
      "1  123157T 2015-01-02   NaN\n",
      "2  123157T 2015-01-03   NaN\n",
      "3  123157T 2015-01-04   NaN\n",
      "4  123157T 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "0  59571 2016-10-23   1.0                 NaN          393.230000   \n",
      "1  59571 2006-01-29   NaN                 NaN                 NaN   \n",
      "2  59571 1996-04-16   1.0          420.991013          406.693652   \n",
      "3  59572 2016-09-18   5.0                 NaN          424.407154   \n",
      "4  59572 2006-01-29   NaN                 NaN                 NaN   \n",
      "\n",
      "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ] H POS5 R 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN                NaN   \n",
      "1                 NaN                 NaN                NaN   \n",
      "2          378.146272          406.622639         421.073862   \n",
      "3                 NaN                 NaN                NaN   \n",
      "4                 NaN                 NaN                NaN   \n",
      "\n",
      "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN  ...                  NaN   \n",
      "1                 NaN                 NaN  ...                  NaN   \n",
      "2                 NaN                 NaN  ...                  NaN   \n",
      "3                 NaN                 NaN  ...                  NaN   \n",
      "4                 NaN                 NaN  ...                  NaN   \n",
      "\n",
      "   H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1                  NaN                  NaN                  NaN   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3                  NaN                  NaN                  NaN   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "\n",
      "   X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  X POS1 T 75°C [mΩ]  \\\n",
      "0           28.142000                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2           29.068145                 NaN                 NaN   \n",
      "3           26.451000                 NaN                 NaN   \n",
      "4                 NaN                 NaN                 NaN   \n",
      "\n",
      "   Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  Y POS1 T 75°C [mΩ]  \n",
      "0              15.909                 NaN                 NaN  \n",
      "1                 NaN                 NaN                 NaN  \n",
      "2                 NaN                 NaN                 0.0  \n",
      "3              15.038                 NaN                 NaN  \n",
      "4                 NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "468283  V147103 2025-11-06   1.0             200.209                 NaN   \n",
      "468284  V147103 2025-11-07   1.0             200.209                 NaN   \n",
      "468285  V147103 2025-11-08   1.0             200.209                 NaN   \n",
      "468286  V147103 2025-11-09   1.0             200.209                 NaN   \n",
      "468287  V147103 2025-11-10   1.0             200.209                 NaN   \n",
      "\n",
      "        H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN                 NaN   \n",
      "468284                 NaN                 NaN                 NaN   \n",
      "468285                 NaN                 NaN                 NaN   \n",
      "468286                 NaN                 NaN                 NaN   \n",
      "468287                 NaN                 NaN                 NaN   \n",
      "\n",
      "        H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN  ...                  NaN   \n",
      "468284                 NaN                 NaN  ...                  NaN   \n",
      "468285                 NaN                 NaN  ...                  NaN   \n",
      "468286                 NaN                 NaN  ...                  NaN   \n",
      "468287                 NaN                 NaN  ...                  NaN   \n",
      "\n",
      "        H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "468283                  NaN                  NaN                  NaN   \n",
      "468284                  NaN                  NaN                  NaN   \n",
      "468285                  NaN                  NaN                  NaN   \n",
      "468286                  NaN                  NaN                  NaN   \n",
      "468287                  NaN                  NaN                  NaN   \n",
      "\n",
      "        X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  X POS1 T 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN                 NaN   \n",
      "468284                 NaN                 NaN                 NaN   \n",
      "468285                 NaN                 NaN                 NaN   \n",
      "468286                 NaN                 NaN                 NaN   \n",
      "468287                 NaN                 NaN                 NaN   \n",
      "\n",
      "        Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  Y POS1 T 75°C [mΩ]  \n",
      "468283                 NaN                 NaN                 NaN  \n",
      "468284                 NaN                 NaN                 NaN  \n",
      "468285                 NaN                 NaN                 NaN  \n",
      "468286                 NaN                 NaN                 NaN  \n",
      "468287                 NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"Max_Delta\"] = df[delta_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"RTRA\"] = df[\"Max_Delta\"].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:91: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "            SERIE      FECHA  RTRA\n",
      "0           59571 2016-10-23   1.0\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   1.0\n",
      "3           59572 2016-09-18   1.0\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   1.0\n",
      "384       D518294 2025-06-05   1.0\n",
      "385       D518294 2025-06-05   1.0\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  59571 2016-10-23   1.0         NaN      3.3692         NaN         NaN   \n",
      "1  59571 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "2  59571 1996-04-16   1.0       3.522      3.3621       3.202      3.0414   \n",
      "3  59572 2016-09-18   1.0         NaN      3.3607         NaN         NaN   \n",
      "4  59572 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS23 T  H-Y POS24 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2      2.8818         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \\\n",
      "0          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "1          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "2          NaN          NaN          NaN       3.616         NaN         NaN   \n",
      "3          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "4          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "\n",
      "   TempR  HumR  \n",
      "0    NaN   NaN  \n",
      "1    NaN   NaN  \n",
      "2    NaN   NaN  \n",
      "3    NaN   NaN  \n",
      "4    NaN   NaN  \n",
      "\n",
      "[5 rows x 170 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  100138 2015-01-01   NaN         NaN         NaN         NaN         NaN   \n",
      "1  100138 2015-01-02   NaN         NaN         NaN         NaN         NaN   \n",
      "2  100138 2015-01-03   NaN         NaN         NaN         NaN         NaN   \n",
      "3  100138 2015-01-04   NaN         NaN         NaN         NaN         NaN   \n",
      "4  100138 2015-01-05   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS23 T  H-Y POS24 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \\\n",
      "0          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "1          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "2          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "3          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "4          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "\n",
      "   TempR  HumR  \n",
      "0    NaN   NaN  \n",
      "1    NaN   NaN  \n",
      "2    NaN   NaN  \n",
      "3    NaN   NaN  \n",
      "4    NaN   NaN  \n",
      "\n",
      "[5 rows x 170 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDIS.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_DIS_ext = df_DIS_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS\n",
      "0    59571 2016-10-23   NaN\n",
      "1    59571 2006-01-29   NaN\n",
      "2    59571 1996-04-16   1.0\n",
      "3    59572 2016-09-18   NaN\n",
      "4    59572 2006-01-29   NaN\n",
      "5    59572 1996-04-22   1.0\n",
      "6    59573 2016-09-18   NaN\n",
      "7    59573 2006-01-29   NaN\n",
      "8   146916 2019-06-30   NaN\n",
      "9   146916 2015-01-06   NaN\n",
      "10  146916 2014-11-12   1.0\n",
      "11  146917 2022-05-12   NaN\n",
      "12  146917 2014-12-05   1.0\n",
      "13  146918 2019-07-11   5.0\n",
      "14  146918 2014-11-25   1.0\n",
      "15  185466 2015-11-22   NaN\n",
      "16  185466 2014-09-12   NaN\n",
      "17  185466 2005-10-21   1.0\n",
      "18  185519 2020-06-16   NaN\n",
      "19  185519 2016-07-10   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS\n",
      "0  123157T 2015-01-01   NaN\n",
      "1  123157T 2015-01-02   NaN\n",
      "2  123157T 2015-01-03   NaN\n",
      "3  123157T 2015-01-04   NaN\n",
      "4  123157T 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  RDIS  H-X DOWN [%] ONAF 2  H-X MID [%] ONAF 2  \\\n",
      "0  59571 2016-10-23   NaN                  NaN                 NaN   \n",
      "1  59571 2006-01-29   NaN                  NaN                 NaN   \n",
      "2  59571 1996-04-16   1.0                  NaN                 NaN   \n",
      "3  59572 2016-09-18   NaN                  NaN                 NaN   \n",
      "4  59572 2006-01-29   NaN                  NaN                 NaN   \n",
      "\n",
      "   H-X TOP [%] ONAF 2  H-Y DOWN [%]  H-Y MID [%]  H-Y TOP [%]  X-Y [%]  \n",
      "0                 NaN           NaN          NaN          NaN      NaN  \n",
      "1                 NaN           NaN          NaN          NaN      NaN  \n",
      "2                 NaN         6.725          NaN          NaN    12.23  \n",
      "3                 NaN           NaN          NaN          NaN      NaN  \n",
      "4                 NaN           NaN          NaN          NaN      NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS  H-X DOWN [%] ONAF 2  H-X MID [%] ONAF 2  \\\n",
      "0  123157T 2015-01-01   NaN                  NaN                 NaN   \n",
      "1  123157T 2015-01-02   NaN                  NaN                 NaN   \n",
      "2  123157T 2015-01-03   NaN                  NaN                 NaN   \n",
      "3  123157T 2015-01-04   NaN                  NaN                 NaN   \n",
      "4  123157T 2015-01-05   NaN                  NaN                 NaN   \n",
      "\n",
      "   H-X TOP [%] ONAF 2  H-Y DOWN [%]  H-Y MID [%]  H-Y TOP [%]  X-Y [%]  \n",
      "0                 NaN           NaN          NaN          NaN      NaN  \n",
      "1                 NaN           NaN          NaN          NaN      NaN  \n",
      "2                 NaN           NaN          NaN          NaN      NaN  \n",
      "3                 NaN           NaN          NaN          NaN      NaN  \n",
      "4                 NaN           NaN          NaN          NaN      NaN   \n",
      "\n",
      "     SERIE      FECHA  ARR  ROHM  RTRA  RDIS\n",
      "0   100138 2019-04-17  1.0   NaN   1.0   NaN\n",
      "1  123157T 2019-04-22  NaN   NaN   NaN   NaN\n",
      "2  123157T 2024-07-12  1.0   1.0   NaN   1.0\n",
      "3  123158T 1984-02-21  1.0   NaN   1.0   NaN\n",
      "4  123158T 2021-12-13  5.0   NaN   5.0   NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fp['Max_FP'] = df_fp[[c for c in df_fp.columns if c.endswith('%')]].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[columna_puntaje] = np.select(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP = df_extendida_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP = df_detalles_ext_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPDEVANADO ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  FPDEVANADO\n",
      "383  5337PA196-03 2025-01-19         NaN\n",
      "384       D518294 2025-06-05         NaN\n",
      "385       D518294 2025-06-05         NaN\n",
      "386        359111 2022-12-14         NaN\n",
      "387       L-30230 2023-11-02         NaN \n",
      "\n",
      "\n",
      " ====== TABLA FPDEVANADO EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  FPDEVANADO\n",
      "0  100138 2015-01-01         NaN\n",
      "1  100138 2015-01-02         NaN\n",
      "2  100138 2015-01-03         NaN\n",
      "3  100138 2015-01-04         NaN\n",
      "4  100138 2015-01-05         NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPDEVANADO ====== \n",
      "\n",
      "   SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  X ICL+ICLT %  \\\n",
      "0  59571 2016-10-23           NaN    0.260     0.200       NaN           NaN   \n",
      "1  59571 2006-01-29          0.22    0.230     0.170       NaN           NaN   \n",
      "2  59571 1996-04-16          0.12    0.122     0.104       NaN           NaN   \n",
      "3  59572 2016-09-18           NaN    0.210     0.150       NaN           NaN   \n",
      "4  59572 2006-01-29          0.21    0.210     0.150       NaN           NaN   \n",
      "\n",
      "   X ICL %  X ICLT %  X ICLH %  Y ICT+ICTH %  Y ICT %  Y ICTH %  Y ICTL %  \\\n",
      "0    0.210       NaN       NaN          0.18     0.14      0.19       NaN   \n",
      "1    0.190       NaN       NaN          0.17     0.13      0.17       NaN   \n",
      "2    0.139       NaN       NaN           NaN      NaN       NaN       NaN   \n",
      "3    0.180       NaN       NaN          0.15     0.11      0.15       NaN   \n",
      "4    0.170       NaN       NaN          0.17     0.12      0.15       NaN   \n",
      "\n",
      "   FPDEVANADO  \n",
      "0         1.0  \n",
      "1         1.0  \n",
      "2         1.0  \n",
      "3         1.0  \n",
      "4         1.0   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPDEVANADO ====== \n",
      "\n",
      "          SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  \\\n",
      "511814  V147103 2025-11-06           NaN      NaN       NaN       NaN   \n",
      "511815  V147103 2025-11-07           NaN      NaN       NaN       NaN   \n",
      "511816  V147103 2025-11-08           NaN      NaN       NaN       NaN   \n",
      "511817  V147103 2025-11-09           NaN      NaN       NaN       NaN   \n",
      "511818  V147103 2025-11-10           NaN      NaN       NaN       NaN   \n",
      "\n",
      "        X ICL+ICLT %  X ICL %  X ICLT %  X ICLH %  Y ICT+ICTH %  Y ICT %  \\\n",
      "511814           NaN      NaN       NaN       NaN           NaN      NaN   \n",
      "511815           NaN      NaN       NaN       NaN           NaN      NaN   \n",
      "511816           NaN      NaN       NaN       NaN           NaN      NaN   \n",
      "511817           NaN      NaN       NaN       NaN           NaN      NaN   \n",
      "511818           NaN      NaN       NaN       NaN           NaN      NaN   \n",
      "\n",
      "        Y ICTH %  Y ICTL %  FPDEVANADO  \n",
      "511814       NaN       NaN         NaN  \n",
      "511815       NaN       NaN         NaN  \n",
      "511816       NaN       NaN         NaN  \n",
      "511817       NaN       NaN         NaN  \n",
      "511818       NaN       NaN         NaN   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:95: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CD = df_extendida_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:103: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CD = df_detalles_ext_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CD ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA   CD\n",
      "0           59571 2016-10-23  5.0\n",
      "1           59571 2006-01-29  5.0\n",
      "2           59571 1996-04-16  1.0\n",
      "3           59572 2016-09-18  NaN\n",
      "4           59572 2006-01-29  NaN\n",
      "..            ...        ...  ...\n",
      "383  5337PA196-03 2025-01-19  NaN\n",
      "384       D518294 2025-06-05  NaN\n",
      "385       D518294 2025-06-05  NaN\n",
      "386        359111 2022-12-14  NaN\n",
      "387       L-30230 2023-11-02  NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CD EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CD\n",
      "0  100138 2015-01-01 NaN\n",
      "1  100138 2015-01-02 NaN\n",
      "2  100138 2015-01-03 NaN\n",
      "3  100138 2015-01-04 NaN\n",
      "4  100138 2015-01-05 NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CD ====== \n",
      "\n",
      "   SERIE      FECHA   CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  H ICHT pF  \\\n",
      "0  59571 2016-10-23  5.0         3802.9    1553.5     2249.5        NaN   \n",
      "1  59571 2006-01-29  5.0         3786.3    1546.1     2240.2        NaN   \n",
      "2  59571 1996-04-16  1.0        11300.0    6497.0     2200.0        NaN   \n",
      "3  59572 2016-09-18  NaN         3757.2    1570.5     2185.9        NaN   \n",
      "4  59572 2006-01-29  NaN         3740.8    1562.9     2176.6        NaN   \n",
      "\n",
      "   X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  Y ICT+ICTH pF  Y ICT pF  \\\n",
      "0         4830.8    4820.3      10.40        NaN         6640.2    1587.9   \n",
      "1         4814.2    4803.3      10.15        NaN         6604.2    1570.6   \n",
      "2            NaN    4900.0        NaN        NaN            NaN       NaN   \n",
      "3         4711.7    4701.1       9.84        NaN         6621.4    1605.4   \n",
      "4         4688.7    4678.6      10.02        NaN         6586.6    1593.1   \n",
      "\n",
      "   Y ICTH pF  Y ICTL pF  \n",
      "0     5052.9        NaN  \n",
      "1     5031.1        NaN  \n",
      "2        NaN        NaN  \n",
      "3     5014.7        NaN  \n",
      "4     4991.4        NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CD ====== \n",
      "\n",
      "          SERIE      FECHA  CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  H ICHT pF  \\\n",
      "511814  V147103 2025-11-06 NaN            NaN       NaN        NaN        NaN   \n",
      "511815  V147103 2025-11-07 NaN            NaN       NaN        NaN        NaN   \n",
      "511816  V147103 2025-11-08 NaN            NaN       NaN        NaN        NaN   \n",
      "511817  V147103 2025-11-09 NaN            NaN       NaN        NaN        NaN   \n",
      "511818  V147103 2025-11-10 NaN            NaN       NaN        NaN        NaN   \n",
      "\n",
      "        X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  Y ICT+ICTH pF  \\\n",
      "511814            NaN       NaN        NaN        NaN            NaN   \n",
      "511815            NaN       NaN        NaN        NaN            NaN   \n",
      "511816            NaN       NaN        NaN        NaN            NaN   \n",
      "511817            NaN       NaN        NaN        NaN            NaN   \n",
      "511818            NaN       NaN        NaN        NaN            NaN   \n",
      "\n",
      "        Y ICT pF  Y ICTH pF  Y ICTL pF  \n",
      "511814       NaN        NaN        NaN  \n",
      "511815       NaN        NaN        NaN  \n",
      "511816       NaN        NaN        NaN  \n",
      "511817       NaN        NaN        NaN  \n",
      "511818       NaN        NaN        NaN   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FURANOS.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:74: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FUR = df_extendida_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:85: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles_FUR = df_extendida_detalles_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  FUR\n",
      "0      D518293 2023-08-29  1.0\n",
      "1      D518292 2023-08-29  1.0\n",
      "2      D518291 2023-08-29  1.0\n",
      "3      V101038 2023-09-03  1.0\n",
      "4       551873 2023-12-05  1.0\n",
      "..         ...        ...  ...\n",
      "128   132006T1 2020-01-01  1.0\n",
      "129    123158T 2023-07-18  1.0\n",
      "130    L-30436 2023-10-23  1.0\n",
      "131    123160T 2009-06-02  4.0\n",
      "132  750005-01 2018-08-02  1.0\n",
      "\n",
      "[133 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  FUR\n",
      "0        100138 2015-01-01  NaN\n",
      "1        100138 2015-01-02  NaN\n",
      "2        100138 2015-01-03  NaN\n",
      "3        100138 2015-01-04  NaN\n",
      "4        100138 2015-01-05  NaN\n",
      "...         ...        ...  ...\n",
      "527606  V180403 2025-11-06  1.0\n",
      "527607  V180403 2025-11-07  1.0\n",
      "527608  V180403 2025-11-08  1.0\n",
      "527609  V180403 2025-11-09  1.0\n",
      "527610  V180403 2025-11-10  1.0\n",
      "\n",
      "[527611 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0      D518293 2023-08-29                          1.0  1.0\n",
      "1      D518292 2023-08-29                          1.0  1.0\n",
      "2      D518291 2023-08-29                          1.0  1.0\n",
      "3      V101038 2023-09-03                          1.0  1.0\n",
      "4       551873 2023-12-05                          1.0  1.0\n",
      "..         ...        ...                          ...  ...\n",
      "128   132006T1 2020-01-01                          1.0  1.0\n",
      "129    123158T 2023-07-18                          1.0  1.0\n",
      "130    L-30436 2023-10-23                         87.0  1.0\n",
      "131    123160T 2009-06-02                       3330.0  4.0\n",
      "132  750005-01 2018-08-02                         25.0  1.0\n",
      "\n",
      "[133 rows x 4 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0        100138 2015-01-01                          NaN  NaN\n",
      "1        100138 2015-01-02                          NaN  NaN\n",
      "2        100138 2015-01-03                          NaN  NaN\n",
      "3        100138 2015-01-04                          NaN  NaN\n",
      "4        100138 2015-01-05                          NaN  NaN\n",
      "...         ...        ...                          ...  ...\n",
      "527606  V180403 2025-11-06                          1.0  1.0\n",
      "527607  V180403 2025-11-07                          1.0  1.0\n",
      "527608  V180403 2025-11-08                          1.0  1.0\n",
      "527609  V180403 2025-11-09                          1.0  1.0\n",
      "527610  V180403 2025-11-10                          1.0  1.0\n",
      "\n",
      "[527611 rows x 4 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/ECC.xlsx\n",
      "         SERIE      FECHA  EAC\n",
      "0     146660T3 2025-02-07  NaN\n",
      "1       364076 2021-08-15  NaN\n",
      "2    230531-01 2025-03-13  NaN\n",
      "3       338118 2025-03-25  NaN\n",
      "4      D518293 2025-03-25  NaN\n",
      "..         ...        ...  ...\n",
      "162    L-30300 2025-09-03  NaN\n",
      "163    L-30436 2025-09-04  NaN\n",
      "164  750005-01 2025-09-05  NaN\n",
      "165    L-30229 2025-09-06  NaN\n",
      "166    123160T 2025-09-07  NaN\n",
      "\n",
      "[167 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ECC.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ECC.py:89: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  ECC\n",
      "0     146660T3 2025-02-07  NaN\n",
      "1       364076 2021-08-15  NaN\n",
      "2    230531-01 2025-03-13  NaN\n",
      "3       338118 2025-03-25  NaN\n",
      "4      D518293 2025-03-25  NaN\n",
      "..         ...        ...  ...\n",
      "162    L-30300 2025-09-03  NaN\n",
      "163    L-30436 2025-09-04  NaN\n",
      "164  750005-01 2025-09-05  NaN\n",
      "165    L-30229 2025-09-06  NaN\n",
      "166    123160T 2025-09-07  NaN\n",
      "\n",
      "[167 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ECC\n",
      "662484  V180403 2025-11-06  NaN\n",
      "662485  V180403 2025-11-07  NaN\n",
      "662486  V180403 2025-11-08  NaN\n",
      "662487  V180403 2025-11-09  NaN\n",
      "662488  V180403 2025-11-10  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE ECC CON FECHAS ORIGINALES ====== \n",
      "\n",
      "       SERIE      FECHA  ECC  EAC\n",
      "0   146660T3 2025-02-07  NaN  NaN\n",
      "1     364076 2021-08-15  NaN  NaN\n",
      "2  230531-01 2025-03-13  NaN  NaN\n",
      "3     338118 2025-03-25  NaN  NaN\n",
      "4    D518293 2025-03-25  NaN  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE ECC CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ECC  EAC\n",
      "400657  D518293 2025-11-01  NaN  NaN\n",
      "400658  D518293 2025-11-02  NaN  NaN\n",
      "400659  D518293 2025-11-03  NaN  NaN\n",
      "400660  D518293 2025-11-04  NaN  NaN\n",
      "400661  D518293 2025-11-05  NaN  NaN\n",
      "400662  D518293 2025-11-06  NaN  NaN\n",
      "400663  D518293 2025-11-07  NaN  NaN\n",
      "400664  D518293 2025-11-08  NaN  NaN\n",
      "400665  D518293 2025-11-09  NaN  NaN\n",
      "400666  D518293 2025-11-10  NaN  NaN\n",
      "      SERIE      FECHA       AIS  FPDEVANADO   CD  FUR  ECC\n",
      "7   123158T 1984-02-21  1.000000         1.0  1.0  NaN  NaN\n",
      "8   123158T 2021-12-13  2.200000         1.0  3.0  NaN  NaN\n",
      "9   123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "10  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "11  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "12  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "13  123158T 2023-07-18  1.857143         1.0  3.0  1.0  NaN\n",
      "14  123158T 2025-09-02  1.857143         1.0  3.0  1.0  NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RNUCLEO.xlsx\n",
      "        SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0    146660T3 2022-05-12   NaN         NaN\n",
      "1    146660T3 2019-01-23   NaN         NaN\n",
      "2    146660T3 2018-02-05   NaN         NaN\n",
      "3    146660T3 2017-11-22   NaN         NaN\n",
      "4      364076 2022-06-18   NaN         NaN\n",
      "5      364076 2015-05-24   NaN         NaN\n",
      "6      364076 2014-08-13   NaN         NaN\n",
      "7      364076 2013-11-05   NaN         NaN\n",
      "8   230531-01 2024-07-16   NaN         NaN\n",
      "9   230531-01 2017-10-26   NaN         NaN\n",
      "10  230531-01 2016-03-04   NaN         NaN\n",
      "11  230531-01 2014-11-11   NaN         NaN\n",
      "12     338118 2024-11-13   NaN         NaN\n",
      "13     338118 2017-12-13   NaN         NaN\n",
      "14     338118 2016-09-05   NaN         NaN\n",
      "15     338118 2014-05-28   NaN         NaN\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  RNUC\n",
      "0    146660T3 2022-05-12   NaN\n",
      "1    146660T3 2019-01-23   NaN\n",
      "2    146660T3 2018-02-05   NaN\n",
      "3    146660T3 2017-11-22   NaN\n",
      "4      364076 2022-06-18   NaN\n",
      "5      364076 2015-05-24   NaN\n",
      "6      364076 2014-08-13   NaN\n",
      "7      364076 2013-11-05   NaN\n",
      "8   230531-01 2024-07-16   NaN\n",
      "9   230531-01 2017-10-26   NaN\n",
      "10  230531-01 2016-03-04   NaN\n",
      "11  230531-01 2014-11-11   NaN\n",
      "12     338118 2024-11-13   NaN\n",
      "13     338118 2017-12-13   NaN\n",
      "14     338118 2016-09-05   NaN\n",
      "15     338118 2014-05-28   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2022-05-12   NaN         NaN\n",
      "1  146660T3 2019-01-23   NaN         NaN\n",
      "2  146660T3 2018-02-05   NaN         NaN\n",
      "3  146660T3 2017-11-22   NaN         NaN\n",
      "4    364076 2022-06-18   NaN         NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2015-01-01   NaN         NaN\n",
      "1  146660T3 2015-01-02   NaN         NaN\n",
      "2  146660T3 2015-01-03   NaN         NaN\n",
      "3  146660T3 2015-01-04   NaN         NaN\n",
      "4  146660T3 2015-01-05   NaN         NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/IEXCITACION.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:57: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_RNUC_ext = df_RNUC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:69: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:74: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_IEX_ext = df_IEX_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  IEX\n",
      "0    59571 2016-10-23    1\n",
      "1    59571 2006-01-29    1\n",
      "2    59571 1996-04-16    1\n",
      "3    59572 2016-09-18    1\n",
      "4    59572 2006-01-29    1\n",
      "5    59572 1996-04-22    1\n",
      "6    59573 2016-09-18    1\n",
      "7    59573 2006-01-29    1\n",
      "8   146916 2019-06-30    1\n",
      "9   146916 2015-01-06    1\n",
      "10  146916 2014-11-12    1\n",
      "11  146917 2022-05-12    1\n",
      "12  146917 2014-12-05    1\n",
      "13  146918 2019-07-11    5\n",
      "14  146918 2014-11-25    1\n",
      "15  185466 2015-11-22    1\n",
      "16  185466 2014-09-12    1\n",
      "17  185466 2005-10-21    1\n",
      "18  185519 2020-06-16    1\n",
      "19  185519 2016-07-10    1 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  IEX\n",
      "511814  V147103 2025-11-06  1.0\n",
      "511815  V147103 2025-11-07  1.0\n",
      "511816  V147103 2025-11-08  1.0\n",
      "511817  V147103 2025-11-09  1.0\n",
      "511818  V147103 2025-11-10  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  59571 2016-10-23    1        NaN     68.167        NaN        NaN   \n",
      "1  59571 2006-01-29    1     61.932        NaN        NaN        NaN   \n",
      "2  59571 1996-04-16    1        NaN        NaN        NaN        NaN   \n",
      "3  59572 2016-09-18    1        NaN        NaN        NaN        NaN   \n",
      "4  59572 2006-01-29    1        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   T POS27 mA  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  100138 2015-01-01  NaN        NaN        NaN        NaN        NaN   \n",
      "1  100138 2015-01-02  NaN        NaN        NaN        NaN        NaN   \n",
      "2  100138 2015-01-03  NaN        NaN        NaN        NaN        NaN   \n",
      "3  100138 2015-01-04  NaN        NaN        NaN        NaN        NaN   \n",
      "4  100138 2015-01-05  NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   T POS27 mA  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "     SERIE      FECHA  NUC  RNUC  IEX\n",
      "0   100138 2019-04-17  1.0   NaN  1.0\n",
      "1  123157T 2019-04-22  1.0   NaN  1.0\n",
      "2  123157T 2024-07-12  5.0   NaN  5.0\n",
      "3  123158T 1984-02-21  1.0   NaN  1.0\n",
      "4  123158T 2021-12-13  1.0   NaN  1.0\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FQOLTC.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2022-05-12   NaN\n",
      "1  146660T3 2018-05-12   NaN\n",
      "2  146660T3 2016-12-30   NaN\n",
      "3  146660T3 2014-03-26   NaN\n",
      "4    364076 2022-06-18   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC  RD  H20\n",
      "0  146660T3 2022-05-12   NaN NaN  NaN\n",
      "1  146660T3 2018-05-12   NaN NaN  NaN\n",
      "2  146660T3 2016-12-30   NaN NaN  NaN\n",
      "3  146660T3 2014-03-26   NaN NaN  NaN\n",
      "4    364076 2022-06-18   NaN NaN  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC  RD  H20\n",
      "0  146660T3 2015-01-01   NaN NaN  NaN\n",
      "1  146660T3 2015-01-02   NaN NaN  NaN\n",
      "2  146660T3 2015-01-03   NaN NaN  NaN\n",
      "3  146660T3 2015-01-04   NaN NaN  NaN\n",
      "4  146660T3 2015-01-05   NaN NaN  NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:81: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_OLTC_ext = df_OLTC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:89: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C1 = df_extendida_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:99: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C1 = df_detalles_ext_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPBC1 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  FPBC1\n",
      "383  5337PA196-03 2025-01-19    NaN\n",
      "384       D518294 2025-06-05    NaN\n",
      "385       D518294 2025-06-05    NaN\n",
      "386        359111 2022-12-14    NaN\n",
      "387       L-30230 2023-11-02    NaN \n",
      "\n",
      "\n",
      " ====== TABLA FPBC1 EXTENDIDA ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC1\n",
      "511814  V147103 2025-11-06    NaN\n",
      "511815  V147103 2025-11-07    NaN\n",
      "511816  V147103 2025-11-08    NaN\n",
      "511817  V147103 2025-11-09    NaN\n",
      "511818  V147103 2025-11-10    NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC1 ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "0  59571 2016-10-23    1.0     0.34      NaN      NaN     0.37\n",
      "1  59571 2006-01-29    1.0     0.36      NaN      NaN     0.40\n",
      "2  59571 1996-04-16    NaN      NaN      NaN      NaN      NaN\n",
      "3  59572 2016-09-18    NaN      NaN      NaN      NaN      NaN\n",
      "4  59572 2006-01-29    1.0     0.37      NaN      NaN     0.34 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC1 ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "511814  V147103 2025-11-06    NaN      NaN      NaN      NaN      NaN\n",
      "511815  V147103 2025-11-07    NaN      NaN      NaN      NaN      NaN\n",
      "511816  V147103 2025-11-08    NaN      NaN      NaN      NaN      NaN\n",
      "511817  V147103 2025-11-09    NaN      NaN      NaN      NaN      NaN\n",
      "511818  V147103 2025-11-10    NaN      NaN      NaN      NaN      NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:90: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C2 = df_extendida_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:98: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C2 = df_detalles_ext_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPBC2 ORIGINAL ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC2\n",
      "0  59571 2016-10-23    5.0\n",
      "1  59571 2006-01-29    1.0\n",
      "2  59571 1996-04-16    NaN\n",
      "3  59572 2016-09-18    NaN\n",
      "4  59572 2006-01-29    1.0 \n",
      "\n",
      "\n",
      " ====== TABLA FPBC2 EXTENDIDA ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC2\n",
      "511814  V147103 2025-11-06    NaN\n",
      "511815  V147103 2025-11-07    NaN\n",
      "511816  V147103 2025-11-08    NaN\n",
      "511817  V147103 2025-11-09    NaN\n",
      "511818  V147103 2025-11-10    NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC2 ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "0  59571 2016-10-23    5.0     0.21      NaN      NaN     6.33\n",
      "1  59571 2006-01-29    1.0     0.19      NaN      NaN     0.25\n",
      "2  59571 1996-04-16    NaN      NaN      NaN      NaN      NaN\n",
      "3  59572 2016-09-18    NaN      NaN      NaN      NaN      NaN\n",
      "4  59572 2006-01-29    1.0     0.21      NaN      NaN     0.26 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC2 ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "511814  V147103 2025-11-06    NaN      NaN      NaN      NaN      NaN\n",
      "511815  V147103 2025-11-07    NaN      NaN      NaN      NaN      NaN\n",
      "511816  V147103 2025-11-08    NaN      NaN      NaN      NaN      NaN\n",
      "511817  V147103 2025-11-09    NaN      NaN      NaN      NaN      NaN\n",
      "511818  V147103 2025-11-10    NaN      NaN      NaN      NaN      NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C1 = df_extendida_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:113: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C1 = df_detalles_ext_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CBC1 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  CBC1\n",
      "0           59571 2016-10-23   NaN\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   NaN\n",
      "3           59572 2016-09-18   NaN\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   NaN\n",
      "384       D518294 2025-06-05   NaN\n",
      "385       D518294 2025-06-05   NaN\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CBC1 EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CBC1\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC1 ====== \n",
      "\n",
      "   SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "0  59571 2016-10-23   NaN    280.25       NaN       NaN    190.91\n",
      "1  59571 2006-01-29   NaN    281.20       NaN       NaN    191.80\n",
      "2  59571 1996-04-16   NaN       NaN       NaN       NaN       NaN\n",
      "3  59572 2016-09-18   NaN       NaN       NaN       NaN       NaN\n",
      "4  59572 2006-01-29   NaN    288.10       NaN       NaN    192.50 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC1 ====== \n",
      "\n",
      "          SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "511814  V147103 2025-11-06   NaN       NaN       NaN       NaN       NaN\n",
      "511815  V147103 2025-11-07   NaN       NaN       NaN       NaN       NaN\n",
      "511816  V147103 2025-11-08   NaN       NaN       NaN       NaN       NaN\n",
      "511817  V147103 2025-11-09   NaN       NaN       NaN       NaN       NaN\n",
      "511818  V147103 2025-11-10   NaN       NaN       NaN       NaN       NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C2 = df_extendida_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:112: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C2 = df_detalles_ext_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CBC2 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  CBC2\n",
      "0           59571 2016-10-23   NaN\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   NaN\n",
      "3           59572 2016-09-18   NaN\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   NaN\n",
      "384       D518294 2025-06-05   NaN\n",
      "385       D518294 2025-06-05   NaN\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CBC2 EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CBC2\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC2 ====== \n",
      "\n",
      "   SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 H0 pF\n",
      "0  59571 2016-10-23   NaN    1114.5       NaN       NaN    373.17\n",
      "1  59571 2006-01-29   NaN    1053.0       NaN       NaN    360.60\n",
      "2  59571 1996-04-16   NaN       NaN       NaN       NaN       NaN\n",
      "3  59572 2016-09-18   NaN       NaN       NaN       NaN       NaN\n",
      "4  59572 2006-01-29   NaN    1072.0       NaN       NaN    353.60 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC2 ====== \n",
      "\n",
      "    SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 H0 pF\n",
      "0  100138 2015-01-01   NaN       NaN       NaN       NaN       NaN\n",
      "1  100138 2015-01-02   NaN       NaN       NaN       NaN       NaN\n",
      "2  100138 2015-01-03   NaN       NaN       NaN       NaN       NaN\n",
      "3  100138 2015-01-04   NaN       NaN       NaN       NaN       NaN\n",
      "4  100138 2015-01-05   NaN       NaN       NaN       NaN       NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPCOCA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:79: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CC = df_extendida_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CC = df_detalles_ext_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CC ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA   CC\n",
      "0           59571 2016-10-23  1.0\n",
      "1           59571 2006-01-29  NaN\n",
      "2           59571 1996-04-16  NaN\n",
      "3           59572 2016-09-18  NaN\n",
      "4           59572 2006-01-29  NaN\n",
      "..            ...        ...  ...\n",
      "383  5337PA196-03 2025-01-19  NaN\n",
      "384       D518294 2025-06-05  NaN\n",
      "385       D518294 2025-06-05  NaN\n",
      "386        359111 2022-12-14  NaN\n",
      "387       L-30230 2023-11-02  NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CC EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CC\n",
      "0  100138 2015-01-01 NaN\n",
      "1  100138 2015-01-02 NaN\n",
      "2  100138 2015-01-03 NaN\n",
      "3  100138 2015-01-04 NaN\n",
      "4  100138 2015-01-05 NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CC ====== \n",
      "\n",
      "   SERIE      FECHA   CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  Y3 mW  \\\n",
      "0  59571 2016-10-23  1.0   15.0    NaN    NaN    NaN   17.0    NaN    NaN   \n",
      "1  59571 2006-01-29  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2  59571 1996-04-16  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3  59572 2016-09-18  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4  59572 2006-01-29  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   Y0 mW  TempR  HumR  \n",
      "0    NaN    NaN   NaN  \n",
      "1    NaN    NaN   NaN  \n",
      "2    NaN    NaN   NaN  \n",
      "3    NaN    NaN   NaN  \n",
      "4    NaN    NaN   NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CC ====== \n",
      "\n",
      "          SERIE      FECHA  CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  \\\n",
      "511814  V147103 2025-11-06 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511815  V147103 2025-11-07 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511816  V147103 2025-11-08 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511817  V147103 2025-11-09 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511818  V147103 2025-11-10 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "        Y3 mW  Y0 mW  TempR  HumR  \n",
      "511814    NaN    NaN    NaN   NaN  \n",
      "511815    NaN    NaN    NaN   NaN  \n",
      "511816    NaN    NaN    NaN   NaN  \n",
      "511817    NaN    NaN    NaN   NaN  \n",
      "511818    NaN    NaN    NaN   NaN   \n",
      "\n",
      "        SERIE      FECHA       BUS  FPBC1  FPBC2  CBC1  CBC2   CC\n",
      "4463  V101042 2022-11-14  1.000000    1.0    1.0   NaN   NaN  1.0\n",
      "4464  V101044 2019-06-21  2.176471    1.0    5.0   1.0   1.0  5.0\n",
      "4465  V147101 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "4466  V147102 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "4467  V147103 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "✅ ¡Éxito! 2682 registros importados a hi_dga\n",
      "   Columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n",
      "✅ ¡Éxito! 3007 registros importados a hi_ace\n",
      "   Columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n",
      "✅ ¡Éxito! 574 registros importados a hi_arr\n",
      "   Columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "✅ ¡Éxito! 863 registros importados a hi_ais\n",
      "   Columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR', 'ECC']\n",
      "✅ ¡Éxito! 404 registros importados a hi_nuc\n",
      "   Columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "✅ ¡Éxito! 16 registros importados a hi_oltc\n",
      "   Columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n",
      "✅ ¡Éxito! 4468 registros importados a hi_bus\n",
      "   Columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ Definir módulos y funciones\n",
    "# ================================\n",
    "from DGA import get_df_detalles_DGA\n",
    "from ACE import get_df_detalles_ACE\n",
    "from ARR import get_df_detalles_ARR\n",
    "from AIS import get_df_detalles_AIS\n",
    "from NUC import get_df_detalles_NUC\n",
    "from OLTC import get_df_detalles_OLTC\n",
    "from BUS import get_df_detalles_BUS\n",
    "\n",
    "# Diccionario con las funciones de obtención de DataFrames\n",
    "data_sources = {\n",
    "    \"dga\": get_df_detalles_DGA,\n",
    "    \"ace\": get_df_detalles_ACE,\n",
    "    \"arr\": get_df_detalles_ARR,\n",
    "    \"ais\": get_df_detalles_AIS,\n",
    "    \"nuc\": get_df_detalles_NUC,\n",
    "    \"oltc\": get_df_detalles_OLTC,\n",
    "    \"bus\": get_df_detalles_BUS,\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ Conexión SQL\n",
    "# ================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ Cargar todos los DataFrames\n",
    "# ================================\n",
    "for name, func in data_sources.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            f\"hi_{name}\", \n",
    "            engine, \n",
    "            if_exists='replace', \n",
    "            index=False, \n",
    "            schema='raw_v2',\n",
    "            dtype={'FECHA': Date()}\n",
    "        )\n",
    "        print(f\"✅ ¡Éxito! {len(df)} registros importados a hi_{name}\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d54387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# from sqlalchemy import create_engine, Date, text\n",
    "# import pandas as pd\n",
    "\n",
    "# # ================================\n",
    "# # 1️⃣ Definir módulos y funciones\n",
    "# # ================================\n",
    "# from DGA import get_df_detalles_DGA\n",
    "# from ACE import get_df_detalles_ACE\n",
    "# from ARR import get_df_detalles_ARR\n",
    "# from AIS import get_df_detalles_AIS\n",
    "# from NUC import get_df_detalles_NUC\n",
    "# from OLTC import get_df_detalles_OLTC\n",
    "# from BUS import get_df_detalles_BUS\n",
    "\n",
    "# # Diccionario con las funciones de obtención de DataFrames\n",
    "# data_sources = {\n",
    "#     \"dga\": get_df_detalles_DGA,\n",
    "#     \"ace\": get_df_detalles_ACE,\n",
    "#     \"arr\": get_df_detalles_ARR,\n",
    "#     \"ais\": get_df_detalles_AIS,\n",
    "#     \"nuc\": get_df_detalles_NUC,\n",
    "#     \"oltc\": get_df_detalles_OLTC,\n",
    "#     \"bus\": get_df_detalles_BUS,\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # 2️⃣ Conexión SQL\n",
    "# # ================================\n",
    "# password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "# engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "\n",
    "# # ================================\n",
    "# # 3️⃣ Cargar solo datos nuevos por SERIE\n",
    "# # ================================\n",
    "# for name, func in data_sources.items():\n",
    "#     try:\n",
    "#         df = func()\n",
    "#         table_name = f\"hi_{name}\"\n",
    "#         schema_name = \"raw_v2\"\n",
    "\n",
    "#         with engine.connect() as conn:\n",
    "#             # Verificar si la tabla existe\n",
    "#             check_table = conn.execute(text(f\"\"\"\n",
    "#                 SELECT EXISTS (\n",
    "#                     SELECT FROM information_schema.tables \n",
    "#                     WHERE table_schema = :schema AND table_name = :table\n",
    "#                 )\n",
    "#             \"\"\"), {\"schema\": schema_name, \"table\": table_name}).scalar()\n",
    "\n",
    "#             if check_table:\n",
    "#                 # Obtener todas las series existentes\n",
    "#                 series_existentes = conn.execute(text(f\"\"\"\n",
    "#                     SELECT DISTINCT \"SERIE\" FROM {schema_name}.{table_name}\n",
    "#                 \"\"\"))\n",
    "#                 series_existentes = [row[0] for row in series_existentes]\n",
    "\n",
    "#                 nuevos_registros = pd.DataFrame()\n",
    "\n",
    "#                 for serie in df[\"SERIE\"].unique():\n",
    "#                     df_serie = df[df[\"SERIE\"] == serie]\n",
    "#                     if serie in series_existentes:\n",
    "#                         max_fecha = conn.execute(text(f\"\"\"\n",
    "#                             SELECT MAX(\"FECHA\") FROM {schema_name}.{table_name} WHERE \"SERIE\" = :serie\n",
    "#                         \"\"\"), {\"serie\": serie}).scalar()\n",
    "#                         df_serie = df_serie[df_serie[\"FECHA\"] > pd.to_datetime(max_fecha)]\n",
    "#                     nuevos_registros = pd.concat([nuevos_registros, df_serie], ignore_index=True)\n",
    "\n",
    "#                 if not nuevos_registros.empty:\n",
    "#                     nuevos_registros.to_sql(\n",
    "#                         table_name,\n",
    "#                         engine,\n",
    "#                         if_exists='append',\n",
    "#                         index=False,\n",
    "#                         schema=schema_name,\n",
    "#                         dtype={'FECHA': Date()}\n",
    "#                     )\n",
    "#                     print(f\"✅ {len(nuevos_registros)} registros nuevos añadidos a {table_name}\")\n",
    "#                 else:\n",
    "#                     print(f\"ℹ️ No hay registros nuevos para {table_name}\")\n",
    "#             else:\n",
    "#                 # Si la tabla no existe, crearla con todos los datos\n",
    "#                 df.to_sql(\n",
    "#                     table_name,\n",
    "#                     engine,\n",
    "#                     if_exists='replace',\n",
    "#                     index=False,\n",
    "#                     schema=schema_name,\n",
    "#                     dtype={'FECHA': Date()}\n",
    "#                 )\n",
    "#                 print(f\"🆕 Tabla {table_name} creada con {len(df)} registros\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b037848",
   "metadata": {},
   "source": [
    "### Carga automática de tablas de subíndices (DGA,ACE,AIS,ARR,NUC,OLTC,BUS) extendidos a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9e53b",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombres de tabla 'hi_<subíndice>_extendido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b87ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ¡Éxito! 634729 registros importados a hi_dga_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n",
      "✅ ¡Éxito! 642684 registros importados a hi_ace_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n",
      "✅ ¡Éxito! 511969 registros importados a hi_arr_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "✅ ¡Éxito! 674632 registros importados a hi_ais_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR', 'ECC']\n",
      "✅ ¡Éxito! 511819 registros importados a hi_nuc_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "✅ ¡Éxito! 15868 registros importados a hi_oltc_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n",
      "✅ ¡Éxito! 515749 registros importados a hi_bus_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ Importar funciones extendidas\n",
    "# ================================\n",
    "from DGA import get_df_detalles_ext_DGA\n",
    "from ACE import get_df_detalles_ext_ACE\n",
    "from ARR import get_df_detalles_ext_ARR\n",
    "from AIS import get_df_detalles_ext_AIS\n",
    "from NUC import get_df_detalles_ext_NUC\n",
    "from OLTC import get_df_detalles_ext_OLTC\n",
    "from BUS import get_df_detalles_ext_BUS\n",
    "\n",
    "# Diccionario con las funciones extendidas\n",
    "data_sources_ext = {\n",
    "    \"dga_extendido\": get_df_detalles_ext_DGA,\n",
    "    \"ace_extendido\": get_df_detalles_ext_ACE,\n",
    "    \"arr_extendido\": get_df_detalles_ext_ARR,\n",
    "    \"ais_extendido\": get_df_detalles_ext_AIS,\n",
    "    \"nuc_extendido\": get_df_detalles_ext_NUC,\n",
    "    \"oltc_extendido\": get_df_detalles_ext_OLTC,\n",
    "    \"bus_extendido\": get_df_detalles_ext_BUS,\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ Conexión SQL\n",
    "# ================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ Cargar todos los DataFrames extendidos\n",
    "# ================================\n",
    "for name, func in data_sources_ext.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            f\"hi_{name}\",\n",
    "            engine,\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            schema='raw_v2',\n",
    "            dtype={'FECHA': Date()}\n",
    "        )\n",
    "        print(f\"✅ ¡Éxito! {len(df)} registros importados a hi_{name}\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412134a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine, Date, text\n",
    "# from datetime import datetime\n",
    "\n",
    "# # ================================\n",
    "# # 1️⃣ Importar funciones extendidas\n",
    "# # ================================\n",
    "# from DGA import get_df_detalles_ext_DGA\n",
    "# from ACE import get_df_detalles_ext_ACE\n",
    "# from ARR import get_df_detalles_ext_ARR\n",
    "# from AIS import get_df_detalles_ext_AIS\n",
    "# from NUC import get_df_detalles_ext_NUC\n",
    "# from OLTC import get_df_detalles_ext_OLTC\n",
    "# from BUS import get_df_detalles_ext_BUS\n",
    "\n",
    "# # Diccionario con las funciones extendidas\n",
    "# data_sources_ext = {\n",
    "#     \"dga_extendido\": get_df_detalles_ext_DGA,\n",
    "#     \"ace_extendido\": get_df_detalles_ext_ACE,\n",
    "#     \"arr_extendido\": get_df_detalles_ext_ARR,\n",
    "#     \"ais_extendido\": get_df_detalles_ext_AIS,\n",
    "#     \"nuc_extendido\": get_df_detalles_ext_NUC,\n",
    "#     \"oltc_extendido\": get_df_detalles_ext_OLTC,\n",
    "#     \"bus_extendido\": get_df_detalles_ext_BUS,\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # 2️⃣ Conexión SQL\n",
    "# # ================================\n",
    "# password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "# engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "\n",
    "# # ================================\n",
    "# # 3️⃣ Función para carga incremental\n",
    "# # ================================\n",
    "# def carga_incremental(tabla_nombre, funcion_fuente, engine):\n",
    "#     \"\"\"\n",
    "#     Realiza carga incremental comparando datos existentes con nuevos\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Obtener nuevos datos\n",
    "#         nuevos_datos = funcion_fuente()\n",
    "        \n",
    "#         if nuevos_datos.empty:\n",
    "#             print(f\"⚠️ No hay nuevos datos para {tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Verificar si la tabla existe en la base de datos\n",
    "#         with engine.connect() as conn:\n",
    "#             tabla_existe = conn.execute(text(f\"\"\"\n",
    "#                 SELECT EXISTS (\n",
    "#                     SELECT FROM information_schema.tables \n",
    "#                     WHERE table_schema = 'raw_v2' \n",
    "#                     AND table_name = 'hi_{tabla_nombre}'\n",
    "#                 );\n",
    "#             \"\"\")).scalar()\n",
    "        \n",
    "#         if not tabla_existe:\n",
    "#             # Si la tabla no existe, crear con todos los datos\n",
    "#             nuevos_datos.to_sql(\n",
    "#                 f\"hi_{tabla_nombre}\",\n",
    "#                 engine,\n",
    "#                 if_exists='fail',\n",
    "#                 index=False,\n",
    "#                 schema='raw_v2',\n",
    "#                 dtype={'FECHA': Date()}\n",
    "#             )\n",
    "#             print(f\"✅ ¡Tabla creada! {len(nuevos_datos)} registros importados a hi_{tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Si la tabla existe, obtener datos existentes para comparar\n",
    "#         with engine.connect() as conn:\n",
    "#             datos_existentes = pd.read_sql_table(\n",
    "#                 f\"hi_{tabla_nombre}\", \n",
    "#                 conn, \n",
    "#                 schema='raw_v2'\n",
    "#             )\n",
    "        \n",
    "#         if datos_existentes.empty:\n",
    "#             # Si la tabla existe pero está vacía, insertar todos los datos\n",
    "#             nuevos_datos.to_sql(\n",
    "#                 f\"hi_{tabla_nombre}\",\n",
    "#                 engine,\n",
    "#                 if_exists='append',\n",
    "#                 index=False,\n",
    "#                 schema='raw_v2'\n",
    "#             )\n",
    "#             print(f\"✅ ¡Datos cargados en tabla vacía! {len(nuevos_datos)} registros importados a hi_{tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Identificar duplicados basado en todas las columnas\n",
    "#         # Combinar datos existentes y nuevos\n",
    "#         todos_datos = pd.concat([datos_existentes, nuevos_datos], ignore_index=True)\n",
    "        \n",
    "#         # Eliminar duplicados manteniendo los primeros (los existentes)\n",
    "#         datos_sin_duplicados = todos_datos.drop_duplicates(keep='first')\n",
    "        \n",
    "#         # Filtrar solo los registros nuevos (los que no estaban en existentes)\n",
    "#         datos_nuevos = datos_sin_duplicados.iloc[len(datos_existentes):]\n",
    "        \n",
    "#         if datos_nuevos.empty:\n",
    "#             print(f\"ℹ️ No hay datos nuevos para {tabla_nombre}. Tabla actualizada.\")\n",
    "#             return\n",
    "        \n",
    "#         # Insertar solo los datos nuevos\n",
    "#         datos_nuevos.to_sql(\n",
    "#             f\"hi_{tabla_nombre}\",\n",
    "#             engine,\n",
    "#             if_exists='append',\n",
    "#             index=False,\n",
    "#             schema='raw_v2'\n",
    "#         )\n",
    "        \n",
    "#         print(f\"✅ ¡Carga incremental exitosa! {len(datos_nuevos)} nuevos registros añadidos a hi_{tabla_nombre}\")\n",
    "#         print(f\"   Total en tabla: {len(datos_sin_duplicados)} registros\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error en carga incremental para {tabla_nombre}: {e}\")\n",
    "\n",
    "# # ================================\n",
    "# # 4️⃣ Ejecutar carga incremental para todas las tablas\n",
    "# # ================================\n",
    "# for name, func in data_sources_ext.items():\n",
    "#     print(f\"\\n🔄 Procesando: {name}\")\n",
    "#     carga_incremental(name, func, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc32238",
   "metadata": {},
   "source": [
    "### Carga automática de tabla de Sub-subíndices detallados y extendidos a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73201da0",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombre de tabla 'hi_<subíndice>_ <subsubíndice>' y 'hi_<subíndice>_<subsubíndice>_extendido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed2f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ hi_arr_rohm: 482 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C [mΩ]', 'X POS1 S 75°C [mΩ]', 'X POS1 T 75°C [mΩ]', 'Y POS1 R 75°C [mΩ]', 'Y POS1 S 75°C [mΩ]', 'Y POS1 T 75°C [mΩ]']\n",
      "✅ hi_arr_rtra: 564 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T', 'TempR', 'HumR']\n",
      "✅ hi_arr_rdis: 231 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X DOWN [%] ONAF 2', 'H-X MID [%] ONAF 2', 'H-X TOP [%] ONAF 2', 'H-Y DOWN [%]', 'H-Y MID [%]', 'H-Y TOP [%]', 'X-Y [%]']\n",
      "✅ hi_arr_rohm_extendido: 468288 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C [mΩ]', 'X POS1 S 75°C [mΩ]', 'X POS1 T 75°C [mΩ]', 'Y POS1 R 75°C [mΩ]', 'Y POS1 S 75°C [mΩ]', 'Y POS1 T 75°C [mΩ]']\n",
      "✅ hi_arr_rtra_extendido: 511985 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T', 'TempR', 'HumR']\n",
      "✅ hi_arr_rdis_extendido: 341165 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X DOWN [%] ONAF 2', 'H-X MID [%] ONAF 2', 'H-X TOP [%] ONAF 2', 'H-Y DOWN [%]', 'H-Y MID [%]', 'H-Y TOP [%]', 'X-Y [%]']\n",
      "✅ hi_ais_furanos: 133 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n",
      "✅ hi_ais_fp: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n",
      "✅ hi_ais_cd: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n",
      "✅ hi_ais_ecc: 167 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ECC', 'EAC']\n",
      "✅ hi_ais_furanos_extendido: 527611 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n",
      "✅ hi_ais_fp_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n",
      "✅ hi_ais_cd_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n",
      "✅ hi_ais_ecc_extendido: 662489 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ECC', 'EAC']\n",
      "✅ hi_bus_fpbc1: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n",
      "✅ hi_bus_fpbc2: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n",
      "✅ hi_bus_cbc1: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n",
      "✅ hi_bus_cbc2: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 H0 pF']\n",
      "✅ hi_bus_cc: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW', 'TempR', 'HumR']\n",
      "✅ hi_bus_fpbc1_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n",
      "✅ hi_bus_fpbc2_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n",
      "✅ hi_bus_cbc1_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n",
      "✅ hi_bus_cbc2_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 H0 pF']\n",
      "✅ hi_bus_cc_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW', 'TempR', 'HumR']\n",
      "✅ hi_nuc_iex: 388 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12 mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12 mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12 mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n",
      "✅ hi_nuc_rnuc: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n",
      "✅ hi_nuc_iex_extendido: 511819 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12 mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12 mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12 mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n",
      "✅ hi_nuc_rnuc_extendido: 15868 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n",
      "\n",
      "🚀 Proceso finalizado paar todos los subíndices y extendidos.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 1️⃣ Importar todos los módulos normales y extendidos\n",
    "# =====================================================\n",
    "# ARR\n",
    "from ARRrohm import get_df_detalles_ROHM, get_df_detalles_ext_ROHM\n",
    "from ARRrtra import get_df_detalles_RTRA, get_df_detalles_ext_RTRA\n",
    "from ARRdis import get_df_detalles_DIS, get_df_detalles_ext_DIS\n",
    "\n",
    "# AIS\n",
    "from FURANOS import get_df_detalles_FUR, get_df_detalles_ext_FUR\n",
    "from FP import get_df_detalles_FP, get_df_detalles_ext_FP\n",
    "from CD import get_df_detalles_CD, get_df_detalles_ext_CD\n",
    "from ECC import get_df_detalles_ECC, get_df_detalles_ext_ECC\n",
    "\n",
    "# BUS\n",
    "from FPBC1 import get_df_detalles_FP_C1, get_df_detalles_ext_FP_C1\n",
    "from FPBC2 import get_df_detalles_FP_C2, get_df_detalles_ext_FP_C2\n",
    "from CBC1 import get_df_detalles_C_C1, get_df_detalles_ext_C_C1\n",
    "from CBC2 import get_df_detalles_C_C2, get_df_detalles_ext_C_C2\n",
    "from FPCOCA import get_df_detalles_CC, get_df_detalles_ext_CC\n",
    "\n",
    "# NUC\n",
    "from NUCiex import get_df_detalles_IEX, get_df_detalles_ext_IEX\n",
    "from NUCrnuc import get_df_detalles_RNUC, get_df_detalles_ext_RNUC\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 2️⃣ Diccionario maestro de fuentes\n",
    "# =====================================================\n",
    "sources = {\n",
    "    # ARR normales\n",
    "    \"hi_arr_rohm\": get_df_detalles_ROHM,\n",
    "    \"hi_arr_rtra\": get_df_detalles_RTRA,\n",
    "    \"hi_arr_rdis\": get_df_detalles_DIS,\n",
    "\n",
    "    # ARR extendidos\n",
    "    \"hi_arr_rohm_extendido\": get_df_detalles_ext_ROHM,\n",
    "    \"hi_arr_rtra_extendido\": get_df_detalles_ext_RTRA,\n",
    "    \"hi_arr_rdis_extendido\": get_df_detalles_ext_DIS,\n",
    "\n",
    "    # AIS normales\n",
    "    \"hi_ais_furanos\": get_df_detalles_FUR,\n",
    "    \"hi_ais_fp\": get_df_detalles_FP,\n",
    "    \"hi_ais_cd\": get_df_detalles_CD,\n",
    "    \"hi_ais_ecc\": get_df_detalles_ECC,\n",
    "    # AIS extendidos\n",
    "    \"hi_ais_furanos_extendido\": get_df_detalles_ext_FUR,\n",
    "    \"hi_ais_fp_extendido\": get_df_detalles_ext_FP,\n",
    "    \"hi_ais_cd_extendido\": get_df_detalles_ext_CD,\n",
    "    \"hi_ais_ecc_extendido\": get_df_detalles_ext_ECC,\n",
    "    # BUS normales\n",
    "    \"hi_bus_fpbc1\": get_df_detalles_FP_C1,\n",
    "    \"hi_bus_fpbc2\": get_df_detalles_FP_C2,\n",
    "    \"hi_bus_cbc1\": get_df_detalles_C_C1,\n",
    "    \"hi_bus_cbc2\": get_df_detalles_C_C2,\n",
    "    \"hi_bus_cc\": get_df_detalles_CC,\n",
    "\n",
    "    # BUS extendidos\n",
    "    \"hi_bus_fpbc1_extendido\": get_df_detalles_ext_FP_C1,\n",
    "    \"hi_bus_fpbc2_extendido\": get_df_detalles_ext_FP_C2,\n",
    "    \"hi_bus_cbc1_extendido\": get_df_detalles_ext_C_C1,\n",
    "    \"hi_bus_cbc2_extendido\": get_df_detalles_ext_C_C2,\n",
    "    \"hi_bus_cc_extendido\": get_df_detalles_ext_CC,\n",
    "\n",
    "    # NUC normales\n",
    "    \"hi_nuc_iex\": get_df_detalles_IEX,\n",
    "    \"hi_nuc_rnuc\": get_df_detalles_RNUC,\n",
    "\n",
    "    # NUC extendidos\n",
    "    \"hi_nuc_iex_extendido\": get_df_detalles_ext_IEX,\n",
    "    \"hi_nuc_rnuc_extendido\": get_df_detalles_ext_RNUC,\n",
    "}\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 3️⃣ Conexión única a PostgreSQL\n",
    "# =====================================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores\")\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 4️⃣ Cargar todos los DataFrames automáticamente\n",
    "# =====================================================\n",
    "for table_name, func in sources.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            table_name,\n",
    "            engine,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "            schema=\"raw_v2\",\n",
    "            dtype={\"FECHA\": Date()},\n",
    "        )\n",
    "        print(f\"✅ {table_name}: {len(df)} registros importados correctamente.\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {table_name}: {e}\")\n",
    "\n",
    "print(\"\\n🚀 Proceso finalizado paar todos los subíndices y extendidos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abf16d",
   "metadata": {},
   "source": [
    "### Carga automática de tabla de índice generla(HI) a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746bfe36",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'processed_v2' con nombre de tabla 'hi_general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f8579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/DGA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:117: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:125: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  DGA\n",
      "0     D518293 2025-02-07  1.3\n",
      "1     D518293 2023-08-29  1.3\n",
      "2     D518293 2022-06-14  1.3\n",
      "3     D518293 2022-04-28  1.3\n",
      "4     D518293 2021-08-15  1.0\n",
      "...       ...        ...  ...\n",
      "2674   338118 2013-02-11  1.3\n",
      "2675   338118 2011-12-19  1.3\n",
      "2676   338118 2011-11-28  1.0\n",
      "2677   338118 2011-11-21  1.0\n",
      "2678   338118 2011-09-17  1.0\n",
      "\n",
      "[2676 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  DGA\n",
      "634718  V180403 2025-11-06  1.0\n",
      "634719  V180403 2025-11-07  1.0\n",
      "634720  V180403 2025-11-08  1.0\n",
      "634721  V180403 2025-11-09  1.0\n",
      "634722  V180403 2025-11-10  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  DGA   H2   CH4  C2H2  C2H4  C2H6      CO     CO2  \\\n",
      "0  D518293 2025-02-07  1.3  4.0  11.8   1.0   1.0   2.6  1064.6  3681.0   \n",
      "1  D518293 2023-08-29  1.3  3.0   9.0   1.0   1.0   2.0   788.0  3213.0   \n",
      "2  D518293 2022-06-14  1.3  5.0   9.0   1.0   1.0   2.0   758.0  3021.0   \n",
      "3  D518293 2022-04-28  1.3  1.0   8.0   1.0   1.0   2.0   745.0  2942.0   \n",
      "4  D518293 2021-08-15  1.0  7.0   7.0   1.0   1.0   1.0   547.0  2375.0   \n",
      "\n",
      "        O2  \n",
      "0   3372.2  \n",
      "1  10157.0  \n",
      "2   3106.0  \n",
      "3   3837.0  \n",
      "4  11922.0   \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "         SERIE      FECHA  DGA   H2  CH4  C2H2  C2H4  C2H6     CO    CO2  \\\n",
      "19559  123160T 2025-02-08  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19560  123160T 2025-02-09  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19561  123160T 2025-02-10  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN   \n",
      "19562  123160T 2025-02-11  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "19563  123160T 2025-02-12  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "19564  123160T 2025-02-13  1.0  4.2  3.2   1.0   1.7   1.0  172.1  708.0   \n",
      "\n",
      "            O2  \n",
      "19559      NaN  \n",
      "19560      NaN  \n",
      "19561      NaN  \n",
      "19562  28466.0  \n",
      "19563  28466.0  \n",
      "19564  28466.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/ACE.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:150: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:157: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "          SERIE      FECHA       ACE\n",
      "0       D518293 2025-02-07  1.000000\n",
      "1       D518293 2023-08-29  1.000000\n",
      "2       D518293 2022-04-28  1.000000\n",
      "3       D518293 2021-08-15  1.952381\n",
      "4       D518293 2019-04-25  1.000000\n",
      "...         ...        ...       ...\n",
      "2932  230531-01 2005-06-08  5.000000\n",
      "2933  230531-01 2005-05-07  5.000000\n",
      "2934  230531-01 2004-06-08  1.000000\n",
      "2935  230531-01 2004-06-03  1.000000\n",
      "2936  230531-01 2004-06-01  1.000000\n",
      "\n",
      "[2937 rows x 3 columns]\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  ACE\n",
      "0  100138 2015-01-01  NaN\n",
      "1  100138 2015-01-02  NaN\n",
      "2  100138 2015-01-03  NaN\n",
      "3  100138 2015-01-04  NaN\n",
      "4  100138 2015-01-05  NaN\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA       ACE   FP25  FP100    HU    AC   TIF   CO    RD  IO\n",
      "0  D518293 2025-02-07  1.000000  0.002  0.096   6.0  0.00  39.9  0.5  74.0 NaN\n",
      "1  D518293 2023-08-29  1.000000  0.001  0.034   7.0  0.01  39.6  0.5  74.0 NaN\n",
      "2  D518293 2022-04-28  1.000000  0.004  0.080   7.0  0.02  41.3  1.0  71.2 NaN\n",
      "3  D518293 2021-08-15  1.952381  0.007  0.225  14.0  0.02  40.0  0.5  42.0 NaN\n",
      "4  D518293 2019-04-25  1.000000  0.005  0.060   NaN  0.01  45.9  0.5  64.0 NaN\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ACE   FP25  FP100   HU     AC   TIF   CO    RD  IO\n",
      "642679  V180403 2025-11-06  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642680  V180403 2025-11-07  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642681  V180403 2025-11-08  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642682  V180403 2025-11-09  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "642683  V180403 2025-11-10  1.0  0.001  0.069  3.0  0.003  42.8  0.5  75.0 NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ROHM\"] = df[score_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:101: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:101: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "            SERIE      FECHA  ROHM\n",
      "0           59571 2016-10-23   1.0\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   1.0\n",
      "3           59572 2016-09-18   5.0\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "341  5337PA196-03 2025-10-20   1.0\n",
      "342  5337PA196-04 2025-10-20   5.0\n",
      "343       P186255 2025-11-02   1.0\n",
      "344       P186256 2025-11-02   5.0\n",
      "345       P186257 2025-11-02   1.0\n",
      "\n",
      "[346 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  ROHM\n",
      "0  123157T 2015-01-01   NaN\n",
      "1  123157T 2015-01-02   NaN\n",
      "2  123157T 2015-01-03   NaN\n",
      "3  123157T 2015-01-04   NaN\n",
      "4  123157T 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "0  59571 2016-10-23   1.0                 NaN          393.230000   \n",
      "1  59571 2006-01-29   NaN                 NaN                 NaN   \n",
      "2  59571 1996-04-16   1.0          420.991013          406.693652   \n",
      "3  59572 2016-09-18   5.0                 NaN          424.407154   \n",
      "4  59572 2006-01-29   NaN                 NaN                 NaN   \n",
      "\n",
      "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ] H POS5 R 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN                NaN   \n",
      "1                 NaN                 NaN                NaN   \n",
      "2          378.146272          406.622639         421.073862   \n",
      "3                 NaN                 NaN                NaN   \n",
      "4                 NaN                 NaN                NaN   \n",
      "\n",
      "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN  ...                  NaN   \n",
      "1                 NaN                 NaN  ...                  NaN   \n",
      "2                 NaN                 NaN  ...                  NaN   \n",
      "3                 NaN                 NaN  ...                  NaN   \n",
      "4                 NaN                 NaN  ...                  NaN   \n",
      "\n",
      "   H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1                  NaN                  NaN                  NaN   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3                  NaN                  NaN                  NaN   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "\n",
      "   X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  X POS1 T 75°C [mΩ]  \\\n",
      "0           28.142000                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2           29.068145                 NaN                 NaN   \n",
      "3           26.451000                 NaN                 NaN   \n",
      "4                 NaN                 NaN                 NaN   \n",
      "\n",
      "   Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  Y POS1 T 75°C [mΩ]  \n",
      "0              15.909                 NaN                 NaN  \n",
      "1                 NaN                 NaN                 NaN  \n",
      "2                 NaN                 NaN                 0.0  \n",
      "3              15.038                 NaN                 NaN  \n",
      "4                 NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "468283  V147103 2025-11-06   1.0             200.209                 NaN   \n",
      "468284  V147103 2025-11-07   1.0             200.209                 NaN   \n",
      "468285  V147103 2025-11-08   1.0             200.209                 NaN   \n",
      "468286  V147103 2025-11-09   1.0             200.209                 NaN   \n",
      "468287  V147103 2025-11-10   1.0             200.209                 NaN   \n",
      "\n",
      "        H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN                 NaN   \n",
      "468284                 NaN                 NaN                 NaN   \n",
      "468285                 NaN                 NaN                 NaN   \n",
      "468286                 NaN                 NaN                 NaN   \n",
      "468287                 NaN                 NaN                 NaN   \n",
      "\n",
      "        H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN  ...                  NaN   \n",
      "468284                 NaN                 NaN  ...                  NaN   \n",
      "468285                 NaN                 NaN  ...                  NaN   \n",
      "468286                 NaN                 NaN  ...                  NaN   \n",
      "468287                 NaN                 NaN  ...                  NaN   \n",
      "\n",
      "        H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "468283                  NaN                  NaN                  NaN   \n",
      "468284                  NaN                  NaN                  NaN   \n",
      "468285                  NaN                  NaN                  NaN   \n",
      "468286                  NaN                  NaN                  NaN   \n",
      "468287                  NaN                  NaN                  NaN   \n",
      "\n",
      "        X POS1 R 75°C [mΩ]  X POS1 S 75°C [mΩ]  X POS1 T 75°C [mΩ]  \\\n",
      "468283                 NaN                 NaN                 NaN   \n",
      "468284                 NaN                 NaN                 NaN   \n",
      "468285                 NaN                 NaN                 NaN   \n",
      "468286                 NaN                 NaN                 NaN   \n",
      "468287                 NaN                 NaN                 NaN   \n",
      "\n",
      "        Y POS1 R 75°C [mΩ]  Y POS1 S 75°C [mΩ]  Y POS1 T 75°C [mΩ]  \n",
      "468283                 NaN                 NaN                 NaN  \n",
      "468284                 NaN                 NaN                 NaN  \n",
      "468285                 NaN                 NaN                 NaN  \n",
      "468286                 NaN                 NaN                 NaN  \n",
      "468287                 NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"Max_Delta\"] = df[delta_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"RTRA\"] = df[\"Max_Delta\"].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:91: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "            SERIE      FECHA  RTRA\n",
      "0           59571 2016-10-23   1.0\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   1.0\n",
      "3           59572 2016-09-18   1.0\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   1.0\n",
      "384       D518294 2025-06-05   1.0\n",
      "385       D518294 2025-06-05   1.0\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  59571 2016-10-23   1.0         NaN      3.3692         NaN         NaN   \n",
      "1  59571 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "2  59571 1996-04-16   1.0       3.522      3.3621       3.202      3.0414   \n",
      "3  59572 2016-09-18   1.0         NaN      3.3607         NaN         NaN   \n",
      "4  59572 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS23 T  H-Y POS24 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2      2.8818         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \\\n",
      "0          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "1          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "2          NaN          NaN          NaN       3.616         NaN         NaN   \n",
      "3          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "4          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "\n",
      "   TempR  HumR  \n",
      "0    NaN   NaN  \n",
      "1    NaN   NaN  \n",
      "2    NaN   NaN  \n",
      "3    NaN   NaN  \n",
      "4    NaN   NaN  \n",
      "\n",
      "[5 rows x 170 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  100138 2015-01-01   NaN         NaN         NaN         NaN         NaN   \n",
      "1  100138 2015-01-02   NaN         NaN         NaN         NaN         NaN   \n",
      "2  100138 2015-01-03   NaN         NaN         NaN         NaN         NaN   \n",
      "3  100138 2015-01-04   NaN         NaN         NaN         NaN         NaN   \n",
      "4  100138 2015-01-05   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS23 T  H-Y POS24 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \\\n",
      "0          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "1          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "2          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "3          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "4          NaN          NaN          NaN         NaN         NaN         NaN   \n",
      "\n",
      "   TempR  HumR  \n",
      "0    NaN   NaN  \n",
      "1    NaN   NaN  \n",
      "2    NaN   NaN  \n",
      "3    NaN   NaN  \n",
      "4    NaN   NaN  \n",
      "\n",
      "[5 rows x 170 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDIS.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_DIS_ext = df_DIS_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS\n",
      "0    59571 2016-10-23   NaN\n",
      "1    59571 2006-01-29   NaN\n",
      "2    59571 1996-04-16   1.0\n",
      "3    59572 2016-09-18   NaN\n",
      "4    59572 2006-01-29   NaN\n",
      "5    59572 1996-04-22   1.0\n",
      "6    59573 2016-09-18   NaN\n",
      "7    59573 2006-01-29   NaN\n",
      "8   146916 2019-06-30   NaN\n",
      "9   146916 2015-01-06   NaN\n",
      "10  146916 2014-11-12   1.0\n",
      "11  146917 2022-05-12   NaN\n",
      "12  146917 2014-12-05   1.0\n",
      "13  146918 2019-07-11   5.0\n",
      "14  146918 2014-11-25   1.0\n",
      "15  185466 2015-11-22   NaN\n",
      "16  185466 2014-09-12   NaN\n",
      "17  185466 2005-10-21   1.0\n",
      "18  185519 2020-06-16   NaN\n",
      "19  185519 2016-07-10   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS\n",
      "0  123157T 2015-01-01   NaN\n",
      "1  123157T 2015-01-02   NaN\n",
      "2  123157T 2015-01-03   NaN\n",
      "3  123157T 2015-01-04   NaN\n",
      "4  123157T 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  RDIS  H-X DOWN [%] ONAF 2  H-X MID [%] ONAF 2  \\\n",
      "0  59571 2016-10-23   NaN                  NaN                 NaN   \n",
      "1  59571 2006-01-29   NaN                  NaN                 NaN   \n",
      "2  59571 1996-04-16   1.0                  NaN                 NaN   \n",
      "3  59572 2016-09-18   NaN                  NaN                 NaN   \n",
      "4  59572 2006-01-29   NaN                  NaN                 NaN   \n",
      "\n",
      "   H-X TOP [%] ONAF 2  H-Y DOWN [%]  H-Y MID [%]  H-Y TOP [%]  X-Y [%]  \n",
      "0                 NaN           NaN          NaN          NaN      NaN  \n",
      "1                 NaN           NaN          NaN          NaN      NaN  \n",
      "2                 NaN         6.725          NaN          NaN    12.23  \n",
      "3                 NaN           NaN          NaN          NaN      NaN  \n",
      "4                 NaN           NaN          NaN          NaN      NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "     SERIE      FECHA  RDIS  H-X DOWN [%] ONAF 2  H-X MID [%] ONAF 2  \\\n",
      "0  123157T 2015-01-01   NaN                  NaN                 NaN   \n",
      "1  123157T 2015-01-02   NaN                  NaN                 NaN   \n",
      "2  123157T 2015-01-03   NaN                  NaN                 NaN   \n",
      "3  123157T 2015-01-04   NaN                  NaN                 NaN   \n",
      "4  123157T 2015-01-05   NaN                  NaN                 NaN   \n",
      "\n",
      "   H-X TOP [%] ONAF 2  H-Y DOWN [%]  H-Y MID [%]  H-Y TOP [%]  X-Y [%]  \n",
      "0                 NaN           NaN          NaN          NaN      NaN  \n",
      "1                 NaN           NaN          NaN          NaN      NaN  \n",
      "2                 NaN           NaN          NaN          NaN      NaN  \n",
      "3                 NaN           NaN          NaN          NaN      NaN  \n",
      "4                 NaN           NaN          NaN          NaN      NaN   \n",
      "\n",
      "     SERIE      FECHA  ARR  ROHM  RTRA  RDIS\n",
      "0   100138 2019-04-17  1.0   NaN   1.0   NaN\n",
      "1  123157T 2019-04-22  NaN   NaN   NaN   NaN\n",
      "2  123157T 2024-07-12  1.0   1.0   NaN   1.0\n",
      "3  123158T 1984-02-21  1.0   NaN   1.0   NaN\n",
      "4  123158T 2021-12-13  5.0   NaN   5.0   NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fp['Max_FP'] = df_fp[[c for c in df_fp.columns if c.endswith('%')]].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[columna_puntaje] = np.select(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP = df_extendida_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP = df_detalles_ext_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPDEVANADO ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  FPDEVANADO\n",
      "383  5337PA196-03 2025-01-19         NaN\n",
      "384       D518294 2025-06-05         NaN\n",
      "385       D518294 2025-06-05         NaN\n",
      "386        359111 2022-12-14         NaN\n",
      "387       L-30230 2023-11-02         NaN \n",
      "\n",
      "\n",
      " ====== TABLA FPDEVANADO EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  FPDEVANADO\n",
      "0  100138 2015-01-01         NaN\n",
      "1  100138 2015-01-02         NaN\n",
      "2  100138 2015-01-03         NaN\n",
      "3  100138 2015-01-04         NaN\n",
      "4  100138 2015-01-05         NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPDEVANADO ====== \n",
      "\n",
      "   SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  X ICL+ICLT %  \\\n",
      "0  59571 2016-10-23           NaN    0.260     0.200       NaN           NaN   \n",
      "1  59571 2006-01-29          0.22    0.230     0.170       NaN           NaN   \n",
      "2  59571 1996-04-16          0.12    0.122     0.104       NaN           NaN   \n",
      "3  59572 2016-09-18           NaN    0.210     0.150       NaN           NaN   \n",
      "4  59572 2006-01-29          0.21    0.210     0.150       NaN           NaN   \n",
      "\n",
      "   X ICL %  X ICLT %  X ICLH %  Y ICT+ICTH %  Y ICT %  Y ICTH %  Y ICTL %  \\\n",
      "0    0.210       NaN       NaN          0.18     0.14      0.19       NaN   \n",
      "1    0.190       NaN       NaN          0.17     0.13      0.17       NaN   \n",
      "2    0.139       NaN       NaN           NaN      NaN       NaN       NaN   \n",
      "3    0.180       NaN       NaN          0.15     0.11      0.15       NaN   \n",
      "4    0.170       NaN       NaN          0.17     0.12      0.15       NaN   \n",
      "\n",
      "   FPDEVANADO  \n",
      "0         1.0  \n",
      "1         1.0  \n",
      "2         1.0  \n",
      "3         1.0  \n",
      "4         1.0   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPDEVANADO ====== \n",
      "\n",
      "          SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  \\\n",
      "511814  V147103 2025-11-06        0.1453   0.1657    0.1254       NaN   \n",
      "511815  V147103 2025-11-07        0.1453   0.1657    0.1254       NaN   \n",
      "511816  V147103 2025-11-08        0.1453   0.1657    0.1254       NaN   \n",
      "511817  V147103 2025-11-09        0.1453   0.1657    0.1254       NaN   \n",
      "511818  V147103 2025-11-10        0.1453   0.1657    0.1254       NaN   \n",
      "\n",
      "        X ICL+ICLT %  X ICL %  X ICLT %  X ICLH %  Y ICT+ICTH %  Y ICT %  \\\n",
      "511814        0.1799   0.2261    0.1638       NaN         0.182   0.1819   \n",
      "511815        0.1799   0.2261    0.1638       NaN         0.182   0.1819   \n",
      "511816        0.1799   0.2261    0.1638       NaN         0.182   0.1819   \n",
      "511817        0.1799   0.2261    0.1638       NaN         0.182   0.1819   \n",
      "511818        0.1799   0.2261    0.1638       NaN         0.182   0.1819   \n",
      "\n",
      "        Y ICTH %  Y ICTL %  FPDEVANADO  \n",
      "511814    0.1989       NaN         1.0  \n",
      "511815    0.1989       NaN         1.0  \n",
      "511816    0.1989       NaN         1.0  \n",
      "511817    0.1989       NaN         1.0  \n",
      "511818    0.1989       NaN         1.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:95: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CD = df_extendida_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:103: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CD = df_detalles_ext_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CD ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA   CD\n",
      "0           59571 2016-10-23  5.0\n",
      "1           59571 2006-01-29  5.0\n",
      "2           59571 1996-04-16  1.0\n",
      "3           59572 2016-09-18  NaN\n",
      "4           59572 2006-01-29  NaN\n",
      "..            ...        ...  ...\n",
      "383  5337PA196-03 2025-01-19  NaN\n",
      "384       D518294 2025-06-05  NaN\n",
      "385       D518294 2025-06-05  NaN\n",
      "386        359111 2022-12-14  NaN\n",
      "387       L-30230 2023-11-02  NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CD EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CD\n",
      "0  100138 2015-01-01 NaN\n",
      "1  100138 2015-01-02 NaN\n",
      "2  100138 2015-01-03 NaN\n",
      "3  100138 2015-01-04 NaN\n",
      "4  100138 2015-01-05 NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CD ====== \n",
      "\n",
      "   SERIE      FECHA   CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  H ICHT pF  \\\n",
      "0  59571 2016-10-23  5.0         3802.9    1553.5     2249.5        NaN   \n",
      "1  59571 2006-01-29  5.0         3786.3    1546.1     2240.2        NaN   \n",
      "2  59571 1996-04-16  1.0        11300.0    6497.0     2200.0        NaN   \n",
      "3  59572 2016-09-18  NaN         3757.2    1570.5     2185.9        NaN   \n",
      "4  59572 2006-01-29  NaN         3740.8    1562.9     2176.6        NaN   \n",
      "\n",
      "   X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  Y ICT+ICTH pF  Y ICT pF  \\\n",
      "0         4830.8    4820.3      10.40        NaN         6640.2    1587.9   \n",
      "1         4814.2    4803.3      10.15        NaN         6604.2    1570.6   \n",
      "2            NaN    4900.0        NaN        NaN            NaN       NaN   \n",
      "3         4711.7    4701.1       9.84        NaN         6621.4    1605.4   \n",
      "4         4688.7    4678.6      10.02        NaN         6586.6    1593.1   \n",
      "\n",
      "   Y ICTH pF  Y ICTL pF  \n",
      "0     5052.9        NaN  \n",
      "1     5031.1        NaN  \n",
      "2        NaN        NaN  \n",
      "3     5014.7        NaN  \n",
      "4     4991.4        NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CD ====== \n",
      "\n",
      "          SERIE      FECHA   CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  \\\n",
      "511814  V147103 2025-11-06  1.0         5704.6    2681.4     3023.3   \n",
      "511815  V147103 2025-11-07  1.0         5704.6    2681.4     3023.3   \n",
      "511816  V147103 2025-11-08  1.0         5704.6    2681.4     3023.3   \n",
      "511817  V147103 2025-11-09  1.0         5704.6    2681.4     3023.3   \n",
      "511818  V147103 2025-11-10  1.0         5704.6    2681.4     3023.3   \n",
      "\n",
      "        H ICHT pF  X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  \\\n",
      "511814        NaN         8209.3    2088.2     6120.7        NaN   \n",
      "511815        NaN         8209.3    2088.2     6120.7        NaN   \n",
      "511816        NaN         8209.3    2088.2     6120.7        NaN   \n",
      "511817        NaN         8209.3    2088.2     6120.7        NaN   \n",
      "511818        NaN         8209.3    2088.2     6120.7        NaN   \n",
      "\n",
      "        Y ICT+ICTH pF  Y ICT pF  Y ICTH pF  Y ICTL pF  \n",
      "511814        10550.1   10504.3       45.7        NaN  \n",
      "511815        10550.1   10504.3       45.7        NaN  \n",
      "511816        10550.1   10504.3       45.7        NaN  \n",
      "511817        10550.1   10504.3       45.7        NaN  \n",
      "511818        10550.1   10504.3       45.7        NaN   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FURANOS.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:74: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FUR = df_extendida_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:85: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles_FUR = df_extendida_detalles_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  FUR\n",
      "0      D518293 2023-08-29  1.0\n",
      "1      D518292 2023-08-29  1.0\n",
      "2      D518291 2023-08-29  1.0\n",
      "3      V101038 2023-09-03  1.0\n",
      "4       551873 2023-12-05  1.0\n",
      "..         ...        ...  ...\n",
      "128   132006T1 2020-01-01  1.0\n",
      "129    123158T 2023-07-18  1.0\n",
      "130    L-30436 2023-10-23  1.0\n",
      "131    123160T 2009-06-02  4.0\n",
      "132  750005-01 2018-08-02  1.0\n",
      "\n",
      "[133 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  FUR\n",
      "0        100138 2015-01-01  NaN\n",
      "1        100138 2015-01-02  NaN\n",
      "2        100138 2015-01-03  NaN\n",
      "3        100138 2015-01-04  NaN\n",
      "4        100138 2015-01-05  NaN\n",
      "...         ...        ...  ...\n",
      "527606  V180403 2025-11-06  1.0\n",
      "527607  V180403 2025-11-07  1.0\n",
      "527608  V180403 2025-11-08  1.0\n",
      "527609  V180403 2025-11-09  1.0\n",
      "527610  V180403 2025-11-10  1.0\n",
      "\n",
      "[527611 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0      D518293 2023-08-29                          1.0  1.0\n",
      "1      D518292 2023-08-29                          1.0  1.0\n",
      "2      D518291 2023-08-29                          1.0  1.0\n",
      "3      V101038 2023-09-03                          1.0  1.0\n",
      "4       551873 2023-12-05                          1.0  1.0\n",
      "..         ...        ...                          ...  ...\n",
      "128   132006T1 2020-01-01                          1.0  1.0\n",
      "129    123158T 2023-07-18                          1.0  1.0\n",
      "130    L-30436 2023-10-23                         87.0  1.0\n",
      "131    123160T 2009-06-02                       3330.0  4.0\n",
      "132  750005-01 2018-08-02                         25.0  1.0\n",
      "\n",
      "[133 rows x 4 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0        100138 2015-01-01                          NaN  NaN\n",
      "1        100138 2015-01-02                          NaN  NaN\n",
      "2        100138 2015-01-03                          NaN  NaN\n",
      "3        100138 2015-01-04                          NaN  NaN\n",
      "4        100138 2015-01-05                          NaN  NaN\n",
      "...         ...        ...                          ...  ...\n",
      "527606  V180403 2025-11-06                          1.0  1.0\n",
      "527607  V180403 2025-11-07                          1.0  1.0\n",
      "527608  V180403 2025-11-08                          1.0  1.0\n",
      "527609  V180403 2025-11-09                          1.0  1.0\n",
      "527610  V180403 2025-11-10                          1.0  1.0\n",
      "\n",
      "[527611 rows x 4 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/ECC.xlsx\n",
      "         SERIE      FECHA  EAC\n",
      "0     146660T3 2025-02-07  NaN\n",
      "1       364076 2021-08-15  NaN\n",
      "2    230531-01 2025-03-13  NaN\n",
      "3       338118 2025-03-25  NaN\n",
      "4      D518293 2025-03-25  NaN\n",
      "..         ...        ...  ...\n",
      "162    L-30300 2025-09-03  NaN\n",
      "163    L-30436 2025-09-04  NaN\n",
      "164  750005-01 2025-09-05  NaN\n",
      "165    L-30229 2025-09-06  NaN\n",
      "166    123160T 2025-09-07  NaN\n",
      "\n",
      "[167 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ECC.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ECC.py:89: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "         SERIE      FECHA  ECC\n",
      "0     146660T3 2025-02-07  NaN\n",
      "1       364076 2021-08-15  NaN\n",
      "2    230531-01 2025-03-13  NaN\n",
      "3       338118 2025-03-25  NaN\n",
      "4      D518293 2025-03-25  NaN\n",
      "..         ...        ...  ...\n",
      "162    L-30300 2025-09-03  NaN\n",
      "163    L-30436 2025-09-04  NaN\n",
      "164  750005-01 2025-09-05  NaN\n",
      "165    L-30229 2025-09-06  NaN\n",
      "166    123160T 2025-09-07  NaN\n",
      "\n",
      "[167 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ECC\n",
      "662484  V180403 2025-11-06  NaN\n",
      "662485  V180403 2025-11-07  NaN\n",
      "662486  V180403 2025-11-08  NaN\n",
      "662487  V180403 2025-11-09  NaN\n",
      "662488  V180403 2025-11-10  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE ECC CON FECHAS ORIGINALES ====== \n",
      "\n",
      "       SERIE      FECHA  ECC  EAC\n",
      "0   146660T3 2025-02-07  NaN  NaN\n",
      "1     364076 2021-08-15  NaN  NaN\n",
      "2  230531-01 2025-03-13  NaN  NaN\n",
      "3     338118 2025-03-25  NaN  NaN\n",
      "4    D518293 2025-03-25  NaN  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE ECC CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  ECC  EAC\n",
      "400657  D518293 2025-11-01  NaN  NaN\n",
      "400658  D518293 2025-11-02  NaN  NaN\n",
      "400659  D518293 2025-11-03  NaN  NaN\n",
      "400660  D518293 2025-11-04  NaN  NaN\n",
      "400661  D518293 2025-11-05  NaN  NaN\n",
      "400662  D518293 2025-11-06  NaN  NaN\n",
      "400663  D518293 2025-11-07  NaN  NaN\n",
      "400664  D518293 2025-11-08  NaN  NaN\n",
      "400665  D518293 2025-11-09  NaN  NaN\n",
      "400666  D518293 2025-11-10  NaN  NaN\n",
      "      SERIE      FECHA       AIS  FPDEVANADO   CD  FUR  ECC\n",
      "7   123158T 1984-02-21  1.000000         1.0  1.0  NaN  NaN\n",
      "8   123158T 2021-12-13  2.200000         1.0  3.0  NaN  NaN\n",
      "9   123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "10  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "11  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "12  123158T 2022-05-21  2.200000         1.0  3.0  NaN  NaN\n",
      "13  123158T 2023-07-18  1.857143         1.0  3.0  1.0  NaN\n",
      "14  123158T 2025-09-02  1.857143         1.0  3.0  1.0  NaN\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RNUCLEO.xlsx\n",
      "        SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0    146660T3 2022-05-12   NaN         NaN\n",
      "1    146660T3 2019-01-23   NaN         NaN\n",
      "2    146660T3 2018-02-05   NaN         NaN\n",
      "3    146660T3 2017-11-22   NaN         NaN\n",
      "4      364076 2022-06-18   NaN         NaN\n",
      "5      364076 2015-05-24   NaN         NaN\n",
      "6      364076 2014-08-13   NaN         NaN\n",
      "7      364076 2013-11-05   NaN         NaN\n",
      "8   230531-01 2024-07-16   NaN         NaN\n",
      "9   230531-01 2017-10-26   NaN         NaN\n",
      "10  230531-01 2016-03-04   NaN         NaN\n",
      "11  230531-01 2014-11-11   NaN         NaN\n",
      "12     338118 2024-11-13   NaN         NaN\n",
      "13     338118 2017-12-13   NaN         NaN\n",
      "14     338118 2016-09-05   NaN         NaN\n",
      "15     338118 2014-05-28   NaN         NaN\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  RNUC\n",
      "0    146660T3 2022-05-12   NaN\n",
      "1    146660T3 2019-01-23   NaN\n",
      "2    146660T3 2018-02-05   NaN\n",
      "3    146660T3 2017-11-22   NaN\n",
      "4      364076 2022-06-18   NaN\n",
      "5      364076 2015-05-24   NaN\n",
      "6      364076 2014-08-13   NaN\n",
      "7      364076 2013-11-05   NaN\n",
      "8   230531-01 2024-07-16   NaN\n",
      "9   230531-01 2017-10-26   NaN\n",
      "10  230531-01 2016-03-04   NaN\n",
      "11  230531-01 2014-11-11   NaN\n",
      "12     338118 2024-11-13   NaN\n",
      "13     338118 2017-12-13   NaN\n",
      "14     338118 2016-09-05   NaN\n",
      "15     338118 2014-05-28   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2022-05-12   NaN         NaN\n",
      "1  146660T3 2019-01-23   NaN         NaN\n",
      "2  146660T3 2018-02-05   NaN         NaN\n",
      "3  146660T3 2017-11-22   NaN         NaN\n",
      "4    364076 2022-06-18   NaN         NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2015-01-01   NaN         NaN\n",
      "1  146660T3 2015-01-02   NaN         NaN\n",
      "2  146660T3 2015-01-03   NaN         NaN\n",
      "3  146660T3 2015-01-04   NaN         NaN\n",
      "4  146660T3 2015-01-05   NaN         NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/IEXCITACION.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:57: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_RNUC_ext = df_RNUC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:69: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:74: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_IEX_ext = df_IEX_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "     SERIE      FECHA  IEX\n",
      "0    59571 2016-10-23    1\n",
      "1    59571 2006-01-29    1\n",
      "2    59571 1996-04-16    1\n",
      "3    59572 2016-09-18    1\n",
      "4    59572 2006-01-29    1\n",
      "5    59572 1996-04-22    1\n",
      "6    59573 2016-09-18    1\n",
      "7    59573 2006-01-29    1\n",
      "8   146916 2019-06-30    1\n",
      "9   146916 2015-01-06    1\n",
      "10  146916 2014-11-12    1\n",
      "11  146917 2022-05-12    1\n",
      "12  146917 2014-12-05    1\n",
      "13  146918 2019-07-11    5\n",
      "14  146918 2014-11-25    1\n",
      "15  185466 2015-11-22    1\n",
      "16  185466 2014-09-12    1\n",
      "17  185466 2005-10-21    1\n",
      "18  185519 2020-06-16    1\n",
      "19  185519 2016-07-10    1 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  IEX\n",
      "511814  V147103 2025-11-06  1.0\n",
      "511815  V147103 2025-11-07  1.0\n",
      "511816  V147103 2025-11-08  1.0\n",
      "511817  V147103 2025-11-09  1.0\n",
      "511818  V147103 2025-11-10  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  59571 2016-10-23    1        NaN     68.167        NaN        NaN   \n",
      "1  59571 2006-01-29    1     61.932        NaN        NaN        NaN   \n",
      "2  59571 1996-04-16    1        NaN        NaN        NaN        NaN   \n",
      "3  59572 2016-09-18    1        NaN        NaN        NaN        NaN   \n",
      "4  59572 2006-01-29    1        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   T POS27 mA  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  100138 2015-01-01  NaN        NaN        NaN        NaN        NaN   \n",
      "1  100138 2015-01-02  NaN        NaN        NaN        NaN        NaN   \n",
      "2  100138 2015-01-03  NaN        NaN        NaN        NaN        NaN   \n",
      "3  100138 2015-01-04  NaN        NaN        NaN        NaN        NaN   \n",
      "4  100138 2015-01-05  NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   T POS27 mA  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "     SERIE      FECHA  NUC  RNUC  IEX\n",
      "0   100138 2019-04-17  1.0   NaN  1.0\n",
      "1  123157T 2019-04-22  1.0   NaN  1.0\n",
      "2  123157T 2024-07-12  5.0   NaN  5.0\n",
      "3  123158T 1984-02-21  1.0   NaN  1.0\n",
      "4  123158T 2021-12-13  1.0   NaN  1.0\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FQOLTC.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2022-05-12   NaN\n",
      "1  146660T3 2018-05-12   NaN\n",
      "2  146660T3 2016-12-30   NaN\n",
      "3  146660T3 2014-03-26   NaN\n",
      "4    364076 2022-06-18   NaN \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC  RD  H20\n",
      "0  146660T3 2022-05-12   NaN NaN  NaN\n",
      "1  146660T3 2018-05-12   NaN NaN  NaN\n",
      "2  146660T3 2016-12-30   NaN NaN  NaN\n",
      "3  146660T3 2014-03-26   NaN NaN  NaN\n",
      "4    364076 2022-06-18   NaN NaN  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC  RD  H20\n",
      "0  146660T3 2015-01-01   NaN NaN  NaN\n",
      "1  146660T3 2015-01-02   NaN NaN  NaN\n",
      "2  146660T3 2015-01-03   NaN NaN  NaN\n",
      "3  146660T3 2015-01-04   NaN NaN  NaN\n",
      "4  146660T3 2015-01-05   NaN NaN  NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:81: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_OLTC_ext = df_OLTC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:89: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C1 = df_extendida_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:99: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C1 = df_detalles_ext_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPBC1 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  FPBC1\n",
      "383  5337PA196-03 2025-01-19    NaN\n",
      "384       D518294 2025-06-05    NaN\n",
      "385       D518294 2025-06-05    NaN\n",
      "386        359111 2022-12-14    NaN\n",
      "387       L-30230 2023-11-02    NaN \n",
      "\n",
      "\n",
      " ====== TABLA FPBC1 EXTENDIDA ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC1\n",
      "511814  V147103 2025-11-06    NaN\n",
      "511815  V147103 2025-11-07    NaN\n",
      "511816  V147103 2025-11-08    NaN\n",
      "511817  V147103 2025-11-09    NaN\n",
      "511818  V147103 2025-11-10    NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC1 ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "0  59571 2016-10-23    1.0     0.34      NaN      NaN     0.37\n",
      "1  59571 2006-01-29    1.0     0.36      NaN      NaN     0.40\n",
      "2  59571 1996-04-16    NaN      NaN      NaN      NaN      NaN\n",
      "3  59572 2016-09-18    NaN      NaN      NaN      NaN      NaN\n",
      "4  59572 2006-01-29    1.0     0.37      NaN      NaN     0.34 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC1 ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "511814  V147103 2025-11-06    NaN      NaN      NaN      NaN      NaN\n",
      "511815  V147103 2025-11-07    NaN      NaN      NaN      NaN      NaN\n",
      "511816  V147103 2025-11-08    NaN      NaN      NaN      NaN      NaN\n",
      "511817  V147103 2025-11-09    NaN      NaN      NaN      NaN      NaN\n",
      "511818  V147103 2025-11-10    NaN      NaN      NaN      NaN      NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:90: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C2 = df_extendida_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:98: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C2 = df_detalles_ext_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA FPBC2 ORIGINAL ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC2\n",
      "0  59571 2016-10-23    5.0\n",
      "1  59571 2006-01-29    1.0\n",
      "2  59571 1996-04-16    NaN\n",
      "3  59572 2016-09-18    NaN\n",
      "4  59572 2006-01-29    1.0 \n",
      "\n",
      "\n",
      " ====== TABLA FPBC2 EXTENDIDA ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC2\n",
      "511814  V147103 2025-11-06    NaN\n",
      "511815  V147103 2025-11-07    NaN\n",
      "511816  V147103 2025-11-08    NaN\n",
      "511817  V147103 2025-11-09    NaN\n",
      "511818  V147103 2025-11-10    NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC2 ====== \n",
      "\n",
      "   SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "0  59571 2016-10-23    5.0     0.21      NaN      NaN     6.33\n",
      "1  59571 2006-01-29    1.0     0.19      NaN      NaN     0.25\n",
      "2  59571 1996-04-16    NaN      NaN      NaN      NaN      NaN\n",
      "3  59572 2016-09-18    NaN      NaN      NaN      NaN      NaN\n",
      "4  59572 2006-01-29    1.0     0.21      NaN      NaN     0.26 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC2 ====== \n",
      "\n",
      "          SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "511814  V147103 2025-11-06    NaN      NaN      NaN      NaN      NaN\n",
      "511815  V147103 2025-11-07    NaN      NaN      NaN      NaN      NaN\n",
      "511816  V147103 2025-11-08    NaN      NaN      NaN      NaN      NaN\n",
      "511817  V147103 2025-11-09    NaN      NaN      NaN      NaN      NaN\n",
      "511818  V147103 2025-11-10    NaN      NaN      NaN      NaN      NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C1 = df_extendida_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:113: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C1 = df_detalles_ext_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:48: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CBC1 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  CBC1\n",
      "0           59571 2016-10-23   NaN\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   NaN\n",
      "3           59572 2016-09-18   NaN\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   NaN\n",
      "384       D518294 2025-06-05   NaN\n",
      "385       D518294 2025-06-05   NaN\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CBC1 EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CBC1\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC1 ====== \n",
      "\n",
      "   SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "0  59571 2016-10-23   NaN    280.25       NaN       NaN    190.91\n",
      "1  59571 2006-01-29   NaN    281.20       NaN       NaN    191.80\n",
      "2  59571 1996-04-16   NaN       NaN       NaN       NaN       NaN\n",
      "3  59572 2016-09-18   NaN       NaN       NaN       NaN       NaN\n",
      "4  59572 2006-01-29   NaN    288.10       NaN       NaN    192.50 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC1 ====== \n",
      "\n",
      "          SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "511814  V147103 2025-11-06   NaN       NaN       NaN       NaN       NaN\n",
      "511815  V147103 2025-11-07   NaN       NaN       NaN       NaN       NaN\n",
      "511816  V147103 2025-11-08   NaN       NaN       NaN       NaN       NaN\n",
      "511817  V147103 2025-11-09   NaN       NaN       NaN       NaN       NaN\n",
      "511818  V147103 2025-11-10   NaN       NaN       NaN       NaN       NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C2 = df_extendida_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:112: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C2 = df_detalles_ext_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CBC2 ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA  CBC2\n",
      "0           59571 2016-10-23   NaN\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   NaN\n",
      "3           59572 2016-09-18   NaN\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   NaN\n",
      "384       D518294 2025-06-05   NaN\n",
      "385       D518294 2025-06-05   NaN\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CBC2 EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CBC2\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC2 ====== \n",
      "\n",
      "   SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 H0 pF\n",
      "0  59571 2016-10-23   NaN    1114.5       NaN       NaN    373.17\n",
      "1  59571 2006-01-29   NaN    1053.0       NaN       NaN    360.60\n",
      "2  59571 1996-04-16   NaN       NaN       NaN       NaN       NaN\n",
      "3  59572 2016-09-18   NaN       NaN       NaN       NaN       NaN\n",
      "4  59572 2006-01-29   NaN    1072.0       NaN       NaN    353.60 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC2 ====== \n",
      "\n",
      "    SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 H0 pF\n",
      "0  100138 2015-01-01   NaN       NaN       NaN       NaN       NaN\n",
      "1  100138 2015-01-02   NaN       NaN       NaN       NaN       NaN\n",
      "2  100138 2015-01-03   NaN       NaN       NaN       NaN       NaN\n",
      "3  100138 2015-01-04   NaN       NaN       NaN       NaN       NaN\n",
      "4  100138 2015-01-05   NaN       NaN       NaN       NaN       NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPCOCA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:79: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CC = df_extendida_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CC = df_detalles_ext_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CC ORIGINAL ====== \n",
      "\n",
      "            SERIE      FECHA   CC\n",
      "0           59571 2016-10-23  1.0\n",
      "1           59571 2006-01-29  NaN\n",
      "2           59571 1996-04-16  NaN\n",
      "3           59572 2016-09-18  NaN\n",
      "4           59572 2006-01-29  NaN\n",
      "..            ...        ...  ...\n",
      "383  5337PA196-03 2025-01-19  NaN\n",
      "384       D518294 2025-06-05  NaN\n",
      "385       D518294 2025-06-05  NaN\n",
      "386        359111 2022-12-14  NaN\n",
      "387       L-30230 2023-11-02  NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CC EXTENDIDA ====== \n",
      "\n",
      "    SERIE      FECHA  CC\n",
      "0  100138 2015-01-01 NaN\n",
      "1  100138 2015-01-02 NaN\n",
      "2  100138 2015-01-03 NaN\n",
      "3  100138 2015-01-04 NaN\n",
      "4  100138 2015-01-05 NaN \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CC ====== \n",
      "\n",
      "   SERIE      FECHA   CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  Y3 mW  \\\n",
      "0  59571 2016-10-23  1.0   15.0    NaN    NaN    NaN   17.0    NaN    NaN   \n",
      "1  59571 2006-01-29  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2  59571 1996-04-16  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3  59572 2016-09-18  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4  59572 2006-01-29  NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   Y0 mW  TempR  HumR  \n",
      "0    NaN    NaN   NaN  \n",
      "1    NaN    NaN   NaN  \n",
      "2    NaN    NaN   NaN  \n",
      "3    NaN    NaN   NaN  \n",
      "4    NaN    NaN   NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CC ====== \n",
      "\n",
      "          SERIE      FECHA  CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  \\\n",
      "511814  V147103 2025-11-06 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511815  V147103 2025-11-07 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511816  V147103 2025-11-08 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511817  V147103 2025-11-09 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "511818  V147103 2025-11-10 NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "        Y3 mW  Y0 mW  TempR  HumR  \n",
      "511814    NaN    NaN    NaN   NaN  \n",
      "511815    NaN    NaN    NaN   NaN  \n",
      "511816    NaN    NaN    NaN   NaN  \n",
      "511817    NaN    NaN    NaN   NaN  \n",
      "511818    NaN    NaN    NaN   NaN   \n",
      "\n",
      "        SERIE      FECHA       BUS  FPBC1  FPBC2  CBC1  CBC2   CC\n",
      "4463  V101042 2022-11-14  1.000000    1.0    1.0   NaN   NaN  1.0\n",
      "4464  V101044 2019-06-21  2.176471    1.0    5.0   1.0   1.0  5.0\n",
      "4465  V147101 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "4466  V147102 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "4467  V147103 2024-03-27       NaN    NaN    NaN   NaN   NaN  NaN\n",
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS']\n",
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR', 'ECC']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\main.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  resultado = resultado.groupby(\"SERIE\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SERIE      FECHA   HI  DGA  ACE  ARR  AIS  NUC  OLTC  BUS\n",
      "0         100138 2017-07-10  1.0  NaN  1.0  NaN  NaN  NaN   NaN  NaN\n",
      "1         100138 2017-10-18  1.0  NaN  1.0  NaN  NaN  NaN   NaN  NaN\n",
      "2         100138 2018-08-07  1.0  NaN  1.0  NaN  NaN  NaN   NaN  NaN\n",
      "3         100138 2019-04-17  1.0  NaN  1.0  1.0  NaN  1.0   NaN  NaN\n",
      "4         100138 2019-04-26  1.0  1.0  1.0  1.0  NaN  1.0   NaN  NaN\n",
      "...          ...        ...  ...  ...  ...  ...  ...  ...   ...  ...\n",
      "2406566  V180402 2025-02-06  1.0  1.0  1.0  NaN  1.0  NaN   NaN  NaN\n",
      "2406567  V180402 2025-08-03  1.0  1.0  1.0  NaN  1.0  NaN   NaN  NaN\n",
      "2406568  V180403 2023-01-01  1.0  NaN  NaN  NaN  1.0  NaN   NaN  NaN\n",
      "2406569  V180403 2025-02-06  1.0  1.0  1.0  NaN  1.0  NaN   NaN  NaN\n",
      "2406570  V180403 2025-08-04  1.0  1.0  1.0  NaN  1.0  NaN   NaN  NaN\n",
      "\n",
      "[2406568 rows x 10 columns]\n",
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS']\n",
      "SERIE            object\n",
      "FECHA    datetime64[ns]\n",
      "HI              float64\n",
      "DGA             float64\n",
      "ACE             float64\n",
      "ARR             float64\n",
      "AIS             float64\n",
      "NUC             float64\n",
      "OLTC            float64\n",
      "BUS             float64\n",
      "dtype: object\n",
      "       SERIE      FECHA        HI   DGA  ACE  ARR       AIS  NUC  OLTC  \\\n",
      "0  230531-01 2025-11-10  3.480994  3.05  1.0  5.0  5.000000  1.0   NaN   \n",
      "1    L-30493 2025-11-10  3.150376  1.00  1.0  5.0  3.857143  5.0   NaN   \n",
      "2    L-30506 2025-11-10  2.669173  1.00  1.0  5.0  2.428571  5.0   NaN   \n",
      "\n",
      "        BUS  \n",
      "0  1.888889  \n",
      "1  3.571429  \n",
      "2  1.571429  \n",
      "¡Éxito! 2969343 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'HI', 'DGA', 'ACE', 'ARR', 'AIS', 'NUC', 'OLTC', 'BUS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from main import obtener_HI\n",
    "\n",
    "df_HI = obtener_HI()\n",
    "df_HI = df_HI.sort_values(by=[\"FECHA\", \"HI\"], ascending=[False, False]).reset_index(drop=True)\n",
    "print(df_HI.dtypes)\n",
    "print(df_HI.head(3))\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "        \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_HI.to_sql('hi_general', engine, if_exists='replace', index=False, schema='processed_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_HI)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_HI.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d7a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR', 'ECC']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\main.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  resultado = resultado.groupby(\"SERIE\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERIE            object\n",
      "FECHA    datetime64[ns]\n",
      "HI              float64\n",
      "DGA             float64\n",
      "ACE             float64\n",
      "ARR             float64\n",
      "AIS             float64\n",
      "NUC             float64\n",
      "OLTC            float64\n",
      "BUS             float64\n",
      "dtype: object\n",
      "     SERIE      FECHA        HI  DGA  ACE       ARR  AIS  NUC  OLTC       BUS\n",
      "0  P186256 2025-11-02  1.694332  1.3  1.0  1.923077  1.0  5.0   NaN  1.000000\n",
      "1  P186257 2025-11-02  1.116099  1.3  1.0  1.000000  1.0  1.0   NaN  1.705882\n",
      "2  P186255 2025-11-02  1.083333  1.3  1.0  1.000000  1.0  1.0   NaN       NaN\n",
      "¡Éxito! 2406568 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'HI', 'DGA', 'ACE', 'ARR', 'AIS', 'NUC', 'OLTC', 'BUS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from main import obtener_HI_original\n",
    "\n",
    "df_HI_original = obtener_HI_original()\n",
    "df_HI_original = df_HI_original.sort_values(by=[\"FECHA\", \"HI\"], ascending=[False, False]).reset_index(drop=True)\n",
    "print(df_HI_original.dtypes)\n",
    "print(df_HI_original.head(3))\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "        \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_HI_original.to_sql('hi_general_original', engine, if_exists='replace', index=False, schema='processed_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_HI_original)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_HI_original.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ceb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import difflib\n",
    "# import pandas as pd\n",
    "# from main import obtener_HI  # Asegúrate de que main.py esté en el mismo directorio\n",
    "\n",
    "# # Obtener el DataFrame\n",
    "# df = obtener_HI()\n",
    "\n",
    "# # Extraer la columna 'SERIE' y eliminar valores nulos\n",
    "# series = df['SERIE'].dropna().astype(str).unique()\n",
    "\n",
    "# # Comparar cada par de palabras en la columna 'SERIE'\n",
    "# similares = []\n",
    "# for i in range(len(series)):\n",
    "#     for j in range(i + 1, len(series)):\n",
    "#         similitud = difflib.SequenceMatcher(None, series[i], series[j]).ratio()\n",
    "#         if similitud > 0.8:  # Puedes ajustar el umbral\n",
    "#             similares.append((series[i], series[j], round(similitud, 2)))\n",
    "\n",
    "# # Crear un DataFrame con los resultados y exportar a CSV\n",
    "# df_similares = pd.DataFrame(similares, columns=['Palabra 1', 'Palabra 2', 'Similitud'])\n",
    "# df_similares.to_csv('series_similares.csv', index=False)\n",
    "\n",
    "# print(\"Archivo 'series_similares.csv' generado con pares de palabras similares.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
