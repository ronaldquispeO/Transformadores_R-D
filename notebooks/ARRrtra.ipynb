{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1871a5e0",
   "metadata": {},
   "source": [
    "### Importar y cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f602e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H-X POS1 R</th>\n",
       "      <th>H-X POS2 R</th>\n",
       "      <th>H-X POS3 R</th>\n",
       "      <th>H-X POS4 R</th>\n",
       "      <th>H-X POS5 R</th>\n",
       "      <th>H-X POS6 R</th>\n",
       "      <th>H-X POS7 R</th>\n",
       "      <th>...</th>\n",
       "      <th>H-Y POS23 T</th>\n",
       "      <th>H-Y POS24 T</th>\n",
       "      <th>H-Y POS25 T</th>\n",
       "      <th>H-Y POS26 T</th>\n",
       "      <th>H-Y POS27 T</th>\n",
       "      <th>X-Y POS1 R</th>\n",
       "      <th>X-Y POS1 S</th>\n",
       "      <th>X-Y POS1 T</th>\n",
       "      <th>TempR</th>\n",
       "      <th>HumR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>3.522</td>\n",
       "      <td>3.3621</td>\n",
       "      <td>3.202</td>\n",
       "      <td>3.0414</td>\n",
       "      <td>2.8818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SERIE      FECHA  H-X POS1 R  H-X POS2 R  H-X POS3 R  \\\n",
       "0         NaN  59571 2016-10-23         NaN      3.3692         NaN   \n",
       "1         NaN  59571 2006-01-29         NaN         NaN         NaN   \n",
       "2         NaN  59571 1996-04-16       3.522      3.3621       3.202   \n",
       "3         NaN  59572 2016-09-18         NaN      3.3607         NaN   \n",
       "4         NaN  59572 2006-01-29         NaN         NaN         NaN   \n",
       "\n",
       "   H-X POS4 R  H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS23 T  \\\n",
       "0         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "1         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "2      3.0414      2.8818         NaN         NaN  ...          NaN   \n",
       "3         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "4         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "\n",
       "   H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  \\\n",
       "0          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "1          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "2          NaN          NaN          NaN          NaN       3.616         NaN   \n",
       "3          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "4          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "\n",
       "   X-Y POS1 T  TempR  HumR  \n",
       "0         NaN    NaN   NaN  \n",
       "1         NaN    NaN   NaN  \n",
       "2         NaN    NaN   NaN  \n",
       "3         NaN    NaN   NaN  \n",
       "4         NaN    NaN   NaN  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# ---------------------------\n",
    "# LECTURA DE DATOS\n",
    "# ---------------------------\n",
    "# Lista de posibles rutas\n",
    "addresses = [\n",
    "    'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx',\n",
    "    'C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx',\n",
    "    'C:/Users/mticllacu/OneDrive - LUZ DEL SUR S.A.A/Archivos de Ronald Quispe Ocaña - ProyectoRyD_V2/Basededatos/RTRA.xlsx'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in addresses:\n",
    "    if os.path.exists(path):   # verifica si existe\n",
    "        df = pd.read_excel(path, header=1)\n",
    "        print(f\"✅ Archivo cargado desde: {path}\")\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    raise FileNotFoundError(\"❌ No se encontró el archivo en ninguna de las rutas especificadas.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94df653",
   "metadata": {},
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ca2a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H-X POS1 R</th>\n",
       "      <th>H-X POS2 R</th>\n",
       "      <th>H-X POS3 R</th>\n",
       "      <th>H-X POS4 R</th>\n",
       "      <th>H-X POS5 R</th>\n",
       "      <th>H-X POS6 R</th>\n",
       "      <th>H-X POS7 R</th>\n",
       "      <th>H-X POS8 R</th>\n",
       "      <th>...</th>\n",
       "      <th>H-Y POS21 T</th>\n",
       "      <th>H-Y POS22 T</th>\n",
       "      <th>H-Y POS23 T</th>\n",
       "      <th>H-Y POS24 T</th>\n",
       "      <th>H-Y POS25 T</th>\n",
       "      <th>H-Y POS26 T</th>\n",
       "      <th>H-Y POS27 T</th>\n",
       "      <th>X-Y POS1 R</th>\n",
       "      <th>X-Y POS1 S</th>\n",
       "      <th>X-Y POS1 T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>3.522</td>\n",
       "      <td>3.3621</td>\n",
       "      <td>3.202</td>\n",
       "      <td>3.0414</td>\n",
       "      <td>2.8818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIE      FECHA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
       "0  59571 2016-10-23         NaN      3.3692         NaN         NaN   \n",
       "1  59571 2006-01-29         NaN         NaN         NaN         NaN   \n",
       "2  59571 1996-04-16       3.522      3.3621       3.202      3.0414   \n",
       "3  59572 2016-09-18         NaN      3.3607         NaN         NaN   \n",
       "4  59572 2006-01-29         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   H-X POS5 R  H-X POS6 R  H-X POS7 R  H-X POS8 R  ...  H-Y POS21 T  \\\n",
       "0         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "1         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "2      2.8818         NaN         NaN         NaN  ...          NaN   \n",
       "3         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "4         NaN         NaN         NaN         NaN  ...          NaN   \n",
       "\n",
       "   H-Y POS22 T  H-Y POS23 T  H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   H-Y POS27 T  X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \n",
       "0          NaN         NaN         NaN         NaN  \n",
       "1          NaN         NaN         NaN         NaN  \n",
       "2          NaN       3.616         NaN         NaN  \n",
       "3          NaN         NaN         NaN         NaN  \n",
       "4          NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"SERIE\"] = df[\"SERIE\"].astype(str)\n",
    "df['SERIE'] = df['SERIE'].astype(str).str.replace(\" \", \"\")\n",
    "# ---------------------------\n",
    "# LIMPIEZA DE DATOS\n",
    "# ---------------------------\n",
    "# df[\"SERIE\"] = df[\"SERIE\"].astype(str)\n",
    "df = df.iloc[:, 1:]   # quitar primera columna vacía\n",
    "df = df[['SERIE']+['FECHA']+[col for col in df.columns if \"POS\" in col ]]  # seleccionar columnas relevantes\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors=\"coerce\")\n",
    "df = df.dropna(subset=['FECHA'])\n",
    "df_full = df.copy()   # copia de detalles originales\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e4942",
   "metadata": {},
   "source": [
    "### Lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a1b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\3475712375.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# CÁLCULO DE DELTAS\n",
    "# ---------------------------\n",
    "res_cols = [c for c in df.columns if c.endswith((\"R\", \"S\", \"T\"))]\n",
    "\n",
    "for col in res_cols:\n",
    "    # valor inicial por SERIE en la fecha mínima\n",
    "    ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
    "    ref_mapped = df[\"SERIE\"].map(ref)\n",
    "\n",
    "    # variación porcentual\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    delta = abs((df[col] - ref_mapped) / ref_mapped) * 100\n",
    "    delta = delta.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # marcar casos inválidos\n",
    "    mask = df[col].isna() | ref_mapped.isna() | (ref_mapped == 0) | (df[col] == 0)\n",
    "    delta[mask] = np.nan\n",
    "\n",
    "    # agregar columna nueva\n",
    "    df[f\"{col}_Delta\"] = delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e3624",
   "metadata": {},
   "source": [
    "### Asignación de puntajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eef42890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\1852777749.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"Max_Delta\"] = df[delta_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\1852777749.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"RTRA\"] = df[\"Max_Delta\"].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>RTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59571</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59571</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59571</td>\n",
       "      <td>1996-04-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59572</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59572</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIE      FECHA  RTRA\n",
       "0  59571 2016-10-23   1.0\n",
       "1  59571 2006-01-29   NaN\n",
       "2  59571 1996-04-16   1.0\n",
       "3  59572 2016-09-18   1.0\n",
       "4  59572 2006-01-29   NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# RTRA FINAL\n",
    "# ---------------------------\n",
    "delta_cols = [c for c in df.columns if c.endswith(\"_Delta\")]\n",
    "df[\"Max_Delta\"] = df[delta_cols].max(axis=1)\n",
    "df[\"RTRA\"] = df[\"Max_Delta\"].apply(\n",
    "    lambda x: np.nan if pd.isna(x) else (5 if x > 0.5 else 1)\n",
    ")\n",
    "df_RTRA = df[['SERIE', 'FECHA', 'RTRA']]\n",
    "df_RTRA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80af71",
   "metadata": {},
   "source": [
    "### Extensión de Calendario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06eeaccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\466003730.py:18: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\466003730.py:25: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_10928\\466003730.py:25: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# EXTENSIÓN DEL CALENDARIO DESDE 2025\n",
    "# ---------------------------\n",
    "inicio = \"2015-01-01\"\n",
    "desde_2025 = f\"{pd.Timestamp.today().year}-01-01\"\n",
    "fecha_inicio = pd.Timestamp(inicio)  # en el 2026 cambiar ---****\n",
    "fecha_fin = pd.Timestamp.today().normalize()\n",
    "fechas = pd.date_range(fecha_inicio, fecha_fin, freq=\"D\")\n",
    "todas_series = df['SERIE'].dropna().unique()\n",
    "calendario = pd.MultiIndex.from_product([todas_series, fechas], names=[\"SERIE\", \"FECHA\"])\n",
    "df_calendario = pd.DataFrame(index=calendario).reset_index()\n",
    "\n",
    "# ---------- Tabla extendida RTRA ----------\n",
    "ultimos_2024 = df_RTRA[df_RTRA['FECHA'] < fecha_inicio].sort_values('FECHA').groupby('SERIE').tail(1)\n",
    "ultimos_2024['FECHA'] = fecha_inicio\n",
    "base_ext = pd.concat([df_RTRA, ultimos_2024], ignore_index=True)\n",
    "df_extendida = pd.merge(df_calendario, base_ext, on=[\"SERIE\", \"FECHA\"], how=\"left\")\n",
    "df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
    "\n",
    "# ---------- Tabla extendida detalles ----------\n",
    "ultimos_2024_det = df_full[df_full['FECHA'] < fecha_inicio].sort_values('FECHA').groupby('SERIE').tail(1)\n",
    "ultimos_2024_det['FECHA'] = fecha_inicio\n",
    "base_ext_det = pd.concat([df_full, ultimos_2024_det], ignore_index=True)\n",
    "df_extendida_detalles = pd.merge(df_calendario, base_ext_det, on=[\"SERIE\", \"FECHA\"], how=\"left\")\n",
    "df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# DETALLES + RTRA\n",
    "# ---------------------------\n",
    "df_detalles = pd.merge(df_full, df_RTRA, on=[\"SERIE\", \"FECHA\"], how=\"left\")\n",
    "df_detalles_ext = pd.merge(df_extendida_detalles, df_extendida, on=[\"SERIE\", \"FECHA\"], how=\"left\")\n",
    "\n",
    "# Reordenar columnas: poner RTRA después de FECHA\n",
    "def reordenar(df_in):\n",
    "    cols = list(df_in.columns)\n",
    "    if \"RTRA\" in cols:\n",
    "        cols.remove(\"RTRA\")\n",
    "        idx = cols.index(\"FECHA\") + 1\n",
    "        cols = cols[:idx] + [\"RTRA\"] + cols[idx:]\n",
    "    return df_in[cols]\n",
    "\n",
    "df_detalles = reordenar(df_detalles)\n",
    "df_detalles_ext = reordenar(df_detalles_ext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf30792",
   "metadata": {},
   "source": [
    "### Funciones a llamar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1707c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "            SERIE      FECHA  RTRA\n",
      "0           59571 2016-10-23   1.0\n",
      "1           59571 2006-01-29   NaN\n",
      "2           59571 1996-04-16   1.0\n",
      "3           59572 2016-09-18   1.0\n",
      "4           59572 2006-01-29   NaN\n",
      "..            ...        ...   ...\n",
      "383  5337PA196-03 2025-01-19   1.0\n",
      "384       D518294 2025-06-05   1.0\n",
      "385       D518294 2025-06-05   1.0\n",
      "386        359111 2022-12-14   NaN\n",
      "387       L-30230 2023-11-02   NaN\n",
      "\n",
      "[388 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA\n",
      "0  100138 2015-01-01   NaN\n",
      "1  100138 2015-01-02   NaN\n",
      "2  100138 2015-01-03   NaN\n",
      "3  100138 2015-01-04   NaN\n",
      "4  100138 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "   SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  59571 2016-10-23   1.0         NaN      3.3692         NaN         NaN   \n",
      "1  59571 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "2  59571 1996-04-16   1.0       3.522      3.3621       3.202      3.0414   \n",
      "3  59572 2016-09-18   1.0         NaN      3.3607         NaN         NaN   \n",
      "4  59572 2006-01-29   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS21 T  H-Y POS22 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2      2.8818         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS23 T  H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2       3.616         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 168 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "    SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  100138 2015-01-01   NaN         NaN         NaN         NaN         NaN   \n",
      "1  100138 2015-01-02   NaN         NaN         NaN         NaN         NaN   \n",
      "2  100138 2015-01-03   NaN         NaN         NaN         NaN         NaN   \n",
      "3  100138 2015-01-04   NaN         NaN         NaN         NaN         NaN   \n",
      "4  100138 2015-01-05   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS21 T  H-Y POS22 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS23 T  H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 168 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# FUNCIONES PARA LLAMAR\n",
    "# ---------------------------\n",
    "def get_df_RTRA():\n",
    "    return df_RTRA\n",
    "\n",
    "def get_df_extendida_RTRA():\n",
    "    return df_extendida\n",
    "\n",
    "def get_df_detalles_RTRA():\n",
    "    return df_detalles\n",
    "\n",
    "def get_df_detalles_ext_RTRA():\n",
    "    return df_detalles_ext\n",
    "\n",
    "# ---------------------------\n",
    "# PRINT DE TABLAS\n",
    "# ---------------------------\n",
    "print('\\n ====== TABLA CON FECHAS ORIGINALES ====== \\n')\n",
    "print(get_df_RTRA(), '\\n')\n",
    "print('\\n ====== TABLA CON FECHAS EXTENDIDAS ====== \\n')\n",
    "print(get_df_extendida_RTRA().head(), '\\n')\n",
    "print('\\n ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \\n')\n",
    "print(get_df_detalles_RTRA().head(), '\\n')\n",
    "print('\\n ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \\n')\n",
    "print(get_df_detalles_ext_RTRA().head(), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
