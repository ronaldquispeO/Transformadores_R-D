{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcda64d",
   "metadata": {},
   "source": [
    "### Importación de librerías y dirección del path donde están los scripts de .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c867c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "from sqlalchemy.types import Date\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\")\n",
    "sys.path.append(r\"C:\\Users\\RONALD Q\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca74e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx\n",
      "¡Éxito! 166 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'SUBESTACION', 'CIRCUITO', 'FASE', 'TENSION', 'POT. INSTALADA', 'POT. PLACA', 'RELACION TRANSFORMACION', 'MARCA', 'Año Fab.', 'POTENCIA', 'POS. TAP', 'TENSION TAP']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "# ---------------------------\n",
    "# CARGA DEL ARCHIVO\n",
    "# ---------------------------\n",
    "addresses = [\n",
    "    'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx',\n",
    "    'C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx',\n",
    "    'C:/Users/mticllacu/OneDrive - LUZ DEL SUR S.A.A/Archivos de Ronald Quispe Ocaña - ProyectoRyD_V2/Basededatos/detalles_transformadores.xlsx'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in addresses:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_excel(path)\n",
    "        print(f\"✅ Archivo cargado desde: {path}\")\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    raise FileNotFoundError(\"❌ No se encontró el archivo en ninguna de las rutas especificadas.\")\n",
    "\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "    \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df.to_sql('bd_detalles', engine, if_exists='replace', index=False, schema='master_v2')\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026901f2",
   "metadata": {},
   "source": [
    "### Carga automática de tabla de índice generla(HI) a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca8643",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'processed_v2' con nombre de tabla 'hi_general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd75987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/DGA.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA   DGA\n",
      "0    146660T3 2022-05-12  2.65\n",
      "1    146660T3 2017-03-10  2.30\n",
      "2    146660T3 2015-06-19  1.75\n",
      "3    146660T3 2013-10-22  1.90\n",
      "4      364076 2022-06-18  1.75\n",
      "5      364076 2017-06-11  2.35\n",
      "6      364076 2016-01-15  1.30\n",
      "7      364076 2014-11-15  2.65\n",
      "8   230531-01 2024-07-16  2.80\n",
      "9   230531-01 2016-11-15  3.95\n",
      "10  230531-01 2015-03-29  3.55\n",
      "11  230531-01 2014-06-10  1.90\n",
      "12     338118 2024-11-13  2.35\n",
      "13     338118 2016-12-19  2.35\n",
      "14     338118 2015-01-27  2.10\n",
      "15     338118 2013-12-13  1.30 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "        SERIE      FECHA   DGA\n",
      "15795  364076 2025-10-20  1.75\n",
      "15796  364076 2025-10-21  1.75\n",
      "15797  364076 2025-10-22  1.75\n",
      "15798  364076 2025-10-23  1.75\n",
      "15799  364076 2025-10-24  1.75 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA   DGA   H2  CH4  C2H2  C2H4  C2H6    CO    CO2     O2\n",
      "0  146660T3 2022-05-12  2.65  179   53    17   314   139  1491   5095  10843\n",
      "1  146660T3 2017-03-10  2.30   75   42    29   134    10   962   1588  16321\n",
      "2  146660T3 2015-06-19  1.75  175  118     8   177    26   858  14735  15477\n",
      "3  146660T3 2013-10-22  1.90  163  264    17    21    30   537  15494   3637\n",
      "4    364076 2022-06-18  1.75   90   71     1   332    89   444  16063  19419 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE DGA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "        SERIE      FECHA   DGA    H2    CH4  C2H2   C2H4  C2H6     CO  \\\n",
      "11840  338118 2025-10-15  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11841  338118 2025-10-16  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11842  338118 2025-10-17  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11843  338118 2025-10-18  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11844  338118 2025-10-19  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11845  338118 2025-10-20  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11846  338118 2025-10-21  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11847  338118 2025-10-22  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11848  338118 2025-10-23  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "11849  338118 2025-10-24  2.35  32.0  212.0   2.0  598.0  81.0  622.0   \n",
      "\n",
      "           CO2      O2  \n",
      "11840  12135.0  6498.0  \n",
      "11841  12135.0  6498.0  \n",
      "11842  12135.0  6498.0  \n",
      "11843  12135.0  6498.0  \n",
      "11844  12135.0  6498.0  \n",
      "11845  12135.0  6498.0  \n",
      "11846  12135.0  6498.0  \n",
      "11847  12135.0  6498.0  \n",
      "11848  12135.0  6498.0  \n",
      "11849  12135.0  6498.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/ACE.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA       ACE\n",
      "0    146660T3 2022-05-12  4.090909\n",
      "1    146660T3 2018-09-17  3.636364\n",
      "2    146660T3 2015-08-19  2.909091\n",
      "3    146660T3 2013-02-19  3.545455\n",
      "4      364076 2022-06-18  2.181818\n",
      "5      364076 2021-08-06  4.000000\n",
      "6      364076 2017-12-06  3.181818\n",
      "7      364076 2012-10-19  4.272727\n",
      "8   230531-01 2024-07-16  4.000000\n",
      "9   230531-01 2021-01-29  3.454545\n",
      "10  230531-01 2018-01-16  3.545455\n",
      "11  230531-01 2013-01-03  3.090909\n",
      "12     338118 2024-11-13  2.363636\n",
      "13     338118 2017-06-15  3.727273\n",
      "14     338118 2015-02-24  3.181818\n",
      "15     338118 2014-08-27  4.181818\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA       ACE\n",
      "0  146660T3 2015-01-01  3.545455\n",
      "1  146660T3 2015-01-02  3.545455\n",
      "2  146660T3 2015-01-03  3.545455\n",
      "3  146660T3 2015-01-04  3.545455\n",
      "4  146660T3 2015-01-05  3.545455\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA       ACE  FP25  FP100  HU    AC  TIF  CO  RD    IO\n",
      "0  146660T3 2022-05-12  4.090909   1.3      7  91  0.06   41   6  31  0.31\n",
      "1  146660T3 2018-09-17  3.636364   0.3      9  41  0.07   43   2  15  0.25\n",
      "2  146660T3 2015-08-19  2.909091   0.3      1  77  0.06   31   3  38  0.26\n",
      "3  146660T3 2013-02-19  3.545455   0.6      5  63  0.02   29   0  39  0.35\n",
      "4    364076 2022-06-18  2.181818   0.1      4  43  0.08   41   3  46  0.21\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA       ACE  FP25  FP100    HU    AC   TIF   CO    RD  \\\n",
      "0  146660T3 2015-01-01  3.545455   0.6    5.0  63.0  0.02  29.0  0.0  39.0   \n",
      "1  146660T3 2015-01-02  3.545455   0.6    5.0  63.0  0.02  29.0  0.0  39.0   \n",
      "2  146660T3 2015-01-03  3.545455   0.6    5.0  63.0  0.02  29.0  0.0  39.0   \n",
      "3  146660T3 2015-01-04  3.545455   0.6    5.0  63.0  0.02  29.0  0.0  39.0   \n",
      "4  146660T3 2015-01-05  3.545455   0.6    5.0  63.0  0.02  29.0  0.0  39.0   \n",
      "\n",
      "     IO  \n",
      "0  0.35  \n",
      "1  0.35  \n",
      "2  0.35  \n",
      "3  0.35  \n",
      "4  0.35  \n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDEV.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:62: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f\"tasa_{gas}\"] = df.groupby(\"SERIE\").apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:116: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\DGA.py:124: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:148: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ACE.py:155: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ROHM\"] = df[score_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:90: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrohm.py:97: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  ROHM\n",
      "0    146660T3 2022-05-12   5.0\n",
      "1    146660T3 2021-07-08   5.0\n",
      "2    146660T3 2019-09-09   5.0\n",
      "3    146660T3 2018-03-03   1.0\n",
      "4      364076 2022-06-18   5.0\n",
      "5      364076 2019-01-12   5.0\n",
      "6      364076 2017-06-13   5.0\n",
      "7      364076 2015-01-10   1.0\n",
      "8   230531-01 2024-07-16   5.0\n",
      "9   230531-01 2017-10-16   5.0\n",
      "10  230531-01 2016-08-08   5.0\n",
      "11  230531-01 2015-12-31   1.0\n",
      "12     338118 2024-11-13   5.0\n",
      "13     338118 2020-09-18   5.0\n",
      "14     338118 2018-08-23   5.0\n",
      "15     338118 2016-11-07   1.0 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  ROHM\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "0  146660T3 2022-05-12   5.0             119.972             144.530   \n",
      "1  146660T3 2021-07-08   5.0             119.547             151.467   \n",
      "2  146660T3 2019-09-09   5.0             135.782             134.007   \n",
      "3  146660T3 2018-03-03   1.0             130.783             147.966   \n",
      "4    364076 2022-06-18   5.0             134.255             123.959   \n",
      "\n",
      "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
      "0             141.528             126.792             129.259   \n",
      "1             148.022             150.973             128.435   \n",
      "2             105.708             118.009             128.354   \n",
      "3             143.770             111.817             139.191   \n",
      "4             142.857             111.972             114.735   \n",
      "\n",
      "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "0             133.276             145.122  ...              139.530   \n",
      "1             159.888             156.112  ...              114.972   \n",
      "2             138.942             157.732  ...              142.943   \n",
      "3             140.366             123.187  ...              109.539   \n",
      "4             128.979             131.346  ...              116.811   \n",
      "\n",
      "   H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "0              117.181              105.375              143.185   \n",
      "1              158.177              131.723              152.473   \n",
      "2              157.936              136.143              137.432   \n",
      "3              121.162              126.707              132.010   \n",
      "4              141.326              156.980              106.554   \n",
      "\n",
      "   X POS1 R 75°C[mΩ]  X POS1 S 75°C[mΩ]  X POS1 T 75°C[mΩ]  Y POS1 R 75°C[mΩ]  \\\n",
      "0             27.998              7.492             25.014                NaN   \n",
      "1             78.062             38.596             17.474                NaN   \n",
      "2              6.049             30.624             75.912                NaN   \n",
      "3             76.903             47.650             88.398                NaN   \n",
      "4             97.623             71.297             65.690                NaN   \n",
      "\n",
      "   Y POS1 S 75°C[mΩ]  Y POS1 T 75°C[mΩ]  \n",
      "0                NaN                NaN  \n",
      "1                NaN                NaN  \n",
      "2                NaN                NaN  \n",
      "3                NaN                NaN  \n",
      "4                NaN                NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  ROHM  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
      "0  146660T3 2015-01-01   NaN                 NaN                 NaN   \n",
      "1  146660T3 2015-01-02   NaN                 NaN                 NaN   \n",
      "2  146660T3 2015-01-03   NaN                 NaN                 NaN   \n",
      "3  146660T3 2015-01-04   NaN                 NaN                 NaN   \n",
      "4  146660T3 2015-01-05   NaN                 NaN                 NaN   \n",
      "\n",
      "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2                 NaN                 NaN                 NaN   \n",
      "3                 NaN                 NaN                 NaN   \n",
      "4                 NaN                 NaN                 NaN   \n",
      "\n",
      "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  ...  H POS24 T 75°C [mΩ]  \\\n",
      "0                 NaN                 NaN  ...                  NaN   \n",
      "1                 NaN                 NaN  ...                  NaN   \n",
      "2                 NaN                 NaN  ...                  NaN   \n",
      "3                 NaN                 NaN  ...                  NaN   \n",
      "4                 NaN                 NaN  ...                  NaN   \n",
      "\n",
      "   H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  H POS27 T 75°C [mΩ]  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1                  NaN                  NaN                  NaN   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3                  NaN                  NaN                  NaN   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "\n",
      "   X POS1 R 75°C[mΩ]  X POS1 S 75°C[mΩ]  X POS1 T 75°C[mΩ]  Y POS1 R 75°C[mΩ]  \\\n",
      "0                NaN                NaN                NaN                NaN   \n",
      "1                NaN                NaN                NaN                NaN   \n",
      "2                NaN                NaN                NaN                NaN   \n",
      "3                NaN                NaN                NaN                NaN   \n",
      "4                NaN                NaN                NaN                NaN   \n",
      "\n",
      "   Y POS1 S 75°C[mΩ]  Y POS1 T 75°C[mΩ]  \n",
      "0                NaN                NaN  \n",
      "1                NaN                NaN  \n",
      "2                NaN                NaN  \n",
      "3                NaN                NaN  \n",
      "4                NaN                NaN  \n",
      "\n",
      "[5 rows x 90 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RTRA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_Delta\"] = delta\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"Max_Delta\"] = df[delta_cols].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"RTRA\"] = df[\"Max_Delta\"].apply(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida = df_extendida.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRrtra.py:87: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles = df_extendida_detalles.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:79: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_DIS_ext = df_DIS_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\ARRdis.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  RTRA\n",
      "0    146660T3 2022-05-12     5\n",
      "1    146660T3 2019-09-09     5\n",
      "2    146660T3 2018-06-04     5\n",
      "3    146660T3 2017-04-02     1\n",
      "4      364076 2022-06-18     5\n",
      "5      364076 2019-09-22     5\n",
      "6      364076 2018-09-29     5\n",
      "7      364076 2015-01-16     1\n",
      "8   230531-01 2024-07-16     5\n",
      "9   230531-01 2018-10-25     5\n",
      "10  230531-01 2015-01-19     5\n",
      "11  230531-01 2013-12-21     1\n",
      "12     338118 2024-11-13     5\n",
      "13     338118 2018-09-10     5\n",
      "14     338118 2016-11-02     5\n",
      "15     338118 2015-07-10     1\n",
      "16     338118 2025-10-21     5 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RTRA\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  146660T3 2022-05-12     5    3.768769    3.744405    3.707801    3.671139   \n",
      "1  146660T3 2019-09-09     5    3.771300    3.746000    3.709000    3.672300   \n",
      "2  146660T3 2018-06-04     5    3.772695    3.740075    3.707455    3.674834   \n",
      "3  146660T3 2017-04-02     1    2.852500    2.824700    2.796900    2.778400   \n",
      "4    364076 2022-06-18     5    2.426000    3.805000    3.502000    3.901000   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS21 T  H-Y POS22 T  \\\n",
      "0    3.646833    3.610171    3.573509  ...          NaN          NaN   \n",
      "1    3.647800    3.611200    3.574500  ...          NaN          NaN   \n",
      "2    3.642214    3.609594    3.576974  ...          NaN          NaN   \n",
      "3    2.750500    2.722700    2.704100  ...          NaN          NaN   \n",
      "4    3.591000    2.533000    2.620000  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS23 T  H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 168 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RTRA  H-X POS1 R  H-X POS2 R  H-X POS3 R  H-X POS4 R  \\\n",
      "0  146660T3 2015-01-01   NaN         NaN         NaN         NaN         NaN   \n",
      "1  146660T3 2015-01-02   NaN         NaN         NaN         NaN         NaN   \n",
      "2  146660T3 2015-01-03   NaN         NaN         NaN         NaN         NaN   \n",
      "3  146660T3 2015-01-04   NaN         NaN         NaN         NaN         NaN   \n",
      "4  146660T3 2015-01-05   NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   H-X POS5 R  H-X POS6 R  H-X POS7 R  ...  H-Y POS21 T  H-Y POS22 T  \\\n",
      "0         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "1         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "2         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "3         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "4         NaN         NaN         NaN  ...          NaN          NaN   \n",
      "\n",
      "   H-Y POS23 T  H-Y POS24 T  H-Y POS25 T  H-Y POS26 T  H-Y POS27 T  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   X-Y POS1 R  X-Y POS1 S  X-Y POS1 T  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 168 columns] \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RDIS.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RDIS\n",
      "0  146660T3 2022-05-12   5.0\n",
      "1  146660T3 2018-02-20   5.0\n",
      "2  146660T3 2016-07-31   5.0\n",
      "3  146660T3 2015-06-06   1.0\n",
      "4    364076 2022-06-18   5.0 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RDIS\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RDIS  H-X 1 [%] ONAF 2  H-X 14 [%] ONAF 2  \\\n",
      "0  146660T3 2022-05-12   5.0            11.720             11.070   \n",
      "1  146660T3 2018-02-20   5.0            11.438              5.847   \n",
      "2  146660T3 2016-07-31   5.0             6.925             11.276   \n",
      "3  146660T3 2015-06-06   1.0             5.967             11.012   \n",
      "4    364076 2022-06-18   5.0             8.346              9.233   \n",
      "\n",
      "   H-X 27 [%] ONAF 2  H-Y 1 [%]  H-Y 14 [%]  H-Y 27 [%]  X-Y 1 [%]  X-Y 2 [%]  \\\n",
      "0             10.670        NaN         NaN         NaN        NaN        NaN   \n",
      "1              9.928        NaN         NaN         NaN        NaN        NaN   \n",
      "2              7.360        NaN         NaN         NaN        NaN        NaN   \n",
      "3              6.140        NaN         NaN         NaN        NaN        NaN   \n",
      "4              8.207        NaN         NaN         NaN        NaN        NaN   \n",
      "\n",
      "   X-Y 3 [%]  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN   \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RDIS  H-X 1 [%] ONAF 2  H-X 14 [%] ONAF 2  \\\n",
      "0  146660T3 2015-01-01   NaN               NaN                NaN   \n",
      "1  146660T3 2015-01-02   NaN               NaN                NaN   \n",
      "2  146660T3 2015-01-03   NaN               NaN                NaN   \n",
      "3  146660T3 2015-01-04   NaN               NaN                NaN   \n",
      "4  146660T3 2015-01-05   NaN               NaN                NaN   \n",
      "\n",
      "   H-X 27 [%] ONAF 2  H-Y 1 [%]  H-Y 14 [%]  H-Y 27 [%]  X-Y 1 [%]  X-Y 2 [%]  \\\n",
      "0                NaN        NaN         NaN         NaN        NaN        NaN   \n",
      "1                NaN        NaN         NaN         NaN        NaN        NaN   \n",
      "2                NaN        NaN         NaN         NaN        NaN        NaN   \n",
      "3                NaN        NaN         NaN         NaN        NaN        NaN   \n",
      "4                NaN        NaN         NaN         NaN        NaN        NaN   \n",
      "\n",
      "   X-Y 3 [%]  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN   \n",
      "\n",
      "        SERIE      FECHA  ARR  ROHM  RTRA  RDIS\n",
      "0    146660T3 2015-06-06  1.0   NaN   NaN   1.0\n",
      "1    146660T3 2016-07-31  5.0   NaN   NaN   5.0\n",
      "2    146660T3 2017-04-02  1.0   NaN   1.0   NaN\n",
      "3    146660T3 2018-02-20  5.0   NaN   NaN   5.0\n",
      "4    146660T3 2018-03-03  1.0   1.0   NaN   NaN\n",
      "5    146660T3 2018-06-04  5.0   NaN   5.0   NaN\n",
      "6    146660T3 2019-09-09  5.0   5.0   5.0   NaN\n",
      "7    146660T3 2021-07-08  5.0   5.0   NaN   NaN\n",
      "8    146660T3 2022-05-12  5.0   5.0   5.0   5.0\n",
      "9   230531-01 2013-09-08  1.0   NaN   NaN   1.0\n",
      "10  230531-01 2013-12-21  1.0   NaN   1.0   NaN\n",
      "11  230531-01 2015-01-19  5.0   NaN   5.0   NaN\n",
      "12  230531-01 2015-03-08  5.0   NaN   NaN   5.0\n",
      "13  230531-01 2015-12-31  1.0   1.0   NaN   NaN\n",
      "14  230531-01 2016-08-08  5.0   5.0   NaN   NaN\n",
      "15  230531-01 2017-10-16  5.0   5.0   NaN   NaN\n",
      "16  230531-01 2018-04-14  5.0   NaN   NaN   5.0\n",
      "17  230531-01 2018-10-25  5.0   NaN   5.0   NaN\n",
      "18  230531-01 2024-07-16  5.0   5.0   5.0   5.0\n",
      "19     338118 2013-09-15  1.0   NaN   NaN   1.0\n",
      "20     338118 2014-04-14  5.0   NaN   NaN   5.0\n",
      "21     338118 2015-02-24  5.0   NaN   NaN   5.0\n",
      "22     338118 2015-07-10  1.0   NaN   1.0   NaN\n",
      "23     338118 2016-11-02  5.0   NaN   5.0   NaN\n",
      "24     338118 2016-11-07  1.0   1.0   NaN   NaN\n",
      "25     338118 2018-08-23  5.0   5.0   NaN   NaN\n",
      "26     338118 2018-09-10  5.0   NaN   5.0   NaN\n",
      "27     338118 2020-09-18  5.0   5.0   NaN   NaN\n",
      "28     338118 2024-11-13  5.0   5.0   5.0   5.0\n",
      "29     338118 2025-10-21  5.0   NaN   5.0   NaN\n",
      "30     364076 2013-12-30  1.0   NaN   NaN   1.0\n",
      "31     364076 2015-01-10  1.0   1.0   NaN   NaN\n",
      "32     364076 2015-01-16  1.0   NaN   1.0   NaN\n",
      "33     364076 2015-08-03  5.0   NaN   NaN   5.0\n",
      "34     364076 2017-06-13  5.0   5.0   NaN   NaN\n",
      "35     364076 2017-11-30  5.0   NaN   NaN   5.0\n",
      "36     364076 2018-09-29  5.0   NaN   5.0   NaN\n",
      "37     364076 2019-01-12  5.0   5.0   NaN   NaN\n",
      "38     364076 2019-09-22  5.0   NaN   5.0   NaN\n",
      "39     364076 2022-06-18  5.0   5.0   5.0   5.0\n",
      "         SERIE      FECHA       ARR  ROHM  RTRA  RDIS\n",
      "1247  146660T3 2018-06-01  2.538462   1.0   1.0   5.0\n",
      "1248  146660T3 2018-06-02  2.538462   1.0   1.0   5.0\n",
      "1249  146660T3 2018-06-03  2.538462   1.0   1.0   5.0\n",
      "1250  146660T3 2018-06-04  4.076923   1.0   5.0   5.0\n",
      "1251  146660T3 2018-06-05  4.076923   1.0   5.0   5.0\n",
      "1252  146660T3 2018-06-06  4.076923   1.0   5.0   5.0\n",
      "1253  146660T3 2018-06-07  4.076923   1.0   5.0   5.0\n",
      "1254  146660T3 2018-06-08  4.076923   1.0   5.0   5.0\n",
      "1255  146660T3 2018-06-09  4.076923   1.0   5.0   5.0\n",
      "1256  146660T3 2018-06-10  4.076923   1.0   5.0   5.0\n",
      "1257  146660T3 2018-06-11  4.076923   1.0   5.0   5.0\n",
      "1258  146660T3 2018-06-12  4.076923   1.0   5.0   5.0\n",
      "1259  146660T3 2018-06-13  4.076923   1.0   5.0   5.0\n",
      "1260  146660T3 2018-06-14  4.076923   1.0   5.0   5.0\n",
      "1261  146660T3 2018-06-15  4.076923   1.0   5.0   5.0\n",
      "1262  146660T3 2018-06-16  4.076923   1.0   5.0   5.0\n",
      "1263  146660T3 2018-06-17  4.076923   1.0   5.0   5.0\n",
      "1264  146660T3 2018-06-18  4.076923   1.0   5.0   5.0\n",
      "1265  146660T3 2018-06-19  4.076923   1.0   5.0   5.0\n",
      "1266  146660T3 2018-06-20  4.076923   1.0   5.0   5.0\n",
      "1267  146660T3 2018-06-21  4.076923   1.0   5.0   5.0\n",
      "1268  146660T3 2018-06-22  4.076923   1.0   5.0   5.0\n",
      "1269  146660T3 2018-06-23  4.076923   1.0   5.0   5.0\n",
      "1270  146660T3 2018-06-24  4.076923   1.0   5.0   5.0\n",
      "1271  146660T3 2018-06-25  4.076923   1.0   5.0   5.0\n",
      "1272  146660T3 2018-06-26  4.076923   1.0   5.0   5.0\n",
      "1273  146660T3 2018-06-27  4.076923   1.0   5.0   5.0\n",
      "1274  146660T3 2018-06-28  4.076923   1.0   5.0   5.0\n",
      "1275  146660T3 2018-06-29  4.076923   1.0   5.0   5.0\n",
      "1276  146660T3 2018-06-30  4.076923   1.0   5.0   5.0\n",
      "None\n",
      "         SERIE      FECHA       ARR\n",
      "1247  146660T3 2018-06-01  2.538462\n",
      "1248  146660T3 2018-06-02  2.538462\n",
      "1249  146660T3 2018-06-03  2.538462\n",
      "1250  146660T3 2018-06-04  4.076923\n",
      "1251  146660T3 2018-06-05  4.076923\n",
      "1252  146660T3 2018-06-06  4.076923\n",
      "1253  146660T3 2018-06-07  4.076923\n",
      "1254  146660T3 2018-06-08  4.076923\n",
      "1255  146660T3 2018-06-09  4.076923\n",
      "1256  146660T3 2018-06-10  4.076923\n",
      "1257  146660T3 2018-06-11  4.076923\n",
      "1258  146660T3 2018-06-12  4.076923\n",
      "1259  146660T3 2018-06-13  4.076923\n",
      "1260  146660T3 2018-06-14  4.076923\n",
      "1261  146660T3 2018-06-15  4.076923\n",
      "1262  146660T3 2018-06-16  4.076923\n",
      "1263  146660T3 2018-06-17  4.076923\n",
      "1264  146660T3 2018-06-18  4.076923\n",
      "1265  146660T3 2018-06-19  4.076923\n",
      "1266  146660T3 2018-06-20  4.076923\n",
      "1267  146660T3 2018-06-21  4.076923\n",
      "1268  146660T3 2018-06-22  4.076923\n",
      "1269  146660T3 2018-06-23  4.076923\n",
      "1270  146660T3 2018-06-24  4.076923\n",
      "1271  146660T3 2018-06-25  4.076923\n",
      "1272  146660T3 2018-06-26  4.076923\n",
      "1273  146660T3 2018-06-27  4.076923\n",
      "1274  146660T3 2018-06-28  4.076923\n",
      "1275  146660T3 2018-06-29  4.076923\n",
      "1276  146660T3 2018-06-30  4.076923\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n",
      "\n",
      " ====== TABLA FPDEVANADO ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA  FPDEVANADO\n",
      "0    146660T3 2022-05-12         5.0\n",
      "1    146660T3 2018-05-21         5.0\n",
      "2    146660T3 2015-05-28         5.0\n",
      "3    146660T3 2013-09-30         5.0\n",
      "4      364076 2022-06-18         5.0\n",
      "5      364076 2020-03-07         5.0\n",
      "6      364076 2016-02-28         5.0\n",
      "7      364076 2014-05-02         5.0\n",
      "8   230531-01 2024-07-16         5.0\n",
      "9   230531-01 2016-06-21         5.0\n",
      "10  230531-01 2015-06-18         5.0\n",
      "11  230531-01 2014-01-20         5.0\n",
      "12     338118 2024-11-13         5.0\n",
      "13     338118 2018-08-29         5.0\n",
      "14     338118 2017-12-18         5.0\n",
      "15     338118 2016-09-02         5.0 \n",
      "\n",
      "\n",
      " ====== TABLA FPDEVANADO EXTENDIDA ====== \n",
      "\n",
      "      SERIE      FECHA  FPDEVANADO\n",
      "0  146660T3 2015-01-01         5.0\n",
      "1  146660T3 2015-01-02         5.0\n",
      "2  146660T3 2015-01-03         5.0\n",
      "3  146660T3 2015-01-04         5.0\n",
      "4  146660T3 2015-01-05         5.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPDEVANADO ====== \n",
      "\n",
      "      SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  \\\n",
      "0  146660T3 2022-05-12         0.239    0.960     0.303     0.942   \n",
      "1  146660T3 2018-05-21         1.023    0.648     1.306     0.850   \n",
      "2  146660T3 2015-05-28         0.454    0.376     1.237     1.065   \n",
      "3  146660T3 2013-09-30         0.516    0.921     0.449     0.691   \n",
      "4    364076 2022-06-18         1.290    0.552     0.614     1.008   \n",
      "\n",
      "   X ICL+ICLT+ICLH %  X ICL+ICLT %  X ICL %  X ICLT %  X ICLH %  \\\n",
      "0              0.834         1.021    0.518     0.956     0.609   \n",
      "1              0.920         0.263    0.627     1.030     1.084   \n",
      "2              0.245         1.202    0.595     0.262     1.009   \n",
      "3              0.124         1.236    0.451     0.124     0.295   \n",
      "4              1.241         0.204    0.238     0.840     0.310   \n",
      "\n",
      "   Y ICT+ICTH+ICTL %  Y ICT+ICTH %  Y ICT %  Y ICTH %  Y ICTL %  FPDEVANADO  \n",
      "0              0.866         1.131    0.909     0.770     1.093         5.0  \n",
      "1              0.329         1.144    0.302     0.166     0.811         5.0  \n",
      "2              0.312         1.055    0.516     0.169     0.836         5.0  \n",
      "3              0.399         0.644    1.300     0.797     0.636         5.0  \n",
      "4              0.212         0.387    0.458     0.339     0.188         5.0   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPDEVANADO ====== \n",
      "\n",
      "      SERIE      FECHA  H ICH+ICHL %  H ICH %  H ICHL %  H ICHT %  \\\n",
      "0  146660T3 2015-01-01         0.516    0.921     0.449     0.691   \n",
      "1  146660T3 2015-01-02         0.516    0.921     0.449     0.691   \n",
      "2  146660T3 2015-01-03         0.516    0.921     0.449     0.691   \n",
      "3  146660T3 2015-01-04         0.516    0.921     0.449     0.691   \n",
      "4  146660T3 2015-01-05         0.516    0.921     0.449     0.691   \n",
      "\n",
      "   X ICL+ICLT+ICLH %  X ICL+ICLT %  X ICL %  X ICLT %  X ICLH %  \\\n",
      "0              0.124         1.236    0.451     0.124     0.295   \n",
      "1              0.124         1.236    0.451     0.124     0.295   \n",
      "2              0.124         1.236    0.451     0.124     0.295   \n",
      "3              0.124         1.236    0.451     0.124     0.295   \n",
      "4              0.124         1.236    0.451     0.124     0.295   \n",
      "\n",
      "   Y ICT+ICTH+ICTL %  Y ICT+ICTH %  Y ICT %  Y ICTH %  Y ICTL %  FPDEVANADO  \n",
      "0              0.399         0.644      1.3     0.797     0.636         5.0  \n",
      "1              0.399         0.644      1.3     0.797     0.636         5.0  \n",
      "2              0.399         0.644      1.3     0.797     0.636         5.0  \n",
      "3              0.399         0.644      1.3     0.797     0.636         5.0  \n",
      "4              0.399         0.644      1.3     0.797     0.636         5.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPDEVANADO.xlsx\n",
      "\n",
      " ====== TABLA CD ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA   CD\n",
      "0    146660T3 2022-05-12  5.0\n",
      "1    146660T3 2018-05-21  5.0\n",
      "2    146660T3 2015-05-28  5.0\n",
      "3    146660T3 2013-09-30  1.0\n",
      "4      364076 2022-06-18  5.0\n",
      "5      364076 2020-03-07  5.0\n",
      "6      364076 2016-02-28  5.0\n",
      "7      364076 2014-05-02  1.0\n",
      "8   230531-01 2024-07-16  5.0\n",
      "9   230531-01 2016-06-21  5.0\n",
      "10  230531-01 2015-06-18  5.0\n",
      "11  230531-01 2014-01-20  1.0\n",
      "12     338118 2024-11-13  5.0\n",
      "13     338118 2018-08-29  5.0\n",
      "14     338118 2017-12-18  5.0\n",
      "15     338118 2016-09-02  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA CD EXTENDIDA ====== \n",
      "\n",
      "      SERIE      FECHA   CD\n",
      "0  146660T3 2015-01-01  1.0\n",
      "1  146660T3 2015-01-02  1.0\n",
      "2  146660T3 2015-01-03  1.0\n",
      "3  146660T3 2015-01-04  1.0\n",
      "4  146660T3 2015-01-05  1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CD ====== \n",
      "\n",
      "      SERIE      FECHA   CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  H ICHT pF  \\\n",
      "0  146660T3 2022-05-12  5.0            887     14294       2385       3283   \n",
      "1  146660T3 2018-05-21  5.0           3266     14844       4973       4378   \n",
      "2  146660T3 2015-05-28  5.0          13595      3041      13409       4997   \n",
      "3  146660T3 2013-09-30  1.0           3575      5165       9934       2680   \n",
      "4    364076 2022-06-18  5.0          10026     10600       2284       9280   \n",
      "\n",
      "   X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  Y ICT+ICTH pF  Y ICT pF  \\\n",
      "0           9684      5342       3452       2346           9356     11655   \n",
      "1           7656      6827       6171       1473           1099     14150   \n",
      "2           3363      9453       4502       9393           1027     11178   \n",
      "3           3167      2562       9573       2551           7384     13682   \n",
      "4           4685      2261       9140        975           6427      7625   \n",
      "\n",
      "   Y ICTH pF  Y ICTL pF  \n",
      "0       2163      14602  \n",
      "1      10186       6119  \n",
      "2       1726       6417  \n",
      "3      12874      13864  \n",
      "4      11516      10686   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CD ====== \n",
      "\n",
      "      SERIE      FECHA   CD  H ICH+ICHL pF  H ICH pF  H ICHL pF  H ICHT pF  \\\n",
      "0  146660T3 2015-01-01  1.0         3575.0    5165.0     9934.0     2680.0   \n",
      "1  146660T3 2015-01-02  1.0         3575.0    5165.0     9934.0     2680.0   \n",
      "2  146660T3 2015-01-03  1.0         3575.0    5165.0     9934.0     2680.0   \n",
      "3  146660T3 2015-01-04  1.0         3575.0    5165.0     9934.0     2680.0   \n",
      "4  146660T3 2015-01-05  1.0         3575.0    5165.0     9934.0     2680.0   \n",
      "\n",
      "   X ICL+ICLT pF  X ICL pF  X ICLT pF  X ICLH pF  Y ICT+ICTH pF  Y ICT pF  \\\n",
      "0         3167.0    2562.0     9573.0     2551.0         7384.0   13682.0   \n",
      "1         3167.0    2562.0     9573.0     2551.0         7384.0   13682.0   \n",
      "2         3167.0    2562.0     9573.0     2551.0         7384.0   13682.0   \n",
      "3         3167.0    2562.0     9573.0     2551.0         7384.0   13682.0   \n",
      "4         3167.0    2562.0     9573.0     2551.0         7384.0   13682.0   \n",
      "\n",
      "   Y ICTH pF  Y ICTL pF  \n",
      "0    12874.0    13864.0  \n",
      "1    12874.0    13864.0  \n",
      "2    12874.0    13864.0  \n",
      "3    12874.0    13864.0  \n",
      "4    12874.0    13864.0   \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FURANOS.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  FUR\n",
      "0    146660T3 2022-05-12  1.0\n",
      "1    146660T3 2020-06-13  1.0\n",
      "2    146660T3 2019-01-25  1.0\n",
      "3    146660T3 2018-08-09  1.0\n",
      "4      364076 2022-06-18  1.0\n",
      "5      364076 2020-06-13  1.0\n",
      "6      364076 2016-01-21  1.0\n",
      "7      364076 2015-05-02  2.0\n",
      "8   230531-01 2024-07-16  2.0\n",
      "9   230531-01 2020-05-12  2.0\n",
      "10  230531-01 2018-07-05  2.0\n",
      "11  230531-01 2015-04-26  2.0\n",
      "12     338118 2024-11-13  2.0\n",
      "13     338118 2019-10-28  2.0\n",
      "14     338118 2018-03-17  2.0\n",
      "15     338118 2015-11-14  2.0 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  FUR\n",
      "0      146660T3 2015-01-01  NaN\n",
      "1      146660T3 2015-01-02  NaN\n",
      "2      146660T3 2015-01-03  NaN\n",
      "3      146660T3 2015-01-04  NaN\n",
      "4      146660T3 2015-01-05  NaN\n",
      "...         ...        ...  ...\n",
      "15795    364076 2025-10-20  1.0\n",
      "15796    364076 2025-10-21  1.0\n",
      "15797    364076 2025-10-22  1.0\n",
      "15798    364076 2025-10-23  1.0\n",
      "15799    364076 2025-10-24  1.0\n",
      "\n",
      "[15800 rows x 3 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0    146660T3 2022-05-12                            1  1.0\n",
      "1    146660T3 2020-06-13                            1  1.0\n",
      "2    146660T3 2019-01-25                            1  1.0\n",
      "3    146660T3 2018-08-09                            1  1.0\n",
      "4      364076 2022-06-18                            1  1.0\n",
      "5      364076 2020-06-13                            2  1.0\n",
      "6      364076 2016-01-21                            2  1.0\n",
      "7      364076 2015-05-02                          143  2.0\n",
      "8   230531-01 2024-07-16                          160  2.0\n",
      "9   230531-01 2020-05-12                          207  2.0\n",
      "10  230531-01 2018-07-05                          319  2.0\n",
      "11  230531-01 2015-04-26                          263  2.0\n",
      "12     338118 2024-11-13                          132  2.0\n",
      "13     338118 2019-10-28                          241  2.0\n",
      "14     338118 2018-03-17                          388  2.0\n",
      "15     338118 2015-11-14                          335  2.0 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES DE FUR CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "          SERIE      FECHA  2-Furfuraldehido (FAL, ppb)  FUR\n",
      "0      146660T3 2015-01-01                          NaN  NaN\n",
      "1      146660T3 2015-01-02                          NaN  NaN\n",
      "2      146660T3 2015-01-03                          NaN  NaN\n",
      "3      146660T3 2015-01-04                          NaN  NaN\n",
      "4      146660T3 2015-01-05                          NaN  NaN\n",
      "...         ...        ...                          ...  ...\n",
      "15795    364076 2025-10-20                          1.0  1.0\n",
      "15796    364076 2025-10-21                          1.0  1.0\n",
      "15797    364076 2025-10-22                          1.0  1.0\n",
      "15798    364076 2025-10-23                          1.0  1.0\n",
      "15799    364076 2025-10-24                          1.0  1.0\n",
      "\n",
      "[15800 rows x 4 columns] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fp['Max_FP'] = df_fp[[c for c in df_fp.columns if c.endswith('%')]].max(axis=1)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[columna_puntaje] = np.select(\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:82: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP = df_extendida_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FP.py:90: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP = df_detalles_ext_FP.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_cd.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CD = df_extendida_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CD.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CD = df_detalles_ext_CD.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:69: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FUR = df_extendida_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FURANOS.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_detalles_FUR = df_extendida_detalles_FUR.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SERIE      FECHA  AIS  FPDEVANADO   CD  FUR\n",
      "0  146660T3 2013-09-30  2.6         5.0  1.0  NaN\n",
      "1  146660T3 2015-05-28  5.0         5.0  5.0  NaN\n",
      "2  146660T3 2018-05-21  5.0         5.0  5.0  NaN\n",
      "3  146660T3 2018-08-09  1.0         NaN  NaN  1.0\n",
      "4  146660T3 2019-01-25  1.0         NaN  NaN  1.0\n",
      "      SERIE      FECHA  AIS  FPDEVANADO   CD  FUR\n",
      "0  146660T3 2015-01-01  2.6         5.0  1.0  NaN\n",
      "1  146660T3 2015-01-02  2.6         5.0  1.0  NaN\n",
      "2  146660T3 2015-01-03  2.6         5.0  1.0  NaN\n",
      "3  146660T3 2015-01-04  2.6         5.0  1.0  NaN\n",
      "4  146660T3 2015-01-05  2.6         5.0  1.0  NaN\n",
      "          SERIE      FECHA       AIS\n",
      "0      146660T3 2015-01-01  2.600000\n",
      "1      146660T3 2015-01-02  2.600000\n",
      "2      146660T3 2015-01-03  2.600000\n",
      "3      146660T3 2015-01-04  2.600000\n",
      "4      146660T3 2015-01-05  2.600000\n",
      "...         ...        ...       ...\n",
      "15795    364076 2025-10-20  3.857143\n",
      "15796    364076 2025-10-21  3.857143\n",
      "15797    364076 2025-10-22  3.857143\n",
      "15798    364076 2025-10-23  3.857143\n",
      "15799    364076 2025-10-24  3.857143\n",
      "\n",
      "[15800 rows x 3 columns]\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/RNUCLEO.xlsx\n",
      "        SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0    146660T3 2022-05-12     1         665\n",
      "1    146660T3 2019-01-23     1         551\n",
      "2    146660T3 2018-02-05     1         933\n",
      "3    146660T3 2017-11-22     1         535\n",
      "4      364076 2022-06-18     1         552\n",
      "5      364076 2015-05-24     1         912\n",
      "6      364076 2014-08-13     1         928\n",
      "7      364076 2013-11-05     5         287\n",
      "8   230531-01 2024-07-16     1         618\n",
      "9   230531-01 2017-10-26     1         978\n",
      "10  230531-01 2016-03-04     5         195\n",
      "11  230531-01 2014-11-11     5         216\n",
      "12     338118 2024-11-13     1         801\n",
      "13     338118 2017-12-13     1         710\n",
      "14     338118 2016-09-05     1         916\n",
      "15     338118 2014-05-28     5         469\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  RNUC\n",
      "0    146660T3 2022-05-12     1\n",
      "1    146660T3 2019-01-23     1\n",
      "2    146660T3 2018-02-05     1\n",
      "3    146660T3 2017-11-22     1\n",
      "4      364076 2022-06-18     1\n",
      "5      364076 2015-05-24     1\n",
      "6      364076 2014-08-13     1\n",
      "7      364076 2013-11-05     5\n",
      "8   230531-01 2024-07-16     1\n",
      "9   230531-01 2017-10-26     1\n",
      "10  230531-01 2016-03-04     5\n",
      "11  230531-01 2014-11-11     5\n",
      "12     338118 2024-11-13     1\n",
      "13     338118 2017-12-13     1\n",
      "14     338118 2016-09-05     1\n",
      "15     338118 2014-05-28     5 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC\n",
      "0  146660T3 2015-01-01   NaN\n",
      "1  146660T3 2015-01-02   NaN\n",
      "2  146660T3 2015-01-03   NaN\n",
      "3  146660T3 2015-01-04   NaN\n",
      "4  146660T3 2015-01-05   NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2022-05-12     1         665\n",
      "1  146660T3 2019-01-23     1         551\n",
      "2  146660T3 2018-02-05     1         933\n",
      "3  146660T3 2017-11-22     1         535\n",
      "4    364076 2022-06-18     1         552 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  RNUC  Valor (MΩ)\n",
      "0  146660T3 2015-01-01   NaN         NaN\n",
      "1  146660T3 2015-01-02   NaN         NaN\n",
      "2  146660T3 2015-01-03   NaN         NaN\n",
      "3  146660T3 2015-01-04   NaN         NaN\n",
      "4  146660T3 2015-01-05   NaN         NaN \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/IEXCITACION.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_RNUC_ext = df_RNUC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCrnuc.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby('SERIE').apply(lambda g: g.loc[g['FECHA'].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_IEX_ext = df_IEX_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\NUCiex.py:84: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "        SERIE      FECHA  IEX\n",
      "0    146660T3 2022-05-12    5\n",
      "1    146660T3 2018-02-16    5\n",
      "2    146660T3 2017-04-15    5\n",
      "3    146660T3 2016-09-24    1\n",
      "4      364076 2022-06-18    5\n",
      "5      364076 2019-04-24    5\n",
      "6      364076 2018-03-07    5\n",
      "7      364076 2014-12-08    1\n",
      "8   230531-01 2024-07-16    5\n",
      "9   230531-01 2019-11-26    5\n",
      "10  230531-01 2018-06-12    5\n",
      "11  230531-01 2015-04-25    1\n",
      "12     338118 2024-11-13    5\n",
      "13     338118 2019-02-13    5\n",
      "14     338118 2017-10-31    5\n",
      "15     338118 2015-04-28    1 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  IEX\n",
      "0  146660T3 2015-01-01  NaN\n",
      "1  146660T3 2015-01-02  NaN\n",
      "2  146660T3 2015-01-03  NaN\n",
      "3  146660T3 2015-01-04  NaN\n",
      "4  146660T3 2015-01-05  NaN \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  146660T3 2022-05-12    5    111.235    191.629    146.622    144.914   \n",
      "1  146660T3 2018-02-16    5    188.693    114.216    133.965    194.859   \n",
      "2  146660T3 2017-04-15    5    100.873    100.875    110.410    124.139   \n",
      "3  146660T3 2016-09-24    1    128.112    143.145    103.937    109.001   \n",
      "4    364076 2022-06-18    5    142.290    180.712    173.369    194.856   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0    179.458    121.242    188.996  ...     186.193     160.812     120.611   \n",
      "1    160.695    145.281    110.364  ...     152.812     194.145     129.906   \n",
      "2    189.568    145.275    110.087  ...     155.308     115.643     121.963   \n",
      "3    169.662    195.572    117.368  ...     179.454     101.771     155.218   \n",
      "4    119.309    142.324    199.955  ...     163.629     121.602     137.777   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0     114.643     143.999     132.651     176.578     161.892     147.003   \n",
      "1     163.382     188.661     107.555     156.040     119.796     104.434   \n",
      "2     182.579     143.042     164.656     102.757     142.567     173.857   \n",
      "3     146.779     164.411     111.809     188.801     148.031     146.680   \n",
      "4     198.430     153.521     186.329     136.476     145.228     190.737   \n",
      "\n",
      "   T POS27 mA  \n",
      "0     124.753  \n",
      "1     170.016  \n",
      "2     118.402  \n",
      "3     110.143  \n",
      "4     160.036  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  IEX  R POS1 mA  R POS2 mA  R POS3 mA  R POS4 mA  \\\n",
      "0  146660T3 2015-01-01  NaN        NaN        NaN        NaN        NaN   \n",
      "1  146660T3 2015-01-02  NaN        NaN        NaN        NaN        NaN   \n",
      "2  146660T3 2015-01-03  NaN        NaN        NaN        NaN        NaN   \n",
      "3  146660T3 2015-01-04  NaN        NaN        NaN        NaN        NaN   \n",
      "4  146660T3 2015-01-05  NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   R POS5 mA  R POS6 mA  R POS7 mA  ...  T POS18 mA  T POS19 mA  T POS20 mA  \\\n",
      "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
      "\n",
      "   T POS21 mA  T POS22 mA  T POS23 mA  T POS24 mA  T POS25 mA  T POS26 mA  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   T POS27 mA  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "\n",
      "[5 rows x 84 columns] \n",
      "\n",
      "      SERIE      FECHA  NUC  RNUC  IEX\n",
      "0  146660T3 2016-09-24  1.0   NaN  1.0\n",
      "1  146660T3 2017-04-15  5.0   NaN  5.0\n",
      "2  146660T3 2017-11-22  1.0   1.0  NaN\n",
      "3  146660T3 2018-02-05  1.0   1.0  NaN\n",
      "4  146660T3 2018-02-16  5.0   NaN  5.0\n",
      "          SERIE      FECHA  NUC  RNUC  IEX\n",
      "0      146660T3 2015-01-01  NaN   NaN  NaN\n",
      "1      146660T3 2015-01-02  NaN   NaN  NaN\n",
      "2      146660T3 2015-01-03  NaN   NaN  NaN\n",
      "3      146660T3 2015-01-04  NaN   NaN  NaN\n",
      "4      146660T3 2015-01-05  NaN   NaN  NaN\n",
      "...         ...        ...  ...   ...  ...\n",
      "15795    364076 2025-10-20  3.5   1.0  5.0\n",
      "15796    364076 2025-10-21  3.5   1.0  5.0\n",
      "15797    364076 2025-10-22  3.5   1.0  5.0\n",
      "15798    364076 2025-10-23  3.5   1.0  5.0\n",
      "15799    364076 2025-10-24  3.5   1.0  5.0\n",
      "\n",
      "[15800 rows x 5 columns]\n",
      "          SERIE      FECHA  NUC\n",
      "0      146660T3 2015-01-01  NaN\n",
      "1      146660T3 2015-01-02  NaN\n",
      "2      146660T3 2015-01-03  NaN\n",
      "3      146660T3 2015-01-04  NaN\n",
      "4      146660T3 2015-01-05  NaN\n",
      "...         ...        ...  ...\n",
      "15795    364076 2025-10-20  3.5\n",
      "15796    364076 2025-10-21  3.5\n",
      "15797    364076 2025-10-22  3.5\n",
      "15798    364076 2025-10-23  3.5\n",
      "15799    364076 2025-10-24  3.5\n",
      "\n",
      "[15800 rows x 3 columns]\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FQOLTC.xlsx\n",
      "\n",
      " ====== TABLA CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2022-05-12   5.0\n",
      "1  146660T3 2018-05-12   1.0\n",
      "2  146660T3 2016-12-30   1.0\n",
      "3  146660T3 2014-03-26   2.5\n",
      "4    364076 2022-06-18   2.5 \n",
      "\n",
      "\n",
      " ====== TABLA CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC\n",
      "0  146660T3 2015-01-01   2.5\n",
      "1  146660T3 2015-01-02   2.5\n",
      "2  146660T3 2015-01-03   2.5\n",
      "3  146660T3 2015-01-04   2.5\n",
      "4  146660T3 2015-01-05   2.5 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS ORIGINALES ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC  RD  H20\n",
      "0  146660T3 2022-05-12   5.0  18   48\n",
      "1  146660T3 2018-05-12   1.0  33   12\n",
      "2  146660T3 2016-12-30   1.0  34   14\n",
      "3  146660T3 2014-03-26   2.5  48   46\n",
      "4    364076 2022-06-18   2.5  58   33 \n",
      "\n",
      "\n",
      " ====== TABLA DE DETALLES CON FECHAS EXTENDIDAS ====== \n",
      "\n",
      "      SERIE      FECHA  OLTC    RD   H20\n",
      "0  146660T3 2015-01-01   2.5  48.0  46.0\n",
      "1  146660T3 2015-01-02   2.5  48.0  46.0\n",
      "2  146660T3 2015-01-03   2.5  48.0  46.0\n",
      "3  146660T3 2015-01-04   2.5  48.0  46.0\n",
      "4  146660T3 2015-01-05   2.5  48.0  46.0 \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n",
      "\n",
      " ====== TABLA FPBC1 ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA  FPBC1\n",
      "11  230531-01 2015-02-11    5.0\n",
      "12     338118 2024-11-13    5.0\n",
      "13     338118 2022-08-19    5.0\n",
      "14     338118 2016-01-06    5.0\n",
      "15     338118 2015-09-22    5.0 \n",
      "\n",
      "\n",
      " ====== TABLA FPBC1 EXTENDIDA ====== \n",
      "\n",
      "        SERIE      FECHA  FPBC1\n",
      "15795  364076 2025-10-20    5.0\n",
      "15796  364076 2025-10-21    5.0\n",
      "15797  364076 2025-10-22    5.0\n",
      "15798  364076 2025-10-23    5.0\n",
      "15799  364076 2025-10-24    5.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC1 ====== \n",
      "\n",
      "      SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "0  146660T3 2022-05-12    3.0     0.92     0.43     0.11     0.15\n",
      "1  146660T3 2019-04-27    5.0     0.76     0.51     1.92     0.12\n",
      "2  146660T3 2015-05-15    5.0     0.23     1.09     1.40     0.43\n",
      "3  146660T3 2014-11-14    5.0     0.94     1.68     1.89     1.42\n",
      "4    364076 2022-06-18    5.0     0.32     0.72     0.59     1.87 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC1 ====== \n",
      "\n",
      "        SERIE      FECHA  FPBC1  C1 H1 %  C1 H2 %  C1 H3 %  C1 H0 %\n",
      "15795  364076 2025-10-20    5.0     0.32     0.72     0.59     1.87\n",
      "15796  364076 2025-10-21    5.0     0.32     0.72     0.59     1.87\n",
      "15797  364076 2025-10-22    5.0     0.32     0.72     0.59     1.87\n",
      "15798  364076 2025-10-23    5.0     0.32     0.72     0.59     1.87\n",
      "15799  364076 2025-10-24    5.0     0.32     0.72     0.59     1.87 \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n",
      "\n",
      " ====== TABLA FPBC2 ORIGINAL ====== \n",
      "\n",
      "      SERIE      FECHA  FPBC2\n",
      "0  146660T3 2022-05-12    5.0\n",
      "1  146660T3 2019-04-27    5.0\n",
      "2  146660T3 2015-05-15    5.0\n",
      "3  146660T3 2014-11-14    5.0\n",
      "4    364076 2022-06-18    5.0 \n",
      "\n",
      "\n",
      " ====== TABLA FPBC2 EXTENDIDA ====== \n",
      "\n",
      "        SERIE      FECHA  FPBC2\n",
      "15795  364076 2025-10-20    5.0\n",
      "15796  364076 2025-10-21    5.0\n",
      "15797  364076 2025-10-22    5.0\n",
      "15798  364076 2025-10-23    5.0\n",
      "15799  364076 2025-10-24    5.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA FPBC2 ====== \n",
      "\n",
      "      SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "0  146660T3 2022-05-12    5.0     6.65     9.90     4.73     9.83\n",
      "1  146660T3 2019-04-27    5.0     4.77     9.65     4.78     5.24\n",
      "2  146660T3 2015-05-15    5.0     3.32     0.46     2.60     8.02\n",
      "3  146660T3 2014-11-14    5.0     8.06     4.02     9.75     3.96\n",
      "4    364076 2022-06-18    5.0     1.87     8.05     2.53     1.49 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA FPBC2 ====== \n",
      "\n",
      "        SERIE      FECHA  FPBC2  C2 H1 %  C2 H2 %  C2 H3 %  C2 H0 %\n",
      "15795  364076 2025-10-20    5.0     1.87     8.05     2.53     1.49\n",
      "15796  364076 2025-10-21    5.0     1.87     8.05     2.53     1.49\n",
      "15797  364076 2025-10-22    5.0     1.87     8.05     2.53     1.49\n",
      "15798  364076 2025-10-23    5.0     1.87     8.05     2.53     1.49\n",
      "15799  364076 2025-10-24    5.0     1.87     8.05     2.53     1.49 \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n",
      "\n",
      " ====== TABLA CBC1 ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA  CBC1\n",
      "0    146660T3 2022-05-12   5.0\n",
      "1    146660T3 2019-04-27   5.0\n",
      "2    146660T3 2015-05-15   5.0\n",
      "3    146660T3 2014-11-14   1.0\n",
      "4      364076 2022-06-18   5.0\n",
      "5      364076 2019-06-27   5.0\n",
      "6      364076 2017-02-20   5.0\n",
      "7      364076 2016-12-30   1.0\n",
      "8   230531-01 2024-07-16   5.0\n",
      "9   230531-01 2022-06-26   5.0\n",
      "10  230531-01 2020-12-14   5.0\n",
      "11  230531-01 2015-02-11   1.0\n",
      "12     338118 2024-11-13   5.0\n",
      "13     338118 2022-08-19   5.0\n",
      "14     338118 2016-01-06   5.0\n",
      "15     338118 2015-09-22   1.0 \n",
      "\n",
      "\n",
      " ====== TABLA CBC1 EXTENDIDA ====== \n",
      "\n",
      "      SERIE      FECHA  CBC1\n",
      "0  146660T3 2015-01-01   1.0\n",
      "1  146660T3 2015-01-02   1.0\n",
      "2  146660T3 2015-01-03   1.0\n",
      "3  146660T3 2015-01-04   1.0\n",
      "4  146660T3 2015-01-05   1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC1 ====== \n",
      "\n",
      "      SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "0  146660T3 2022-05-12   5.0      4943      4295      1709       246\n",
      "1  146660T3 2019-04-27   5.0      2163       807      3261      4874\n",
      "2  146660T3 2015-05-15   5.0      2215      2681      3458      4995\n",
      "3  146660T3 2014-11-14   1.0       246      3372      1718      2143\n",
      "4    364076 2022-06-18   5.0      3758      4644      4239       502 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC1 ====== \n",
      "\n",
      "      SERIE      FECHA  CBC1  C1 H1 pF  C1 H2 pF  C1 H3 pF  C1 H0 pF\n",
      "0  146660T3 2015-01-01   1.0     246.0    3372.0    1718.0    2143.0\n",
      "1  146660T3 2015-01-02   1.0     246.0    3372.0    1718.0    2143.0\n",
      "2  146660T3 2015-01-03   1.0     246.0    3372.0    1718.0    2143.0\n",
      "3  146660T3 2015-01-04   1.0     246.0    3372.0    1718.0    2143.0\n",
      "4  146660T3 2015-01-05   1.0     246.0    3372.0    1718.0    2143.0 \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPC1C2.xlsx\n",
      "\n",
      " ====== TABLA CBC2 ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA  CBC2\n",
      "0    146660T3 2022-05-12   5.0\n",
      "1    146660T3 2019-04-27   5.0\n",
      "2    146660T3 2015-05-15   5.0\n",
      "3    146660T3 2014-11-14   1.0\n",
      "4      364076 2022-06-18   5.0\n",
      "5      364076 2019-06-27   5.0\n",
      "6      364076 2017-02-20   5.0\n",
      "7      364076 2016-12-30   1.0\n",
      "8   230531-01 2024-07-16   5.0\n",
      "9   230531-01 2022-06-26   5.0\n",
      "10  230531-01 2020-12-14   5.0\n",
      "11  230531-01 2015-02-11   1.0\n",
      "12     338118 2024-11-13   5.0\n",
      "13     338118 2022-08-19   5.0\n",
      "14     338118 2016-01-06   5.0\n",
      "15     338118 2015-09-22   1.0 \n",
      "\n",
      "\n",
      " ====== TABLA CBC2 EXTENDIDA ====== \n",
      "\n",
      "      SERIE      FECHA  CBC2\n",
      "0  146660T3 2015-01-01   1.0\n",
      "1  146660T3 2015-01-02   1.0\n",
      "2  146660T3 2015-01-03   1.0\n",
      "3  146660T3 2015-01-04   1.0\n",
      "4  146660T3 2015-01-05   1.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CBC2 ====== \n",
      "\n",
      "      SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 NH0 pF\n",
      "0  146660T3 2022-05-12   5.0      3779      1236      3863       3385\n",
      "1  146660T3 2019-04-27   5.0      4059      3342      1351        715\n",
      "2  146660T3 2015-05-15   5.0      3224      1120      4255       3712\n",
      "3  146660T3 2014-11-14   1.0      3471      1069       198       3445\n",
      "4    364076 2022-06-18   5.0      4343      3495      2393       2038 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CBC2 ====== \n",
      "\n",
      "      SERIE      FECHA  CBC2  C2 H1 pF  C2 H2 pF  C2 H3 pF  C2 NH0 pF\n",
      "0  146660T3 2015-01-01   1.0    3471.0    1069.0     198.0     3445.0\n",
      "1  146660T3 2015-01-02   1.0    3471.0    1069.0     198.0     3445.0\n",
      "2  146660T3 2015-01-03   1.0    3471.0    1069.0     198.0     3445.0\n",
      "3  146660T3 2015-01-04   1.0    3471.0    1069.0     198.0     3445.0\n",
      "4  146660T3 2015-01-05   1.0    3471.0    1069.0     198.0     3445.0 \n",
      "\n",
      "✅ Archivo cargado desde: C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD_V2/Basededatos/FPCOCA.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:70: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_OLTC_ext = df_OLTC_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\OLTC.py:78: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext = df_detalles_ext.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:90: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C1 = df_extendida_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC1.py:98: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C1 = df_detalles_ext_FP_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:89: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_FP_C2 = df_extendida_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPBC2.py:97: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_FP_C2 = df_detalles_ext_FP_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c1.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C1 = df_extendida_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC1.py:112: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C1 = df_detalles_ext_C_C1.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df_c_c2.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:103: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_C_C2 = df_extendida_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\CBC2.py:111: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_C_C2 = df_detalles_ext_C_C2.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:78: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extendida_CC = df_extendida_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n",
      "C:\\Users\\roquispec\\OneDrive - LUZ DEL SUR S.A.A\\Documentos\\Estudios de Ingreso\\ProyectoRyD_V2\\ScriptsPython\\FPCOCA.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_detalles_ext_CC = df_detalles_ext_CC.groupby(\"SERIE\").apply(lambda g: g.ffill()).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TABLA CC ORIGINAL ====== \n",
      "\n",
      "        SERIE      FECHA   CC\n",
      "0    146660T3 2022-05-12  5.0\n",
      "1    146660T3 2019-04-27  5.0\n",
      "2    146660T3 2015-05-15  5.0\n",
      "3    146660T3 2014-11-14  5.0\n",
      "4      364076 2022-06-18  5.0\n",
      "5      364076 2019-06-27  5.0\n",
      "6      364076 2017-02-20  5.0\n",
      "7      364076 2016-12-30  5.0\n",
      "8   230531-01 2024-07-16  5.0\n",
      "9   230531-01 2022-06-26  5.0\n",
      "10  230531-01 2020-12-14  5.0\n",
      "11  230531-01 2015-02-11  5.0\n",
      "12     338118 2024-11-13  5.0\n",
      "13     338118 2022-08-19  5.0\n",
      "14     338118 2016-01-06  5.0\n",
      "15     338118 2015-09-22  5.0 \n",
      "\n",
      "\n",
      " ====== TABLA CC EXTENDIDA ====== \n",
      "\n",
      "      SERIE      FECHA   CC\n",
      "0  146660T3 2015-01-01  5.0\n",
      "1  146660T3 2015-01-02  5.0\n",
      "2  146660T3 2015-01-03  5.0\n",
      "3  146660T3 2015-01-04  5.0\n",
      "4  146660T3 2015-01-05  5.0 \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA CC ====== \n",
      "\n",
      "      SERIE      FECHA   CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  Y3 mW  \\\n",
      "0  146660T3 2022-05-12  5.0    112    857    872    251    796    801    602   \n",
      "1  146660T3 2019-04-27  5.0    337    164    703    613    855    857    735   \n",
      "2  146660T3 2015-05-15  5.0    476    360    108    904    821    510    434   \n",
      "3  146660T3 2014-11-14  5.0    593    713    482    307    642    463     75   \n",
      "4    364076 2022-06-18  5.0    121    731    554    605     97    211    589   \n",
      "\n",
      "   Y0 mW  \n",
      "0    645  \n",
      "1    850  \n",
      "2    220  \n",
      "3    390  \n",
      "4     53   \n",
      "\n",
      "\n",
      " ====== TABLA DETALLADA EXTENDIDA CC ====== \n",
      "\n",
      "      SERIE      FECHA   CC  X1 mW  X2 mW  X3 mW  X0 mW  Y1 mW  Y2 mW  Y3 mW  \\\n",
      "0  146660T3 2015-01-01  5.0  593.0  713.0  482.0  307.0  642.0  463.0   75.0   \n",
      "1  146660T3 2015-01-02  5.0  593.0  713.0  482.0  307.0  642.0  463.0   75.0   \n",
      "2  146660T3 2015-01-03  5.0  593.0  713.0  482.0  307.0  642.0  463.0   75.0   \n",
      "3  146660T3 2015-01-04  5.0  593.0  713.0  482.0  307.0  642.0  463.0   75.0   \n",
      "4  146660T3 2015-01-05  5.0  593.0  713.0  482.0  307.0  642.0  463.0   75.0   \n",
      "\n",
      "   Y0 mW  \n",
      "0  390.0  \n",
      "1  390.0  \n",
      "2  390.0  \n",
      "3  390.0  \n",
      "4  390.0   \n",
      "\n",
      "          SERIE      FECHA       BUS\n",
      "0      146660T3 2015-01-01  3.117647\n",
      "1      146660T3 2015-01-02  3.117647\n",
      "2      146660T3 2015-01-03  3.117647\n",
      "3      146660T3 2015-01-04  3.117647\n",
      "4      146660T3 2015-01-05  3.117647\n",
      "...         ...        ...       ...\n",
      "15795    364076 2025-10-20  5.000000\n",
      "15796    364076 2025-10-21  5.000000\n",
      "15797    364076 2025-10-22  5.000000\n",
      "15798    364076 2025-10-23  5.000000\n",
      "15799    364076 2025-10-24  5.000000\n",
      "\n",
      "[15800 rows x 3 columns]\n",
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS']\n",
      "          SERIE      FECHA        HI   DGA       ACE  ARR       AIS  NUC  \\\n",
      "0      146660T3 2015-01-01  2.514897  1.90  3.545455  NaN  2.600000  NaN   \n",
      "1      146660T3 2015-01-02  2.514897  1.90  3.545455  NaN  2.600000  NaN   \n",
      "2      146660T3 2015-01-03  2.514897  1.90  3.545455  NaN  2.600000  NaN   \n",
      "3      146660T3 2015-01-04  2.514897  1.90  3.545455  NaN  2.600000  NaN   \n",
      "4      146660T3 2015-01-05  2.514897  1.90  3.545455  NaN  2.600000  NaN   \n",
      "...         ...        ...       ...   ...       ...  ...       ...  ...   \n",
      "15795    364076 2025-10-20  3.344968  1.75  2.181818  5.0  3.857143  3.5   \n",
      "15796    364076 2025-10-21  3.344968  1.75  2.181818  5.0  3.857143  3.5   \n",
      "15797    364076 2025-10-22  3.344968  1.75  2.181818  5.0  3.857143  3.5   \n",
      "15798    364076 2025-10-23  3.344968  1.75  2.181818  5.0  3.857143  3.5   \n",
      "15799    364076 2025-10-24  3.344968  1.75  2.181818  5.0  3.857143  3.5   \n",
      "\n",
      "       OLTC       BUS  \n",
      "0       2.5  3.117647  \n",
      "1       2.5  3.117647  \n",
      "2       2.5  3.117647  \n",
      "3       2.5  3.117647  \n",
      "4       2.5  3.117647  \n",
      "...     ...       ...  \n",
      "15795   2.5  5.000000  \n",
      "15796   2.5  5.000000  \n",
      "15797   2.5  5.000000  \n",
      "15798   2.5  5.000000  \n",
      "15799   2.5  5.000000  \n",
      "\n",
      "[15800 rows x 10 columns]\n",
      "[DGA] columnas: ['SERIE', 'FECHA', 'DGA']\n",
      "[ACE] columnas: ['SERIE', 'FECHA', 'ACE']\n",
      "[ARR] columnas: ['SERIE', 'FECHA', 'ARR']\n",
      "[AIS] columnas: ['SERIE', 'FECHA', 'AIS']\n",
      "[NUC] columnas: ['SERIE', 'FECHA', 'NUC']\n",
      "[OLTC] columnas: ['SERIE', 'FECHA', 'OLTC']\n",
      "[BUS] columnas: ['SERIE', 'FECHA', 'BUS']\n",
      "SERIE            object\n",
      "FECHA    datetime64[ns]\n",
      "HI              float64\n",
      "DGA             float64\n",
      "ACE             float64\n",
      "ARR             float64\n",
      "AIS             float64\n",
      "NUC             float64\n",
      "OLTC            float64\n",
      "BUS             float64\n",
      "dtype: object\n",
      "       SERIE      FECHA        HI   DGA       ACE  ARR       AIS  NUC  OLTC  \\\n",
      "0  230531-01 2025-10-24  3.910714  2.80  4.000000  5.0  4.142857  3.5   3.5   \n",
      "1   146660T3 2025-10-24  3.862347  2.65  4.090909  5.0  3.857143  3.5   5.0   \n",
      "2     338118 2025-10-24  3.584578  2.35  2.363636  5.0  4.142857  3.5   2.5   \n",
      "\n",
      "        BUS  \n",
      "0  5.000000  \n",
      "1  4.529412  \n",
      "2  5.000000  \n",
      "¡Éxito! 15800 registros importados automáticamente\n",
      "La tabla se creó con las columnas: ['SERIE', 'FECHA', 'HI', 'DGA', 'ACE', 'ARR', 'AIS', 'NUC', 'OLTC', 'BUS']\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR DATAFRAME HI:\n",
    "from main import obtener_HI\n",
    "\n",
    "df_HI = obtener_HI()\n",
    "df_HI = df_HI.sort_values(by=[\"FECHA\", \"HI\"], ascending=[False, False]).reset_index(drop=True)\n",
    "print(df_HI.dtypes)\n",
    "print(df_HI.head(3))\n",
    "\n",
    "# Conexión con SQLAlchemy (MUCHO más simple)\n",
    "try:\n",
    "    # Codificar contraseña por si tiene caracteres especiales\n",
    "    password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "    \n",
    "    # Crear engine de conexión\n",
    "    engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "        \n",
    "    # Importar directamente el DataFrame a PostgreSQL\n",
    "    # if_exists='replace' = borra la tabla si existe y crea una nueva\n",
    "    # index=False = no incluir el índice del DataFrame como columna\n",
    "    df_HI.to_sql('hi_general', engine, if_exists='replace', index=False, schema='processed_v2',dtype={'FECHA': Date()})\n",
    "    \n",
    "    print(f\"¡Éxito! {len(df_HI)} registros importados automáticamente\")\n",
    "    print(\"La tabla se creó con las columnas:\", list(df_HI.columns))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e7586",
   "metadata": {},
   "source": [
    "### Carga automática de tablas de subíndices (DGA,ACE,AIS,ARR,NUC,OLTC,BUS) a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886751c",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombres de tabla 'hi_<subíndice>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb90b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ¡Éxito! 16 registros importados a hi_dga\n",
      "   Columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n",
      "✅ ¡Éxito! 16 registros importados a hi_ace\n",
      "   Columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n",
      "✅ ¡Éxito! 40 registros importados a hi_arr\n",
      "   Columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "✅ ¡Éxito! 28 registros importados a hi_ais\n",
      "   Columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR']\n",
      "✅ ¡Éxito! 28 registros importados a hi_nuc\n",
      "   Columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "✅ ¡Éxito! 16 registros importados a hi_oltc\n",
      "   Columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n",
      "✅ ¡Éxito! 16 registros importados a hi_bus\n",
      "   Columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ Definir módulos y funciones\n",
    "# ================================\n",
    "from DGA import get_df_detalles_DGA\n",
    "from ACE import get_df_detalles_ACE\n",
    "from ARR import get_df_detalles_ARR\n",
    "from AIS import get_df_detalles_AIS\n",
    "from NUC import get_df_detalles_NUC\n",
    "from OLTC import get_df_detalles_OLTC\n",
    "from BUS import get_df_detalles_BUS\n",
    "\n",
    "# Diccionario con las funciones de obtención de DataFrames\n",
    "data_sources = {\n",
    "    \"dga\": get_df_detalles_DGA,\n",
    "    \"ace\": get_df_detalles_ACE,\n",
    "    \"arr\": get_df_detalles_ARR,\n",
    "    \"ais\": get_df_detalles_AIS,\n",
    "    \"nuc\": get_df_detalles_NUC,\n",
    "    \"oltc\": get_df_detalles_OLTC,\n",
    "    \"bus\": get_df_detalles_BUS,\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ Conexión SQL\n",
    "# ================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ Cargar todos los DataFrames\n",
    "# ================================\n",
    "for name, func in data_sources.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            f\"hi_{name}\", \n",
    "            engine, \n",
    "            if_exists='replace', \n",
    "            index=False, \n",
    "            schema='raw_v2',\n",
    "            dtype={'FECHA': Date()}\n",
    "        )\n",
    "        print(f\"✅ ¡Éxito! {len(df)} registros importados a hi_{name}\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d54387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# from sqlalchemy import create_engine, Date, text\n",
    "# import pandas as pd\n",
    "\n",
    "# # ================================\n",
    "# # 1️⃣ Definir módulos y funciones\n",
    "# # ================================\n",
    "# from DGA import get_df_detalles_DGA\n",
    "# from ACE import get_df_detalles_ACE\n",
    "# from ARR import get_df_detalles_ARR\n",
    "# from AIS import get_df_detalles_AIS\n",
    "# from NUC import get_df_detalles_NUC\n",
    "# from OLTC import get_df_detalles_OLTC\n",
    "# from BUS import get_df_detalles_BUS\n",
    "\n",
    "# # Diccionario con las funciones de obtención de DataFrames\n",
    "# data_sources = {\n",
    "#     \"dga\": get_df_detalles_DGA,\n",
    "#     \"ace\": get_df_detalles_ACE,\n",
    "#     \"arr\": get_df_detalles_ARR,\n",
    "#     \"ais\": get_df_detalles_AIS,\n",
    "#     \"nuc\": get_df_detalles_NUC,\n",
    "#     \"oltc\": get_df_detalles_OLTC,\n",
    "#     \"bus\": get_df_detalles_BUS,\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # 2️⃣ Conexión SQL\n",
    "# # ================================\n",
    "# password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "# engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "\n",
    "# # ================================\n",
    "# # 3️⃣ Cargar solo datos nuevos por SERIE\n",
    "# # ================================\n",
    "# for name, func in data_sources.items():\n",
    "#     try:\n",
    "#         df = func()\n",
    "#         table_name = f\"hi_{name}\"\n",
    "#         schema_name = \"raw_v2\"\n",
    "\n",
    "#         with engine.connect() as conn:\n",
    "#             # Verificar si la tabla existe\n",
    "#             check_table = conn.execute(text(f\"\"\"\n",
    "#                 SELECT EXISTS (\n",
    "#                     SELECT FROM information_schema.tables \n",
    "#                     WHERE table_schema = :schema AND table_name = :table\n",
    "#                 )\n",
    "#             \"\"\"), {\"schema\": schema_name, \"table\": table_name}).scalar()\n",
    "\n",
    "#             if check_table:\n",
    "#                 # Obtener todas las series existentes\n",
    "#                 series_existentes = conn.execute(text(f\"\"\"\n",
    "#                     SELECT DISTINCT \"SERIE\" FROM {schema_name}.{table_name}\n",
    "#                 \"\"\"))\n",
    "#                 series_existentes = [row[0] for row in series_existentes]\n",
    "\n",
    "#                 nuevos_registros = pd.DataFrame()\n",
    "\n",
    "#                 for serie in df[\"SERIE\"].unique():\n",
    "#                     df_serie = df[df[\"SERIE\"] == serie]\n",
    "#                     if serie in series_existentes:\n",
    "#                         max_fecha = conn.execute(text(f\"\"\"\n",
    "#                             SELECT MAX(\"FECHA\") FROM {schema_name}.{table_name} WHERE \"SERIE\" = :serie\n",
    "#                         \"\"\"), {\"serie\": serie}).scalar()\n",
    "#                         df_serie = df_serie[df_serie[\"FECHA\"] > pd.to_datetime(max_fecha)]\n",
    "#                     nuevos_registros = pd.concat([nuevos_registros, df_serie], ignore_index=True)\n",
    "\n",
    "#                 if not nuevos_registros.empty:\n",
    "#                     nuevos_registros.to_sql(\n",
    "#                         table_name,\n",
    "#                         engine,\n",
    "#                         if_exists='append',\n",
    "#                         index=False,\n",
    "#                         schema=schema_name,\n",
    "#                         dtype={'FECHA': Date()}\n",
    "#                     )\n",
    "#                     print(f\"✅ {len(nuevos_registros)} registros nuevos añadidos a {table_name}\")\n",
    "#                 else:\n",
    "#                     print(f\"ℹ️ No hay registros nuevos para {table_name}\")\n",
    "#             else:\n",
    "#                 # Si la tabla no existe, crearla con todos los datos\n",
    "#                 df.to_sql(\n",
    "#                     table_name,\n",
    "#                     engine,\n",
    "#                     if_exists='replace',\n",
    "#                     index=False,\n",
    "#                     schema=schema_name,\n",
    "#                     dtype={'FECHA': Date()}\n",
    "#                 )\n",
    "#                 print(f\"🆕 Tabla {table_name} creada con {len(df)} registros\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b037848",
   "metadata": {},
   "source": [
    "### Carga automática de tablas de subíndices (DGA,ACE,AIS,ARR,NUC,OLTC,BUS) extendidos a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9e53b",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombres de tabla 'hi_<subíndice>_extendido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b87ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ¡Éxito! 15800 registros importados a hi_dga_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'DGA', 'H2', 'CH4', 'C2H2', 'C2H4', 'C2H6', 'CO', 'CO2', 'O2']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_ace_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'ACE', 'FP25', 'FP100', 'HU', 'AC', 'TIF', 'CO', 'RD', 'IO']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_arr_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'ARR', 'ROHM', 'RTRA', 'RDIS']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_ais_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'AIS', 'FPDEVANADO', 'CD', 'FUR']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_nuc_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'NUC', 'RNUC', 'IEX']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_oltc_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'OLTC', 'RD', 'H20']\n",
      "✅ ¡Éxito! 15800 registros importados a hi_bus_extendido\n",
      "   Columnas: ['SERIE', 'FECHA', 'BUS', 'FPBC1', 'FPBC2', 'CBC1', 'CBC2', 'CC']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ Importar funciones extendidas\n",
    "# ================================\n",
    "from DGA import get_df_detalles_ext_DGA\n",
    "from ACE import get_df_detalles_ext_ACE\n",
    "from ARR import get_df_detalles_ext_ARR\n",
    "from AIS import get_df_detalles_ext_AIS\n",
    "from NUC import get_df_detalles_ext_NUC\n",
    "from OLTC import get_df_detalles_ext_OLTC\n",
    "from BUS import get_df_detalles_ext_BUS\n",
    "\n",
    "# Diccionario con las funciones extendidas\n",
    "data_sources_ext = {\n",
    "    \"dga_extendido\": get_df_detalles_ext_DGA,\n",
    "    \"ace_extendido\": get_df_detalles_ext_ACE,\n",
    "    \"arr_extendido\": get_df_detalles_ext_ARR,\n",
    "    \"ais_extendido\": get_df_detalles_ext_AIS,\n",
    "    \"nuc_extendido\": get_df_detalles_ext_NUC,\n",
    "    \"oltc_extendido\": get_df_detalles_ext_OLTC,\n",
    "    \"bus_extendido\": get_df_detalles_ext_BUS,\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ Conexión SQL\n",
    "# ================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores')\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ Cargar todos los DataFrames extendidos\n",
    "# ================================\n",
    "for name, func in data_sources_ext.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            f\"hi_{name}\",\n",
    "            engine,\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            schema='raw_v2',\n",
    "            dtype={'FECHA': Date()}\n",
    "        )\n",
    "        print(f\"✅ ¡Éxito! {len(df)} registros importados a hi_{name}\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {name.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412134a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine, Date, text\n",
    "# from datetime import datetime\n",
    "\n",
    "# # ================================\n",
    "# # 1️⃣ Importar funciones extendidas\n",
    "# # ================================\n",
    "# from DGA import get_df_detalles_ext_DGA\n",
    "# from ACE import get_df_detalles_ext_ACE\n",
    "# from ARR import get_df_detalles_ext_ARR\n",
    "# from AIS import get_df_detalles_ext_AIS\n",
    "# from NUC import get_df_detalles_ext_NUC\n",
    "# from OLTC import get_df_detalles_ext_OLTC\n",
    "# from BUS import get_df_detalles_ext_BUS\n",
    "\n",
    "# # Diccionario con las funciones extendidas\n",
    "# data_sources_ext = {\n",
    "#     \"dga_extendido\": get_df_detalles_ext_DGA,\n",
    "#     \"ace_extendido\": get_df_detalles_ext_ACE,\n",
    "#     \"arr_extendido\": get_df_detalles_ext_ARR,\n",
    "#     \"ais_extendido\": get_df_detalles_ext_AIS,\n",
    "#     \"nuc_extendido\": get_df_detalles_ext_NUC,\n",
    "#     \"oltc_extendido\": get_df_detalles_ext_OLTC,\n",
    "#     \"bus_extendido\": get_df_detalles_ext_BUS,\n",
    "# }\n",
    "\n",
    "# # ================================\n",
    "# # 2️⃣ Conexión SQL\n",
    "# # ================================\n",
    "# password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "# engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost:5432/postgres')\n",
    "\n",
    "# # ================================\n",
    "# # 3️⃣ Función para carga incremental\n",
    "# # ================================\n",
    "# def carga_incremental(tabla_nombre, funcion_fuente, engine):\n",
    "#     \"\"\"\n",
    "#     Realiza carga incremental comparando datos existentes con nuevos\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Obtener nuevos datos\n",
    "#         nuevos_datos = funcion_fuente()\n",
    "        \n",
    "#         if nuevos_datos.empty:\n",
    "#             print(f\"⚠️ No hay nuevos datos para {tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Verificar si la tabla existe en la base de datos\n",
    "#         with engine.connect() as conn:\n",
    "#             tabla_existe = conn.execute(text(f\"\"\"\n",
    "#                 SELECT EXISTS (\n",
    "#                     SELECT FROM information_schema.tables \n",
    "#                     WHERE table_schema = 'raw_v2' \n",
    "#                     AND table_name = 'hi_{tabla_nombre}'\n",
    "#                 );\n",
    "#             \"\"\")).scalar()\n",
    "        \n",
    "#         if not tabla_existe:\n",
    "#             # Si la tabla no existe, crear con todos los datos\n",
    "#             nuevos_datos.to_sql(\n",
    "#                 f\"hi_{tabla_nombre}\",\n",
    "#                 engine,\n",
    "#                 if_exists='fail',\n",
    "#                 index=False,\n",
    "#                 schema='raw_v2',\n",
    "#                 dtype={'FECHA': Date()}\n",
    "#             )\n",
    "#             print(f\"✅ ¡Tabla creada! {len(nuevos_datos)} registros importados a hi_{tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Si la tabla existe, obtener datos existentes para comparar\n",
    "#         with engine.connect() as conn:\n",
    "#             datos_existentes = pd.read_sql_table(\n",
    "#                 f\"hi_{tabla_nombre}\", \n",
    "#                 conn, \n",
    "#                 schema='raw_v2'\n",
    "#             )\n",
    "        \n",
    "#         if datos_existentes.empty:\n",
    "#             # Si la tabla existe pero está vacía, insertar todos los datos\n",
    "#             nuevos_datos.to_sql(\n",
    "#                 f\"hi_{tabla_nombre}\",\n",
    "#                 engine,\n",
    "#                 if_exists='append',\n",
    "#                 index=False,\n",
    "#                 schema='raw_v2'\n",
    "#             )\n",
    "#             print(f\"✅ ¡Datos cargados en tabla vacía! {len(nuevos_datos)} registros importados a hi_{tabla_nombre}\")\n",
    "#             return\n",
    "        \n",
    "#         # Identificar duplicados basado en todas las columnas\n",
    "#         # Combinar datos existentes y nuevos\n",
    "#         todos_datos = pd.concat([datos_existentes, nuevos_datos], ignore_index=True)\n",
    "        \n",
    "#         # Eliminar duplicados manteniendo los primeros (los existentes)\n",
    "#         datos_sin_duplicados = todos_datos.drop_duplicates(keep='first')\n",
    "        \n",
    "#         # Filtrar solo los registros nuevos (los que no estaban en existentes)\n",
    "#         datos_nuevos = datos_sin_duplicados.iloc[len(datos_existentes):]\n",
    "        \n",
    "#         if datos_nuevos.empty:\n",
    "#             print(f\"ℹ️ No hay datos nuevos para {tabla_nombre}. Tabla actualizada.\")\n",
    "#             return\n",
    "        \n",
    "#         # Insertar solo los datos nuevos\n",
    "#         datos_nuevos.to_sql(\n",
    "#             f\"hi_{tabla_nombre}\",\n",
    "#             engine,\n",
    "#             if_exists='append',\n",
    "#             index=False,\n",
    "#             schema='raw_v2'\n",
    "#         )\n",
    "        \n",
    "#         print(f\"✅ ¡Carga incremental exitosa! {len(datos_nuevos)} nuevos registros añadidos a hi_{tabla_nombre}\")\n",
    "#         print(f\"   Total en tabla: {len(datos_sin_duplicados)} registros\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error en carga incremental para {tabla_nombre}: {e}\")\n",
    "\n",
    "# # ================================\n",
    "# # 4️⃣ Ejecutar carga incremental para todas las tablas\n",
    "# # ================================\n",
    "# for name, func in data_sources_ext.items():\n",
    "#     print(f\"\\n🔄 Procesando: {name}\")\n",
    "#     carga_incremental(name, func, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc32238",
   "metadata": {},
   "source": [
    "### Carga automática de tabla de Sub-subíndices detallados y extendidos a PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73201da0",
   "metadata": {},
   "source": [
    "Los carga automáticamente en el esquema 'raw_v2' con nombre de tabla 'hi_<subíndice>_ <subsubíndice>' y 'hi_<subíndice>_<subsubíndice>_extendido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed2f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ hi_arr_rohm: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C[mΩ]', 'X POS1 S 75°C[mΩ]', 'X POS1 T 75°C[mΩ]', 'Y POS1 R 75°C[mΩ]', 'Y POS1 S 75°C[mΩ]', 'Y POS1 T 75°C[mΩ]']\n",
      "✅ hi_arr_rtra: 17 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T']\n",
      "✅ hi_arr_rdis: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X 1 [%] ONAF 2', 'H-X 14 [%] ONAF 2', 'H-X 27 [%] ONAF 2', 'H-Y 1 [%]', 'H-Y 14 [%]', 'H-Y 27 [%]', 'X-Y 1 [%]', 'X-Y 2 [%]', 'X-Y 3 [%]']\n",
      "✅ hi_arr_rohm_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'ROHM', 'H POS1 R 75°C [mΩ]', 'H POS2 R 75°C [mΩ]', 'H POS3 R 75°C [mΩ]', 'H POS4 R 75°C [mΩ]', 'H POS5 R 75°C [mΩ]', 'H POS6 R 75°C [mΩ]', 'H POS7 R 75°C [mΩ]', 'H POS8 R 75°C [mΩ]', 'H POS9 R 75°C [mΩ]', 'H POS10 R 75°C [mΩ]', 'H POS11 R 75°C [mΩ]', 'H POS12 R 75°C [mΩ]', 'H POS13 R 75°C [mΩ]', 'H POS14 R 75°C [mΩ]', 'H POS15 R 75°C [mΩ]', 'H POS16 R 75°C [mΩ]', 'H POS17 R 75°C [mΩ]', 'H POS18 R 75°C [mΩ]', 'H POS19 R 75°C [mΩ]', 'H POS20 R 75°C [mΩ]', 'H POS21 R 75°C [mΩ]', 'H POS22 R 75°C [mΩ]', 'H POS23 R 75°C [mΩ]', 'H POS24 R 75°C [mΩ]', 'H POS25 R 75°C [mΩ]', 'H POS26 R 75°C [mΩ]', 'H POS27 R 75°C [mΩ]', 'H POS1 S 75°C [mΩ]', 'H POS2 S 75°C [mΩ]', 'H POS3 S 75°C [mΩ]', 'H POS4 S 75°C [mΩ]', 'H POS5 S 75°C [mΩ]', 'H POS6 S 75°C [mΩ]', 'H POS7 S 75°C [mΩ]', 'H POS8 S 75°C [mΩ]', 'H POS9 S 75°C [mΩ]', 'H POS10 S 75°C [mΩ]', 'H POS11 S 75°C [mΩ]', 'H POS12 S 75°C [mΩ]', 'H POS13 S 75°C [mΩ]', 'H POS14 S 75°C [mΩ]', 'H POS15 S 75°C [mΩ]', 'H POS16 S 75°C [mΩ]', 'H POS17 S 75°C [mΩ]', 'H POS18 S 75°C [mΩ]', 'H POS19 S 75°C [mΩ]', 'H POS20 S 75°C [mΩ]', 'H POS21 S 75°C [mΩ]', 'H POS22 S 75°C [mΩ]', 'H POS23 S 75°C [mΩ]', 'H POS24 S 75°C [mΩ]', 'H POS25 S 75°C [mΩ]', 'H POS26 S 75°C [mΩ]', 'H POS27 S 75°C [mΩ]', 'H POS1 T 75°C [mΩ]', 'H POS2 T 75°C [mΩ]', 'H POS3 T 75°C [mΩ]', 'H POS4 T 75°C [mΩ]', 'H POS5 T 75°C [mΩ]', 'H POS6 T 75°C [mΩ]', 'H POS7 T 75°C [mΩ]', 'H POS8 T 75°C [mΩ]', 'H POS9 T 75°C [mΩ]', 'H POS10 T 75°C [mΩ]', 'H POS11 T 75°C [mΩ]', 'H POS12 T 75°C [mΩ]', 'H POS13 T 75°C [mΩ]', 'H POS14 T 75°C [mΩ]', 'H POS15 T 75°C [mΩ]', 'H POS16 T 75°C [mΩ]', 'H POS17 T 75°C [mΩ]', 'H POS18 T 75°C [mΩ]', 'H POS19 T 75°C [mΩ]', 'H POS20 T 75°C [mΩ]', 'H POS21 T 75°C [mΩ]', 'H POS22 T 75°C [mΩ]', 'H POS23 T 75°C [mΩ]', 'H POS24 T 75°C [mΩ]', 'H POS25 T 75°C [mΩ]', 'H POS26 T 75°C [mΩ]', 'H POS27 T 75°C [mΩ]', 'X POS1 R 75°C[mΩ]', 'X POS1 S 75°C[mΩ]', 'X POS1 T 75°C[mΩ]', 'Y POS1 R 75°C[mΩ]', 'Y POS1 S 75°C[mΩ]', 'Y POS1 T 75°C[mΩ]']\n",
      "✅ hi_arr_rtra_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RTRA', 'H-X POS1 R', 'H-X POS2 R', 'H-X POS3 R', 'H-X POS4 R', 'H-X POS5 R', 'H-X POS6 R', 'H-X POS7 R', 'H-X POS8 R', 'H-X POS9 R', 'H-X POS10 R', 'H-X POS11 R', 'H-X POS12 R', 'H-X POS13 R', 'H-X POS14 R', 'H-X POS15 R', 'H-X POS16 R', 'H-X POS17 R', 'H-X POS18 R', 'H-X POS19 R', 'H-X POS20 R', 'H-X POS21 R', 'H-X POS22 R', 'H-X POS23 R', 'H-X POS24 R', 'H-X POS25 R', 'H-X POS26 R', 'H-X POS27 R', 'H-X POS1 S', 'H-X POS2 S', 'H-X POS3 S', 'H-X POS4 S', 'H-X POS5 S', 'H-X POS6 S', 'H-X POS7 S', 'H-X POS8 S', 'H-X POS9 S', 'H-X POS10 S', 'H-X POS11 S', 'H-X POS12 S', 'H-X POS13 S', 'H-X POS14 S', 'H-X POS15 S', 'H-X POS16 S', 'H-X POS17 S', 'H-X POS18 S', 'H-X POS19 S', 'H-X POS20 S', 'H-X POS21 S', 'H-X POS22 S', 'H-X POS23 S', 'H-X POS24 S', 'H-X POS25 S', 'H-X POS26 S', 'H-X POS27 S', 'H-X POS1 T', 'H-X POS2 T', 'H-X POS3 T', 'H-X POS4 T', 'H-X POS5 T', 'H-X POS6 T', 'H-X POS7 T', 'H-X POS8 T', 'H-X POS9 T', 'H-X POS10 T', 'H-X POS11 T', 'H-X POS12 T', 'H-X POS13 T', 'H-X POS14 T', 'H-X POS15 T', 'H-X POS16 T', 'H-X POS17 T', 'H-X POS18 T', 'H-X POS19 T', 'H-X POS20 T', 'H-X POS21 T', 'H-X POS22 T', 'H-X POS23 T', 'H-X POS24 T', 'H-X POS25 T', 'H-X POS26 T', 'H-X POS27 T', 'H-Y POS1 R', 'H-Y POS2 R', 'H-Y POS3 R', 'H-Y POS4 R', 'H-Y POS5 R', 'H-Y POS6 R', 'H-Y POS7 R', 'H-Y POS8 R', 'H-Y POS9 R', 'H-Y POS10 R', 'H-Y POS11 R', 'H-Y POS12 R', 'H-Y POS13 R', 'H-Y POS14 R', 'H-Y POS15 R', 'H-Y POS16 R', 'H-Y POS17 R', 'H-Y POS18 R', 'H-Y POS19 R', 'H-Y POS20 R', 'H-Y POS21 R', 'H-Y POS22 R', 'H-Y POS23 R', 'H-Y POS24 R', 'H-Y POS25 R', 'H-Y POS26 R', 'H-Y POS27 R', 'H-Y POS1 S', 'H-Y POS2 S', 'H-Y POS3 S', 'H-Y POS4 S', 'H-Y POS5 S', 'H-Y POS6 S', 'H-Y POS7 S', 'H-Y POS8 S', 'H-Y POS9 S', 'H-Y POS10 S', 'H-Y POS11 S', 'H-Y POS12 S', 'H-Y POS13 S', 'H-Y POS14 S', 'H-Y POS15 S', 'H-Y POS16 S', 'H-Y POS17 S', 'H-Y POS18 S', 'H-Y POS19 S', 'H-Y POS20 S', 'H-Y POS21 S', 'H-Y POS22 S', 'H-Y POS23 S', 'H-Y POS24 S', 'H-Y POS25 S', 'H-Y POS26 S', 'H-Y POS27 S', 'H-Y POS1 T', 'H-Y POS2 T', 'H-Y POS3 T', 'H-Y POS4 T', 'H-Y POS5 T', 'H-Y POS6 T', 'H-Y POS7 T', 'H-Y POS8 T', 'H-Y POS9 T', 'H-Y POS10 T', 'H-Y POS11 T', 'H-Y POS12 T', 'H-Y POS13 T', 'H-Y POS14 T', 'H-Y POS15 T', 'H-Y POS16 T', 'H-Y POS17 T', 'H-Y POS18 T', 'H-Y POS19 T', 'H-Y POS20 T', 'H-Y POS21 T', 'H-Y POS22 T', 'H-Y POS23 T', 'H-Y POS24 T', 'H-Y POS25 T', 'H-Y POS26 T', 'H-Y POS27 T', 'X-Y POS1 R', 'X-Y POS1 S', 'X-Y POS1 T']\n",
      "✅ hi_arr_rdis_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RDIS', 'H-X 1 [%] ONAF 2', 'H-X 14 [%] ONAF 2', 'H-X 27 [%] ONAF 2', 'H-Y 1 [%]', 'H-Y 14 [%]', 'H-Y 27 [%]', 'X-Y 1 [%]', 'X-Y 2 [%]', 'X-Y 3 [%]']\n",
      "✅ hi_ais_furanos: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n",
      "✅ hi_ais_fp: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT+ICLH %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH+ICTL %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n",
      "✅ hi_ais_cd: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n",
      "✅ hi_ais_furanos_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', '2-Furfuraldehido (FAL, ppb)', 'FUR']\n",
      "✅ hi_ais_fp_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'H ICH+ICHL %', 'H ICH %', 'H ICHL %', 'H ICHT %', 'X ICL+ICLT+ICLH %', 'X ICL+ICLT %', 'X ICL %', 'X ICLT %', 'X ICLH %', 'Y ICT+ICTH+ICTL %', 'Y ICT+ICTH %', 'Y ICT %', 'Y ICTH %', 'Y ICTL %', 'FPDEVANADO']\n",
      "✅ hi_ais_cd_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CD', 'H ICH+ICHL pF', 'H ICH pF', 'H ICHL pF', 'H ICHT pF', 'X ICL+ICLT pF', 'X ICL pF', 'X ICLT pF', 'X ICLH pF', 'Y ICT+ICTH pF', 'Y ICT pF', 'Y ICTH pF', 'Y ICTL pF']\n",
      "✅ hi_bus_fpbc1: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n",
      "✅ hi_bus_fpbc2: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n",
      "✅ hi_bus_cbc1: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n",
      "✅ hi_bus_cbc2: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 NH0 pF']\n",
      "✅ hi_bus_cc: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW']\n",
      "✅ hi_bus_fpbc1_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC1', 'C1 H1 %', 'C1 H2 %', 'C1 H3 %', 'C1 H0 %']\n",
      "✅ hi_bus_fpbc2_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'FPBC2', 'C2 H1 %', 'C2 H2 %', 'C2 H3 %', 'C2 H0 %']\n",
      "✅ hi_bus_cbc1_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC1', 'C1 H1 pF', 'C1 H2 pF', 'C1 H3 pF', 'C1 H0 pF']\n",
      "✅ hi_bus_cbc2_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CBC2', 'C2 H1 pF', 'C2 H2 pF', 'C2 H3 pF', 'C2 NH0 pF']\n",
      "✅ hi_bus_cc_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'CC', 'X1 mW', 'X2 mW', 'X3 mW', 'X0 mW', 'Y1 mW', 'Y2 mW', 'Y3 mW', 'Y0 mW']\n",
      "✅ hi_nuc_iex: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12  mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12  mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12  mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n",
      "✅ hi_nuc_rnuc: 16 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n",
      "✅ hi_nuc_iex_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'IEX', 'R POS1 mA', 'R POS2 mA', 'R POS3 mA', 'R POS4 mA', 'R POS5 mA', 'R POS6 mA', 'R POS7 mA', 'R POS8 mA', 'R POS9 mA', 'R POS10 mA', 'R POS11 mA', 'R POS12  mA', 'R POS13 mA', 'R POS14 mA', 'R POS15 mA', 'R POS16 mA', 'R POS17 mA', 'R POS18 mA', 'R POS19 mA', 'R POS20 mA', 'R POS21 mA', 'R POS22 mA', 'R POS23 mA', 'R POS24 mA', 'R POS25 mA', 'R POS26 mA', 'R POS27 mA', 'S POS1 mA', 'S POS2 mA', 'S POS3 mA', 'S POS4 mA', 'S POS5 mA', 'S POS6 mA', 'S POS7 mA', 'S POS8 mA', 'S POS9 mA', 'S POS10 mA', 'S POS11 mA', 'S POS12  mA', 'S POS13 mA', 'S POS14 mA', 'S POS15 mA', 'S POS16 mA', 'S POS17 mA', 'S POS18 mA', 'S POS19 mA', 'S POS20 mA', 'S POS21 mA', 'S POS22 mA', 'S POS23 mA', 'S POS24 mA', 'S POS25 mA', 'S POS26 mA', 'S POS27 mA', 'T POS1 mA', 'T POS2 mA', 'T POS3 mA', 'T POS4 mA', 'T POS5 mA', 'T POS6 mA', 'T POS7 mA', 'T POS8 mA', 'T POS9 mA', 'T POS10 mA', 'T POS11 mA', 'T POS12  mA', 'T POS13 mA', 'T POS14 mA', 'T POS15 mA', 'T POS16 mA', 'T POS17 mA', 'T POS18 mA', 'T POS19 mA', 'T POS20 mA', 'T POS21 mA', 'T POS22 mA', 'T POS23 mA', 'T POS24 mA', 'T POS25 mA', 'T POS26 mA', 'T POS27 mA']\n",
      "✅ hi_nuc_rnuc_extendido: 15800 registros importados correctamente.\n",
      "   Columnas: ['SERIE', 'FECHA', 'RNUC', 'Valor (MΩ)']\n",
      "\n",
      "🚀 Proceso finalizado para todos los subíndices y extendidos.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine, Date\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 1️⃣ Importar todos los módulos normales y extendidos\n",
    "# =====================================================\n",
    "# ARR\n",
    "from ARRrohm import get_df_detalles_ROHM, get_df_detalles_ext_ROHM\n",
    "from ARRrtra import get_df_detalles_RTRA, get_df_detalles_ext_RTRA\n",
    "from ARRdis import get_df_detalles_DIS, get_df_detalles_ext_DIS\n",
    "\n",
    "# AIS\n",
    "from FURANOS import get_df_detalles_FUR, get_df_detalles_ext_FUR\n",
    "from FP import get_df_detalles_FP, get_df_detalles_ext_FP\n",
    "from CD import get_df_detalles_CD, get_df_detalles_ext_CD\n",
    "\n",
    "# BUS\n",
    "from FPBC1 import get_df_detalles_FP_C1, get_df_detalles_ext_FP_C1\n",
    "from FPBC2 import get_df_detalles_FP_C2, get_df_detalles_ext_FP_C2\n",
    "from CBC1 import get_df_detalles_C_C1, get_df_detalles_ext_C_C1\n",
    "from CBC2 import get_df_detalles_C_C2, get_df_detalles_ext_C_C2\n",
    "from FPCOCA import get_df_detalles_CC, get_df_detalles_ext_CC\n",
    "\n",
    "# NUC\n",
    "from NUCiex import get_df_detalles_IEX, get_df_detalles_ext_IEX\n",
    "from NUCrnuc import get_df_detalles_RNUC, get_df_detalles_ext_RNUC\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 2️⃣ Diccionario maestro de fuentes\n",
    "# =====================================================\n",
    "sources = {\n",
    "    # ARR normales\n",
    "    \"hi_arr_rohm\": get_df_detalles_ROHM,\n",
    "    \"hi_arr_rtra\": get_df_detalles_RTRA,\n",
    "    \"hi_arr_rdis\": get_df_detalles_DIS,\n",
    "\n",
    "    # ARR extendidos\n",
    "    \"hi_arr_rohm_extendido\": get_df_detalles_ext_ROHM,\n",
    "    \"hi_arr_rtra_extendido\": get_df_detalles_ext_RTRA,\n",
    "    \"hi_arr_rdis_extendido\": get_df_detalles_ext_DIS,\n",
    "\n",
    "    # AIS normales\n",
    "    \"hi_ais_furanos\": get_df_detalles_FUR,\n",
    "    \"hi_ais_fp\": get_df_detalles_FP,\n",
    "    \"hi_ais_cd\": get_df_detalles_CD,\n",
    "\n",
    "    # AIS extendidos\n",
    "    \"hi_ais_furanos_extendido\": get_df_detalles_ext_FUR,\n",
    "    \"hi_ais_fp_extendido\": get_df_detalles_ext_FP,\n",
    "    \"hi_ais_cd_extendido\": get_df_detalles_ext_CD,\n",
    "\n",
    "    # BUS normales\n",
    "    \"hi_bus_fpbc1\": get_df_detalles_FP_C1,\n",
    "    \"hi_bus_fpbc2\": get_df_detalles_FP_C2,\n",
    "    \"hi_bus_cbc1\": get_df_detalles_C_C1,\n",
    "    \"hi_bus_cbc2\": get_df_detalles_C_C2,\n",
    "    \"hi_bus_cc\": get_df_detalles_CC,\n",
    "\n",
    "    # BUS extendidos\n",
    "    \"hi_bus_fpbc1_extendido\": get_df_detalles_ext_FP_C1,\n",
    "    \"hi_bus_fpbc2_extendido\": get_df_detalles_ext_FP_C2,\n",
    "    \"hi_bus_cbc1_extendido\": get_df_detalles_ext_C_C1,\n",
    "    \"hi_bus_cbc2_extendido\": get_df_detalles_ext_C_C2,\n",
    "    \"hi_bus_cc_extendido\": get_df_detalles_ext_CC,\n",
    "\n",
    "    # NUC normales\n",
    "    \"hi_nuc_iex\": get_df_detalles_IEX,\n",
    "    \"hi_nuc_rnuc\": get_df_detalles_RNUC,\n",
    "\n",
    "    # NUC extendidos\n",
    "    \"hi_nuc_iex_extendido\": get_df_detalles_ext_IEX,\n",
    "    \"hi_nuc_rnuc_extendido\": get_df_detalles_ext_RNUC,\n",
    "}\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 3️⃣ Conexión única a PostgreSQL\n",
    "# =====================================================\n",
    "password = urllib.parse.quote_plus(\"delangeluz\")\n",
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{password}@localhost:5432/transformadores\")\n",
    "\n",
    "# =====================================================\n",
    "# 🔹 4️⃣ Cargar todos los DataFrames automáticamente\n",
    "# =====================================================\n",
    "for table_name, func in sources.items():\n",
    "    try:\n",
    "        df = func()\n",
    "        df.to_sql(\n",
    "            table_name,\n",
    "            engine,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "            schema=\"raw_v2\",\n",
    "            dtype={\"FECHA\": Date()},\n",
    "        )\n",
    "        print(f\"✅ {table_name}: {len(df)} registros importados correctamente.\")\n",
    "        print(\"   Columnas:\", list(df.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al importar {table_name}: {e}\")\n",
    "\n",
    "print(\"\\n🚀 Proceso finalizado para todos los subíndices y extendidos.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
