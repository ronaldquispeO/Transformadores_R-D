{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c359bb1d",
   "metadata": {},
   "source": [
    "### IMPORTAR LIRERÍAS Y LEER DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5fbcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoR&D/Basededatos/RDEV.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m address3 = \u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmticllacu\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mOneDrive - LUZ DEL SUR S.A.A\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mArchivos de Ronald Quispe Ocaña - ProyectoR&D\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mBasededatos\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mRDEV.xlsx\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#df = pd.read_excel(address, header=1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RONALD Q\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RONALD Q\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RONALD Q\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RONALD Q\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoR&D/Basededatos/RDEV.xlsx'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "address = 'C:/Users/RONALD Q/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD/Basededatos/RDEV.xlsx'\n",
    "address2 = 'C:/Users/roquispec/OneDrive - LUZ DEL SUR S.A.A/Documentos/Estudios de Ingreso/ProyectoRyD/Basededatos/RDEV.xlsx'\n",
    "address3 = 'C:\\\\Users\\\\mticllacu\\\\OneDrive - LUZ DEL SUR S.A.A\\\\Archivos de Ronald Quispe Ocaña - ProyectoRyD\\\\Basededatos\\\\RDEV.xlsx'\n",
    "#df = pd.read_excel(address, header=1)\n",
    "df = pd.read_excel(address, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e2851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]</th>\n",
       "      <th>H POS25 T 75°C [mΩ]</th>\n",
       "      <th>H POS26 T 75°C [mΩ]</th>\n",
       "      <th>H POS27 T 75°C [mΩ]</th>\n",
       "      <th>X POS1 R 75°C[mΩ]</th>\n",
       "      <th>X POS1 S 75°C[mΩ]</th>\n",
       "      <th>X POS1 T 75°C[mΩ]</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>143.481000</td>\n",
       "      <td>145.522000</td>\n",
       "      <td>148.221000</td>\n",
       "      <td>151.179000</td>\n",
       "      <td>5.348000</td>\n",
       "      <td>5.343000</td>\n",
       "      <td>5.334000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>143.598459</td>\n",
       "      <td>146.222351</td>\n",
       "      <td>148.846243</td>\n",
       "      <td>151.708671</td>\n",
       "      <td>11.319709</td>\n",
       "      <td>11.180166</td>\n",
       "      <td>11.883846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>138.403592</td>\n",
       "      <td>140.338718</td>\n",
       "      <td>142.995010</td>\n",
       "      <td>145.807553</td>\n",
       "      <td>5.170520</td>\n",
       "      <td>5.183673</td>\n",
       "      <td>5.190792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>147.560000</td>\n",
       "      <td>150.389000</td>\n",
       "      <td>152.156000</td>\n",
       "      <td>155.001000</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>14.730000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>151.516777</td>\n",
       "      <td>154.389417</td>\n",
       "      <td>156.216369</td>\n",
       "      <td>159.125068</td>\n",
       "      <td>12.418000</td>\n",
       "      <td>12.455000</td>\n",
       "      <td>125.590000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146918</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>138.333000</td>\n",
       "      <td>136.501000</td>\n",
       "      <td>133.945000</td>\n",
       "      <td>131.398000</td>\n",
       "      <td>129.652000</td>\n",
       "      <td>127.065000</td>\n",
       "      <td>124.519000</td>\n",
       "      <td>122.704000</td>\n",
       "      <td>...</td>\n",
       "      <td>132.949000</td>\n",
       "      <td>134.800000</td>\n",
       "      <td>137.290000</td>\n",
       "      <td>140.009000</td>\n",
       "      <td>4.962000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>4.968000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>146918</td>\n",
       "      <td>2014-11-25</td>\n",
       "      <td>142.987812</td>\n",
       "      <td>141.265067</td>\n",
       "      <td>138.568081</td>\n",
       "      <td>135.906737</td>\n",
       "      <td>134.112706</td>\n",
       "      <td>131.475125</td>\n",
       "      <td>128.790019</td>\n",
       "      <td>126.924702</td>\n",
       "      <td>...</td>\n",
       "      <td>137.570077</td>\n",
       "      <td>139.494798</td>\n",
       "      <td>142.084856</td>\n",
       "      <td>144.948177</td>\n",
       "      <td>5.131284</td>\n",
       "      <td>5.145423</td>\n",
       "      <td>5.146848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "5  146918 2019-07-11          138.333000          136.501000   \n",
       "6  146918 2014-11-25          142.987812          141.265067   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "5          133.945000          131.398000          129.652000   \n",
       "6          138.568081          135.906737          134.112706   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "5          127.065000          124.519000          122.704000  ...   \n",
       "6          131.475125          128.790019          126.924702  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]  H POS25 T 75°C [mΩ]  H POS26 T 75°C [mΩ]  \\\n",
       "0           143.481000           145.522000           148.221000   \n",
       "1           143.598459           146.222351           148.846243   \n",
       "2           138.403592           140.338718           142.995010   \n",
       "3           147.560000           150.389000           152.156000   \n",
       "4           151.516777           154.389417           156.216369   \n",
       "5           132.949000           134.800000           137.290000   \n",
       "6           137.570077           139.494798           142.084856   \n",
       "\n",
       "   H POS27 T 75°C [mΩ]  X POS1 R 75°C[mΩ]  X POS1 S 75°C[mΩ]  \\\n",
       "0           151.179000           5.348000           5.343000   \n",
       "1           151.708671          11.319709          11.180166   \n",
       "2           145.807553           5.170520           5.183673   \n",
       "3           155.001000          14.540000          14.560000   \n",
       "4           159.125068          12.418000          12.455000   \n",
       "5           140.009000           4.962000           4.960000   \n",
       "6           144.948177           5.131284           5.145423   \n",
       "\n",
       "   X POS1 T 75°C[mΩ]  Y POS1 R 75°C[mΩ]  Y POS1 S 75°C[mΩ]  Y POS1 T 75°C[mΩ]  \n",
       "0           5.334000                NaN                NaN                NaN  \n",
       "1          11.883846                NaN                NaN                NaN  \n",
       "2           5.190792                NaN                NaN                NaN  \n",
       "3          14.730000                NaN                NaN                NaN  \n",
       "4         125.590000                NaN                NaN                NaN  \n",
       "5           4.968000                NaN                NaN                NaN  \n",
       "6           5.146848                NaN                NaN                NaN  \n",
       "\n",
       "[7 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.dropna(axis=1,how = 'all')\n",
    "df = df.iloc[:,1:]\n",
    "df['FECHA']= pd.to_datetime(df['FECHA'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f474e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\315815301.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n"
     ]
    }
   ],
   "source": [
    "# Columnas de resistencia (terminan en mΩ)\n",
    "res_cols = [c for c in df.columns if c.endswith(\"[mΩ]\")]\n",
    "\n",
    "for col in res_cols:\n",
    "    # valor inicial por SERIE en la fecha mínima\n",
    "    ref = df.groupby(\"SERIE\").apply(lambda g: g.loc[g[\"FECHA\"].idxmin(), col])\n",
    "    ref_mapped = df[\"SERIE\"].map(ref)\n",
    "\n",
    "    # variación porcentual\n",
    "    delta = abs((df[col] - ref_mapped) / ref_mapped) * 100\n",
    "\n",
    "    # reemplazar inf por NaN (división por cero)\n",
    "    delta = delta.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # si alguno es NaN o ref/valor es 0 -> NaN\n",
    "    mask = df[col].isna() | ref_mapped.isna() | (ref_mapped == 0) | (df[col] == 0)\n",
    "    delta[mask] = np.nan\n",
    "\n",
    "    # agregar columna nueva\n",
    "    df[f\"{col}_Delta\"] = delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a57ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Delta</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Delta</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Delta</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Delta</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Delta</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.668552</td>\n",
       "      <td>3.693408</td>\n",
       "      <td>3.654666</td>\n",
       "      <td>3.683929</td>\n",
       "      <td>3.432531</td>\n",
       "      <td>3.073641</td>\n",
       "      <td>2.758893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.753419</td>\n",
       "      <td>4.192451</td>\n",
       "      <td>4.091914</td>\n",
       "      <td>4.047196</td>\n",
       "      <td>118.927854</td>\n",
       "      <td>115.680402</td>\n",
       "      <td>128.940916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611445</td>\n",
       "      <td>2.591122</td>\n",
       "      <td>2.599196</td>\n",
       "      <td>2.591715</td>\n",
       "      <td>17.088098</td>\n",
       "      <td>16.900843</td>\n",
       "      <td>88.271359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]_Delta  H POS25 T 75°C [mΩ]_Delta  \\\n",
       "0                   3.668552                   3.693408   \n",
       "1                   3.753419                   4.192451   \n",
       "2                   0.000000                   0.000000   \n",
       "3                   2.611445                   2.591122   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   H POS26 T 75°C [mΩ]_Delta  H POS27 T 75°C [mΩ]_Delta  \\\n",
       "0                   3.654666                   3.683929   \n",
       "1                   4.091914                   4.047196   \n",
       "2                   0.000000                   0.000000   \n",
       "3                   2.599196                   2.591715   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   X POS1 R 75°C[mΩ]_Delta  X POS1 S 75°C[mΩ]_Delta  X POS1 T 75°C[mΩ]_Delta  \\\n",
       "0                 3.432531                 3.073641                 2.758893   \n",
       "1               118.927854               115.680402               128.940916   \n",
       "2                 0.000000                 0.000000                 0.000000   \n",
       "3                17.088098                16.900843                88.271359   \n",
       "4                 0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   Y POS1 R 75°C[mΩ]_Delta  Y POS1 S 75°C[mΩ]_Delta  Y POS1 T 75°C[mΩ]_Delta  \n",
       "0                      NaN                      NaN                      NaN  \n",
       "1                      NaN                      NaN                      NaN  \n",
       "2                      NaN                      NaN                      NaN  \n",
       "3                      NaN                      NaN                      NaN  \n",
       "4                      NaN                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n",
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\1961661274.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[puntaje_col] = df[col].apply(\n"
     ]
    }
   ],
   "source": [
    "# Identificar las columnas que terminan en \"_Delta\"\n",
    "delta_cols = [c for c in df.columns if c.endswith(\"_Delta\")]\n",
    "\n",
    "# Crear nuevas columnas de puntaje según la regla\n",
    "for col in delta_cols:\n",
    "    puntaje_col = col.replace(\"_Delta\", \"_Score\")  # ejemplo: H POS21..._Delta → H POS21..._Score\n",
    "    df[puntaje_col] = df[col].apply(\n",
    "        lambda x: np.nan if pd.isna(x) else (1 if x < 5 else 5) \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS24 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Score</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS24 T 75°C [mΩ]_Score  H POS25 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   H POS26 T 75°C [mΩ]_Score  H POS27 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   X POS1 R 75°C[mΩ]_Score  X POS1 S 75°C[mΩ]_Score  X POS1 T 75°C[mΩ]_Score  \\\n",
       "0                        1                        1                        1   \n",
       "1                        5                        5                        5   \n",
       "2                        1                        1                        1   \n",
       "3                        5                        5                        5   \n",
       "4                        1                        1                        1   \n",
       "\n",
       "   Y POS1 R 75°C[mΩ]_Score  Y POS1 S 75°C[mΩ]_Score  Y POS1 T 75°C[mΩ]_Score  \n",
       "0                      NaN                      NaN                      NaN  \n",
       "1                      NaN                      NaN                      NaN  \n",
       "2                      NaN                      NaN                      NaN  \n",
       "3                      NaN                      NaN                      NaN  \n",
       "4                      NaN                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 263 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roquispec\\AppData\\Local\\Temp\\ipykernel_14188\\4100089174.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ROHM\"] = df[delta_cols].max(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Identificar las columnas que terminan en \"_Delta\"\n",
    "delta_cols = [c for c in df.columns if c.endswith(\"_Score\")]\n",
    "\n",
    "# Crear una nueva columna con el máximo por fila\n",
    "df[\"ROHM\"] = df[delta_cols].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fdecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H POS1 R 75°C [mΩ]</th>\n",
       "      <th>H POS2 R 75°C [mΩ]</th>\n",
       "      <th>H POS3 R 75°C [mΩ]</th>\n",
       "      <th>H POS4 R 75°C [mΩ]</th>\n",
       "      <th>H POS5 R 75°C [mΩ]</th>\n",
       "      <th>H POS6 R 75°C [mΩ]</th>\n",
       "      <th>H POS7 R 75°C [mΩ]</th>\n",
       "      <th>H POS8 R 75°C [mΩ]</th>\n",
       "      <th>...</th>\n",
       "      <th>H POS25 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS26 T 75°C [mΩ]_Score</th>\n",
       "      <th>H POS27 T 75°C [mΩ]_Score</th>\n",
       "      <th>X POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>X POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 R 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 S 75°C[mΩ]_Score</th>\n",
       "      <th>Y POS1 T 75°C[mΩ]_Score</th>\n",
       "      <th>ROHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>149.785000</td>\n",
       "      <td>147.781000</td>\n",
       "      <td>144.857000</td>\n",
       "      <td>142.047000</td>\n",
       "      <td>140.025000</td>\n",
       "      <td>137.230000</td>\n",
       "      <td>134.387000</td>\n",
       "      <td>132.398000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>148.965511</td>\n",
       "      <td>147.057225</td>\n",
       "      <td>144.194798</td>\n",
       "      <td>141.451638</td>\n",
       "      <td>139.424085</td>\n",
       "      <td>136.800193</td>\n",
       "      <td>133.937765</td>\n",
       "      <td>132.148748</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>144.028680</td>\n",
       "      <td>142.225767</td>\n",
       "      <td>139.389184</td>\n",
       "      <td>136.732893</td>\n",
       "      <td>134.761709</td>\n",
       "      <td>132.081379</td>\n",
       "      <td>129.340951</td>\n",
       "      <td>127.417845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>153.255000</td>\n",
       "      <td>150.592000</td>\n",
       "      <td>147.916000</td>\n",
       "      <td>145.976000</td>\n",
       "      <td>143.261000</td>\n",
       "      <td>140.604000</td>\n",
       "      <td>138.741000</td>\n",
       "      <td>136.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>157.346194</td>\n",
       "      <td>154.665864</td>\n",
       "      <td>151.913417</td>\n",
       "      <td>149.942233</td>\n",
       "      <td>147.153728</td>\n",
       "      <td>144.449359</td>\n",
       "      <td>142.514233</td>\n",
       "      <td>139.785825</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  H POS1 R 75°C [mΩ]  H POS2 R 75°C [mΩ]  \\\n",
       "0  146916 2019-06-30          149.785000          147.781000   \n",
       "1  146916 2015-01-06          148.965511          147.057225   \n",
       "2  146916 2014-11-12          144.028680          142.225767   \n",
       "3  146917 2022-05-12          153.255000          150.592000   \n",
       "4  146917 2014-12-05          157.346194          154.665864   \n",
       "\n",
       "   H POS3 R 75°C [mΩ]  H POS4 R 75°C [mΩ]  H POS5 R 75°C [mΩ]  \\\n",
       "0          144.857000          142.047000          140.025000   \n",
       "1          144.194798          141.451638          139.424085   \n",
       "2          139.389184          136.732893          134.761709   \n",
       "3          147.916000          145.976000          143.261000   \n",
       "4          151.913417          149.942233          147.153728   \n",
       "\n",
       "   H POS6 R 75°C [mΩ]  H POS7 R 75°C [mΩ]  H POS8 R 75°C [mΩ]  ...  \\\n",
       "0          137.230000          134.387000          132.398000  ...   \n",
       "1          136.800193          133.937765          132.148748  ...   \n",
       "2          132.081379          129.340951          127.417845  ...   \n",
       "3          140.604000          138.741000          136.053000  ...   \n",
       "4          144.449359          142.514233          139.785825  ...   \n",
       "\n",
       "   H POS25 T 75°C [mΩ]_Score  H POS26 T 75°C [mΩ]_Score  \\\n",
       "0                          1                          1   \n",
       "1                          1                          1   \n",
       "2                          1                          1   \n",
       "3                          1                          1   \n",
       "4                          1                          1   \n",
       "\n",
       "   H POS27 T 75°C [mΩ]_Score  X POS1 R 75°C[mΩ]_Score  \\\n",
       "0                          1                        1   \n",
       "1                          1                        5   \n",
       "2                          1                        1   \n",
       "3                          1                        5   \n",
       "4                          1                        1   \n",
       "\n",
       "   X POS1 S 75°C[mΩ]_Score  X POS1 T 75°C[mΩ]_Score  Y POS1 R 75°C[mΩ]_Score  \\\n",
       "0                        1                        1                      NaN   \n",
       "1                        5                        5                      NaN   \n",
       "2                        1                        1                      NaN   \n",
       "3                        5                        5                      NaN   \n",
       "4                        1                        1                      NaN   \n",
       "\n",
       "   Y POS1 S 75°C[mΩ]_Score  Y POS1 T 75°C[mΩ]_Score  ROHM  \n",
       "0                      NaN                      NaN   1.0  \n",
       "1                      NaN                      NaN   5.0  \n",
       "2                      NaN                      NaN   1.0  \n",
       "3                      NaN                      NaN   5.0  \n",
       "4                      NaN                      NaN   1.0  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e02c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIE</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>ROHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146916</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146916</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146916</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146917</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146917</td>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIE      FECHA  ROHM\n",
       "0  146916 2019-06-30   1.0\n",
       "1  146916 2015-01-06   5.0\n",
       "2  146916 2014-11-12   1.0\n",
       "3  146917 2022-05-12   5.0\n",
       "4  146917 2014-12-05   1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROHM = df[['SERIE','FECHA','ROHM']]\n",
    "df_ROHM.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
